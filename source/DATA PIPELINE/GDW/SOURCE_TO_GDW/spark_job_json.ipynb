{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"8g\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "sc= spark.sparkContext\n",
    "df = sc.wholeTextFiles('/home/worker2/Desktop/thesis/K18/File_K18/sample_crawl_dataset/Rule_Job_0912.json').map(lambda x:ast.literal_eval(x[1]))\\\n",
    "                            .map(lambda x: json.dumps(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ WARN] Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, col\n",
    "import pyspark.sql.functions as f\n",
    "jobpost = df.select(df.JobID.alias('id'), df.JobTitle.alias('career'), df.knowledge,df.technologySkill)\n",
    "jobpost = jobpost.withColumn('knowledge',lower(col('knowledge'))) \\\n",
    "                    .withColumn('technologySkill',lower(col('technologySkill'))) \\\n",
    "                    .withColumn(\"knowledge\", f.regexp_replace(f.col(\"knowledge\"), \",\", \"\").alias(\"knowledge\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.functions import trim,ltrim,rtrim\n",
    "from pyspark.sql.functions import split, col, monotonically_increasing_id\n",
    "from pyspark.sql.functions import lower, col\n",
    "jobpost = jobpost.withColumn(\"timestamp\", f.current_timestamp()).alias(\"timestamp\")\n",
    "jobpost = jobpost.select(jobpost.id, jobpost.career.alias('name'), jobpost.knowledge, jobpost.technologySkill, jobpost.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import trim,ltrim,rtrim\n",
    "jobpost = jobpost.withColumn(\"name\", ltrim(col(\"name\"))).alias(\"name\") \\\n",
    "                .withColumn('name', lower(col('name')))\n",
    "jobpost = jobpost.withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"senior\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"senior', \", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"sr.\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \", senior\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"sr. \", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"jr.\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"sr\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"mid-senior\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"lead\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"with\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"remote\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"onsite\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"mid Level\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"associate\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \", consultant\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"senior Consultant\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"iii\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"ii\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \" , \", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \" intern \", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \" intern\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"junior \", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \" junior\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"campaign \", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"contract: \", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"\\(.*?\\)\", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", f.regexp_replace(f.col(\"name\"), \"sr \", \"\").alias(\"name\")) \\\n",
    "    .withColumn(\"name\", trim(col(\"name\"))).alias(\"name\")\n",
    "jobpost = jobpost.withColumn(\"name\", ltrim(col(\"name\"))).alias(\"name\") \\\n",
    "                .withColumn('name', lower(col('name')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "career = jobpost.dropDuplicates(['name']).select(jobpost.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "career = career.dropDuplicates(['name']).select('name')\n",
    "career.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Career\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobpost_node = jobpost.select(jobpost.id, jobpost.timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jobpost_node.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"node.keys\", \"id\")\\\n",
    "    .option(\"labels\",\":JobPosting\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jobpost.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"relationship\", 'ABOUT')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':JobPosting')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Career')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 15:10:40.458068: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 15:10:41.827234: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-18 15:10:41.827267: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-18 15:10:45.074001: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-18 15:10:45.074362: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-18 15:10:45.074393: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from transformers import BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-18 15:10:50.299700: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /home/worker2/Desktop/thesis/NER/NERModel_config/converting/saved_model/1\n",
      "2023-02-18 15:10:50.338782: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\n",
      "2023-02-18 15:10:50.338849: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /home/worker2/Desktop/thesis/NER/NERModel_config/converting/saved_model/1\n",
      "2023-02-18 15:10:50.338953: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-18 15:10:50.602986: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
      "2023-02-18 15:10:50.626470: I external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2096000000 Hz\n",
      "2023-02-18 15:10:56.098017: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /home/worker2/Desktop/thesis/NER/NERModel_config/converting/saved_model/1\n",
      "2023-02-18 15:10:56.294892: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 5995215 microseconds.\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import *\n",
    "MODEL_NAME = '/home/worker2/Desktop/thesis/NER/NERModel_config'\n",
    "bert = BertForTokenClassification.loadSavedModel(\n",
    "     '{}/converting/saved_model/1'.format(MODEL_NAME),\n",
    "     spark\n",
    " )\\\n",
    " .setInputCols([\"document\",'token'])\\\n",
    " .setOutputCol(\"ner\")\\\n",
    " .setCaseSensitive(True)\\\n",
    " .setMaxSentenceLength(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert.write().overwrite().save(\"./{}\".format(MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenClassifier_loaded = BertForTokenClassification.load(\"./{}\".format(MODEL_NAME))\\\n",
    "  .setInputCols([\"document\",'token'])\\\n",
    "  .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-TOOL',\n",
       " 'B-TOOL',\n",
       " 'I-KNOW',\n",
       " '[SEP]',\n",
       " 'B-LANG',\n",
       " 'I-LANG',\n",
       " 'B-FRAM',\n",
       " 'I-FRAM',\n",
       " 'B-KNOW',\n",
       " 'I-PLAT',\n",
       " '[CLS]',\n",
       " 'O',\n",
       " 'B-PLAT']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenClassifier_loaded.getClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import *\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('knowledge') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "converter = NerConverter()\\\n",
    "    .setInputCols([\"document\",\"token\",\"ner\"])\\\n",
    "    .setOutputCol(\"ner_span\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    tokenizer,\n",
    "    tokenClassifier_loaded,\n",
    "    converter\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_df = jobpost.select(jobpost.id, jobpost.knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.fit(knowledge_df).transform(knowledge_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "result_last = result.select(F.explode(F.arrays_zip(\"ner_span.result\",\"ner_span.metadata\")).alias(\"entities\"), 'id') \\\n",
    ".select(F.expr(\"entities['result']\").alias(\"name\"), \n",
    "        F.expr(\"entities['metadata'].entity\").alias(\"entity\"), 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "programmingLanguage = result_last.distinct().select(result_last.name).where(result_last.entity == 'LANG')\n",
    "programmingLanguage.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Competency:ProgrammingLanguage\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tool = result_last.distinct().select(result_last.name).where(result_last.entity == 'TOOL')\n",
    "tool.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Competency:Tool\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "framework = result_last.distinct().select(result_last.name).where(result_last.entity == 'FRAM')\n",
    "framework.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Competency:Framework\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "platform = result_last.distinct().select(result_last.name).where(result_last.entity == 'PLAT')\n",
    "platform.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Competency:Platform\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "knowledge = result_last.distinct().select(result_last.name).where(result_last.entity == 'KNOW')\n",
    "knowledge.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Competency:Knowledge\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobpost_knowledgedf_df = result_last.distinct().select(result_last.name, result_last.entity,result_last.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jobpost_pl = jobpost_knowledgedf_df.select(jobpost_knowledgedf_df.name, jobpost_knowledgedf_df.id).where(jobpost_knowledgedf_df.entity == 'LANG')\n",
    "jobpost_pl.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"relationship\", 'NEED_PL')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':JobPosting')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':ProgrammingLanguage')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jobpost_tool = jobpost_knowledgedf_df.select(jobpost_knowledgedf_df.name, jobpost_knowledgedf_df.id).where(jobpost_knowledgedf_df.entity == 'TOOL')\n",
    "jobpost_tool.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"relationship\", 'NEED_TOOL')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':JobPosting')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Tool')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jobpost_fram = jobpost_knowledgedf_df.select(jobpost_knowledgedf_df.name, jobpost_knowledgedf_df.id).where(jobpost_knowledgedf_df.entity == 'FRAM')\n",
    "jobpost_fram.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"relationship\", 'NEED_FRAM')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':JobPosting')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Framework')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jobpost_plat = jobpost_knowledgedf_df.select(jobpost_knowledgedf_df.name, jobpost_knowledgedf_df.id).where(jobpost_knowledgedf_df.entity == 'PLAT')\n",
    "jobpost_plat.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"relationship\", 'NEED_PLAT')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':JobPosting')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Platform')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jobpost_know = jobpost_knowledgedf_df.select(jobpost_knowledgedf_df.name, jobpost_knowledgedf_df.id).where(jobpost_knowledgedf_df.entity == 'KNOW')\n",
    "jobpost_know.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"relationship\", 'NEED_KNOW')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':JobPosting')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Knowledge')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import *\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('tech') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "converter = NerConverter()\\\n",
    "    .setInputCols([\"document\",\"token\",\"ner\"])\\\n",
    "    .setOutputCol(\"ner_span\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    tokenizer,\n",
    "    tokenClassifier_loaded,\n",
    "    converter\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_df = jobpost.select(jobpost.id, jobpost.technologySkill.alias('tech'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_df = tech_df.select(col(\"id\"), split(col(\"tech\"),\",\").alias(\"tech\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "tech_df = tech_df.select(tech_df.id, explode(\"tech\").alias(\"tech\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_df = tech_df.withColumn(\"tech\", trim(col(\"tech\"))).alias(\"tech\")\\\n",
    "                .withColumn(\"tech\", ltrim(col(\"tech\"))).alias(\"tech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.fit(tech_df).transform(tech_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_last = result.select(F.explode(F.arrays_zip(\"ner_span.result\",\"ner_span.metadata\")).alias(\"entities\"), 'id') \\\n",
    ".select(F.expr(\"entities['result']\").alias(\"name\"), \n",
    "        F.expr(\"entities['metadata'].entity\").alias(\"entity\"), 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_last = result_last.orderBy(\"id\").where(result_last.entity != 'EP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "programmingLanguage = result_last.distinct().select(result_last.name).where(result_last.entity == 'LANG')\n",
    "programmingLanguage.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Competency:ProgrammingLanguage\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tool = result_last.distinct().select(result_last.name).where(result_last.entity == 'TOOL')\n",
    "tool.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Competency:Tool\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "framework = result_last.distinct().select(result_last.name).where(result_last.entity == 'FRAM')\n",
    "framework.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Competency:Framework\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "platform = result_last.distinct().select(result_last.name).where(result_last.entity == 'PLAT')\n",
    "platform.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Competency:Platform\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "knowledge = result_last.distinct().select(result_last.name).where(result_last.entity == 'KNOW')\n",
    "knowledge.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Competency:Knowledge\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobpost_knowledgedf_df = result_last.distinct().select(result_last.name, result_last.entity,result_last.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jobpost_pl = jobpost_knowledgedf_df.select(jobpost_knowledgedf_df.name, jobpost_knowledgedf_df.id).where(jobpost_knowledgedf_df.entity == 'LANG')\n",
    "jobpost_pl.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"relationship\", 'NEED_PL')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':JobPosting')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':ProgrammingLanguage')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jobpost_tool = jobpost_knowledgedf_df.select(jobpost_knowledgedf_df.name, jobpost_knowledgedf_df.id).where(jobpost_knowledgedf_df.entity == 'TOOL')\n",
    "jobpost_tool.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"relationship\", 'NEED_TOOL')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':JobPosting')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Tool')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jobpost_fram = jobpost_knowledgedf_df.select(jobpost_knowledgedf_df.name, jobpost_knowledgedf_df.id).where(jobpost_knowledgedf_df.entity == 'FRAM')\n",
    "jobpost_fram.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"relationship\", 'NEED_FRAM')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':JobPosting')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Framework')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jobpost_plat = jobpost_knowledgedf_df.select(jobpost_knowledgedf_df.name, jobpost_knowledgedf_df.id).where(jobpost_knowledgedf_df.entity == 'PLAT')\n",
    "jobpost_plat.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"relationship\", 'NEED_PLAT')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':JobPosting')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Platform')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "jobpost_know = jobpost_knowledgedf_df.select(jobpost_knowledgedf_df.name, jobpost_knowledgedf_df.id).where(jobpost_knowledgedf_df.entity == 'KNOW')\n",
    "jobpost_know.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", \"neo4j://localhost:7687\")\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", \"password\")\\\n",
    "    .option(\"relationship\", 'NEED_KNOW')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':JobPosting')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Knowledge')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
