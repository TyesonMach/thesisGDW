{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a801f5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark NLP\")\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .config(\"spark.driver.memory\",\"12g\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95132e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# get the start time\n",
    "st = time.time()\n",
    "url='neo4j://localhost:7692'\n",
    "password = 'password'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdc305d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-19 00:53:33.970268: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-19 00:53:34.689424: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-19 00:53:34.689469: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-19 00:53:37.277008: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-19 00:53:37.277277: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-19 00:53:37.277298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "from transformers import BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc648fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-19 00:53:42.260622: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /home/worker2/Desktop/thesis/NER/NERModel_config/converting/saved_model/1\n",
      "2023-02-19 00:53:42.309064: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }\n",
      "2023-02-19 00:53:42.309139: I external/org_tensorflow/tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /home/worker2/Desktop/thesis/NER/NERModel_config/converting/saved_model/1\n",
      "2023-02-19 00:53:42.309248: I external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-19 00:53:42.654410: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.\n",
      "2023-02-19 00:53:42.680140: I external/org_tensorflow/tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2096000000 Hz\n",
      "2023-02-19 00:53:47.117996: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /home/worker2/Desktop/thesis/NER/NERModel_config/converting/saved_model/1\n",
      "2023-02-19 00:53:47.300294: I external/org_tensorflow/tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 5039695 microseconds.\n"
     ]
    }
   ],
   "source": [
    "from sparknlp.annotator import *\n",
    "MODEL_NAME = '/home/worker2/Desktop/thesis/NER/NERModel_config'\n",
    "bert = BertForTokenClassification.loadSavedModel(\n",
    "     '{}/converting/saved_model/1'.format(MODEL_NAME),\n",
    "     spark\n",
    " )\\\n",
    " .setInputCols([\"document\",'token'])\\\n",
    " .setOutputCol(\"ner\")\\\n",
    " .setCaseSensitive(True)\\\n",
    " .setMaxSentenceLength(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49d0439f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bert.write().overwrite().save(\"./{}\".format(MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c59d9885",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenClassifier_loaded = BertForTokenClassification.load(\"./{}\".format(MODEL_NAME))\\\n",
    "  .setInputCols([\"document\",'token'])\\\n",
    "  .setOutputCol(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3572ccbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I-TOOL',\n",
       " 'B-TOOL',\n",
       " 'I-KNOW',\n",
       " '[SEP]',\n",
       " 'B-LANG',\n",
       " 'I-LANG',\n",
       " 'B-FRAM',\n",
       " 'I-FRAM',\n",
       " 'B-KNOW',\n",
       " 'I-PLAT',\n",
       " '[CLS]',\n",
       " 'O',\n",
       " 'B-PLAT']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenClassifier_loaded.getClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0488c83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import *\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('description') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "converter = NerConverter()\\\n",
    "    .setInputCols([\"document\",\"token\",\"ner\"])\\\n",
    "    .setOutputCol(\"ner_span\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    tokenizer,\n",
    "    tokenClassifier_loaded,\n",
    "    converter\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72af88a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.option('header','true').csv('/home/worker2/Desktop/thesis/K18/File_K18/sample_crawl_dataset/Coursera_DataScience.csv',inferSchema=True, escape = '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b86814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f\n",
    "df = df.withColumn(\"enroll\", f.regexp_replace(f.col(\"enroll\"), \",\", \"\").alias(\"enroll\")) \\\n",
    "    .withColumn(\"time\", f.regexp_replace(f.col(\"time\"), \" hours\", \"\").alias(\"time\")) \\\n",
    "    .withColumn(\"time\", f.regexp_replace(f.col(\"time\"), \" hour\", \"\").alias(\"time\")) \\\n",
    "    .withColumn(\"fee\", f.regexp_replace(f.col(\"fee\"), \"[a-zA-Z]+\", \"\").alias(\"fee\"))\n",
    "    #.withColumn(\"fee\", f.regexp_replace(f.col(\"fee\"), \"Enroll\", \"\").alias(\"fee\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c1c0ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType, LongType, IntegerType\n",
    "\n",
    "df = df \\\n",
    "  .withColumn(\"rating\" ,\n",
    "              df[\"rating\"]\n",
    "              .cast(FloatType()))   \\\n",
    "  .withColumn(\"enroll\",\n",
    "              df[\"enroll\"]\n",
    "              .cast(LongType())) \\\n",
    "  .withColumn(\"time\",df['time'].cast(IntegerType())) \\\n",
    "  .withColumn(\"fee\", df['fee'].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0ca3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,when\n",
    "df = df.na.fill(value=0, subset=['rating','enroll', 'fee','time'])\n",
    "df = df.na.fill(value='None', subset=['link','instructor', 'levelrequirement', 'skillrequirement', 'SkillWillLearn','SkillGain', 'Subject', 'organization', 'program', 'RelationInsOrg', 'Subtitle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c85826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when,lower\n",
    "df = df.withColumn('levelrequirement', lower('levelrequirement'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77ae35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"levelrequirement\", when((df.levelrequirement != \"expert\") & (df.levelrequirement != \"advanced\") & (df.levelrequirement != 'intermediate') & (df.levelrequirement != 'beginner'),\"beginner\") \\\n",
    "                                        .when(df.levelrequirement == \"advanced\",\"expert\")\n",
    "                                        .otherwise(df.levelrequirement))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "408a7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when,lower\n",
    "df = df.withColumn('levelrequirement', lower('levelrequirement'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e3463ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, col, monotonically_increasing_id\n",
    "\n",
    "df2 = df.select(col('name'),col('link'),col('rating'),col('enroll'),col('instructor'),col('time'),col('levelrequirement'),col('skillrequirement'),\n",
    "                col('SkillWillLearn'),col('SkillGain'),col('Subject'),col('organization'),col('fee'),col('program'),col('RelationInsOrg'),split(col(\"Subtitle\"),\", \").alias(\"Subtitle\"))\n",
    "df2 = df2.withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "684c024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn(\"timestamp\", f.current_timestamp()).alias(\"timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07837336",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex2 = r\"^https?://.*\"\n",
    "df2 = df2.filter(col(\"link\").rlike(regex2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a160eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "course = df2.select(col('id'), col('name'), col('rating'), col('enroll'), col('time'), col('fee'), col('link'), col('timestamp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0316685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "course.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Append\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"id\")\\\n",
    "    .option(\"labels\",\":Course\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29b5eed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn(\"instructor\", f.regexp_replace(f.col(\"instructor\"), \", PhD\", \"\").alias(\"instructor\")) \\\n",
    "    .withColumn(\"instructor\", f.regexp_replace(f.col(\"instructor\"), \", Ph.D.\", \"\").alias(\"instructor\")) \\\n",
    "    .withColumn(\"instructor\", f.regexp_replace(f.col(\"instructor\"), chr(34), \"\").alias(\"instructor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1ff822e",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructor = df2.select(col(\"id\"), split(col(\"instructor\"),\",\").alias(\"instructor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e756b373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode\n",
    "instructor = instructor.select(instructor.id, explode(\"instructor\").alias(\"instructor\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4014d69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructorNode = instructor.select(instructor.instructor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dcaf9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "instructorNode.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"instructor\")\\\n",
    "    .option(\"labels\",\":Instructor\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0d41d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "instructor.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"relationship\", 'INSTRUCT_BY')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Instructor')\\\n",
    "    .option('relationship.target.node.keys','instructor:instructor')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a06987c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = df2.select(col(\"id\"), col('levelrequirement').alias('level'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a143674",
   "metadata": {},
   "outputs": [],
   "source": [
    "level.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"level\")\\\n",
    "    .option(\"labels\",\":Level\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8d47b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, col\n",
    "subtitle = df2.select(col(\"id\"), explode(col(\"Subtitle\")).alias(\"language\"))\n",
    "subtitle = subtitle.withColumn('language', lower(col('language'))) \\\n",
    "            .withColumn(\"language\", f.regexp_replace(f.col(\"language\"), \"subtitles: \", \"\").alias(\"language\")) \\\n",
    "            .withColumn(\"language\", f.regexp_replace(f.col(\"language\"), \"subtitles:\", \"\").alias(\"language\")) \\\n",
    "            .withColumn(\"language\", f.regexp_replace(f.col(\"language\"), \"none\", \"english\").alias(\"language\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab74a674",
   "metadata": {},
   "outputs": [],
   "source": [
    "subNode = subtitle.select(subtitle.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8de7cdef",
   "metadata": {},
   "outputs": [],
   "source": [
    "subNode.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"language\")\\\n",
    "    .option(\"labels\",\":Language\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8763cbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "subtitle.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"relationship\", 'HAVE_LANGUAGE')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Language')\\\n",
    "    .option('relationship.target.node.keys','language:language')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd2f36af",
   "metadata": {},
   "outputs": [],
   "source": [
    "level.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"relationship\", 'HAS_LEVEL')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Level')\\\n",
    "    .option('relationship.target.node.keys','level:level')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c599b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "regex = r\"(?:https?:\\/\\/)?(?:[^@\\n]+@)?(?:www\\.)?([^:\\/\\n?]+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34d481ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex2 = r\"^https?://.*\"\n",
    "website = df2.select(df2.id, df2.link)\n",
    "website = website.filter(col(\"link\").rlike(regex2))\n",
    "website = website.withColumn(\"website\", regexp_extract(df[\"link\"], regex, 1))\n",
    "websiteNode = website.dropDuplicates(['website']).select(col('website').alias('name'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "96e3a2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "websiteNode.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Website\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54d09be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "website.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"relationship\", 'PROVIDE_BY')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Website')\\\n",
    "    .option('relationship.target.node.keys','website:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b2187aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, col\n",
    "from pyspark.sql.functions import trim,ltrim,rtrim\n",
    "import pyspark.sql.functions as f\n",
    "df = df.select(df.SkillWillLearn.alias('description'))\n",
    "df = df.withColumn('description', lower(col('description'))) \\\n",
    "        .withColumn('description', f.regexp_replace(col(\"description\"), \"[\\n\\r]\", \"\")) \\\n",
    "        .withColumn('description', f.regexp_replace(col(\"description\"), \"®\", \"\")) \\\n",
    "        .withColumn('description', f.regexp_replace(col(\"description\"), \"'s\", \"\")) \\\n",
    "        .withColumn('description', f.regexp_replace(col(\"description\"), \";\", \" \")) \\\n",
    "        .withColumn('description', f.decode('description','UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0938f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db9b3929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split, col, monotonically_increasing_id\n",
    "result = result.withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fc68605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "result_last = result.select(F.explode(F.arrays_zip(\"ner_span.result\",\"ner_span.metadata\")).alias(\"entities\"), 'id') \\\n",
    ".select(F.expr(\"entities['result']\").alias(\"name\"), \n",
    "        F.expr(\"entities['metadata'].entity\").alias(\"entity\"), 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "750efd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_last = result_last.orderBy(\"id\").where(result_last.entity != 'EP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "834c2bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "programmingLanguage = result_last.distinct().select(result_last.name).where(result_last.entity == 'LANG')\n",
    "#programmingLanguage = programmingLanguage.withColumn('chunk', f.regexp_replace(col(\"chunk\"), \"-?\\\\d+\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "979c1077",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "programmingLanguage.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":ProgrammingLanguage\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "51f73b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = result_last.distinct().select(result_last.name).where(result_last.entity == 'TOOL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33d81d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tool.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Tool\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8c9cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework = result_last.distinct().select(result_last.name).where(result_last.entity == 'FRAM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6a00104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "framework.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Framework\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d8ea750",
   "metadata": {},
   "outputs": [],
   "source": [
    "platform = result_last.distinct().select(result_last.name).where(result_last.entity == 'PLAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "add9cccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "platform.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Platform\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7c70258",
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge = result_last.distinct().select(result_last.name).where(result_last.entity == 'KNOW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5203d3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "knowledge.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Knowledge\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "13984454",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_lo = result_last.distinct().select(result_last.name, result_last.entity,result_last.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9e809d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_pl = course_lo.select(course_lo.name, course_lo.id).where(course_lo.entity == 'LANG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ca52bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "course_pl.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"relationship\", 'TEACH_PL')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':ProgrammingLanguage')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9997b416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "course_tool = course_lo.select(course_lo.name, course_lo.id).where(course_lo.entity == 'TOOL')\n",
    "course_tool.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"relationship\", 'TEACH_TOOL')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Tool')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "78549c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "course_fram = course_lo.select(course_lo.name, course_lo.id).where(course_lo.entity == 'FRAM')\n",
    "course_fram.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"relationship\", 'TEACH_FRAM')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Framework')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "670e9cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "course_plat = course_lo.select(course_lo.name, course_lo.id).where(course_lo.entity == 'PLAT')\n",
    "course_plat.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"relationship\", 'TEACH_PLAT')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Platform')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ad112757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "course_know = course_lo.select(course_lo.name, course_lo.id).where(course_lo.entity == 'KNOW')\n",
    "course_know.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option('batch.size','200') \\\n",
    "    .option(\"relationship\", 'TEACH_KNOW')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Knowledge')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "652686e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "require_df = df2.select(df2.skillrequirement.alias('description'))\n",
    "require_df = require_df.withColumn('description', lower(col('description'))) \\\n",
    "        .withColumn('description', f.regexp_replace(col(\"description\"), \"[\\n\\r]\", \"\")) \\\n",
    "        .withColumn('description', f.regexp_replace(col(\"description\"), \"®\", \"\")) \\\n",
    "        .withColumn('description', f.regexp_replace(col(\"description\"), \"'s\", \"\")) \\\n",
    "        .withColumn('description', f.regexp_replace(col(\"description\"), \";\", \" \")) \\\n",
    "        .withColumn('description', f.decode('description','UTF-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9899bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import *\n",
    "document_assembler = DocumentAssembler() \\\n",
    "    .setInputCol('description') \\\n",
    "    .setOutputCol('document')\n",
    "\n",
    "tokenizer = Tokenizer() \\\n",
    "    .setInputCols(['document']) \\\n",
    "    .setOutputCol('token')\n",
    "\n",
    "converter = NerConverter()\\\n",
    "    .setInputCols([\"document\",\"token\",\"ner\"])\\\n",
    "    .setOutputCol(\"ner_span\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    document_assembler, \n",
    "    tokenizer,\n",
    "    tokenClassifier_loaded,\n",
    "    converter\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64523c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "require_result = pipeline.fit(require_df).transform(require_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55fe159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "require_result = require_result.withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f5311d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "require_last = require_result.select(F.explode(F.arrays_zip(\"ner_span.result\",\"ner_span.metadata\")).alias(\"entities\"), 'id') \\\n",
    ".select(F.expr(\"entities['result']\").alias(\"name\"), \n",
    "        F.expr(\"entities['metadata'].entity\").alias(\"entity\"), 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "edbf57dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "require_last = require_last.orderBy(\"id\").where(require_last.entity != 'EP]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ddaa922a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pl_require = require_last.distinct().select(require_last.name).where(require_last.entity == 'LANG')\n",
    "pl_require.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":ProgrammingLanguage\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6541c105",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tool_require = require_last.distinct().select(require_last.name).where(require_last.entity == 'TOOL')\n",
    "tool_require.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Tool\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bdd2ee21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "framework_require = require_last.distinct().select(require_last.name).where(require_last.entity == 'FRAM')\n",
    "framework_require.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Framework\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "480647bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "platform_require = require_last.distinct().select(require_last.name).where(require_last.entity == 'PLAT')\n",
    "platform_require.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Platform\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ff22898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "knowledge_require = require_last.distinct().select(require_last.name).where(require_last.entity == 'KNOW')\n",
    "knowledge_require.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"node.keys\", \"name\")\\\n",
    "    .option(\"labels\",\":Knowledge\")\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9e3a90e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "course_require_lo = require_last.distinct().select(require_last.name, require_last.entity,require_last.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c793e2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "course_require_pl = course_require_lo.select(course_require_lo.name, course_require_lo.id).where(course_require_lo.entity == 'LANG')\n",
    "course_require_pl.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"relationship\", 'REQUIRE_PL')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':ProgrammingLanguage')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53a471d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "course_require_tool = course_require_lo.select(course_require_lo.name, course_require_lo.id).where(course_require_lo.entity == 'TOOL')\n",
    "course_require_tool.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"relationship\", 'REQUIRE_TOOL')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Tool')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ab61ae93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "course_require_fram = course_require_lo.select(course_require_lo.name, course_require_lo.id).where(course_require_lo.entity == 'FRAM')\n",
    "course_require_fram.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"relationship\", 'REQUIRE_FRAM')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Framework')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf5145dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "course_require_plat = course_require_lo.select(course_require_lo.name, course_require_lo.id).where(course_require_lo.entity == 'PLAT')\n",
    "course_require_plat.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"relationship\", 'REQUIRE_PLAT')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Platform')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "83b9b9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "course_require_know = course_require_lo.select(course_require_lo.name, course_require_lo.id).where(course_require_lo.entity == 'KNOW')\n",
    "course_require_know.write.format(\"org.neo4j.spark.DataSource\")\\\n",
    "    .mode(\"Overwrite\")\\\n",
    "    .option(\"url\", url)\\\n",
    "    .option(\"authentication.type\", \"basic\")\\\n",
    "    .option(\"authentication.basic.username\", \"neo4j\")\\\n",
    "    .option(\"authentication.basic.password\", password)\\\n",
    "    .option(\"relationship\", 'REQUIRE_KNOW')\\\n",
    "    .option('relationship.save.strategy','keys')\\\n",
    "    .option('relationship.source.labels',':Course')\\\n",
    "    .option('relationship.source.node.keys','id:id')\\\n",
    "    .option('relationship.source.save.mode','Match')\\\n",
    "    .option('relationship.target.labels',':Knowledge')\\\n",
    "    .option('relationship.target.node.keys','name:name')\\\n",
    "    .option('relationship.target.save.mode','Match')\\\n",
    "    .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0db4a0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 959.5246350765228 seconds\n"
     ]
    }
   ],
   "source": [
    "et = time.time()\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58576a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
