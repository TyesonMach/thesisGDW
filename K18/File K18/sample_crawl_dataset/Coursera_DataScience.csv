name,link,rating,enroll,instructor,time,levelrequirement,skillrequirement,SkillWillLearn,SkillGain,Subject,organization,fee,program,RelationInsOrg,Subtitle
Machine Learning,https://www.coursera.org/learn/machine-learning,4.9,"4,491,564",Andrew Ng,61 hours,,,"Machine learning is the science of getting computers to act without being explicitly programmed. In the past decade, machine learning has given us self-driving cars, practical speech recognition, effective web search, and a vastly improved understanding of the human genome. Machine learning is so pervasive today that you probably use it dozens of times a day without knowing it. Many researchers also think it is the best way to make progress towards human-level AI. In this class, you will learn about the most effective machine learning techniques, and gain practice implementing them and getting them to work for yourself. More importantly, you'll learn about not only the theoretical underpinnings of learning, but also gain the practical know-how needed to quickly and powerfully apply these techniques to new problems. Finally, you'll learn about some of Silicon Valley's best practices in innovation as it pertains to machine learning and AI. This course provides a broad introduction to machine learning, datamining, and statistical pattern recognition. Topics include: (i) Supervised learning (parametric/non-parametric algorithms, support vector machines, kernels, neural networks). (ii) Unsupervised learning (clustering, dimensionality reduction, recommender systems, deep learning). (iii) Best practices in machine learning (bias/variance theory; innovation process in machine learning and AI). The course will also draw from numerous case studies and applications, so that you'll also learn how to apply learning algorithms to building smart robots (perception, control), text understanding (web search, anti-spam), computer vision, medical informatics, audio, database mining, and other areas.",Logistic Regression          Artificial Neural Network          Machine Learning (ML) Algorithms          Machine Learning      ,Data Science,Stanford University,Enroll for Free,,"Andrew Ng work for Stanford University, Coursera, DeepLearning.AI","Arabic, French, Portuguese (European), Chinese (Simplified), Italian, Vietnamese, German, Russian, English, Hebrew, Spanish, Hindi, Japanese"
Data Visualization in Excel,https://www.coursera.org/learn/excel-data-visualization,4.9,"12,564","Nicky Bull,Dr Prashan S. M. Karunaratne",18 hours,Intermediate,We expect that you have some background with Excel. You can move around the interface and create basic formulas.,"In an age now driven by ""big data"", we need to cut through the noise and present key information in a way that can be quickly consumed and acted upon making data visualization an increasingly important skill. Visualizations need to not only present data in an easy to understand and attractive way, but they must also provide context for the data, tell a story, achieving that fine balance between form and function. Excel has many rivals in this space, but it is still an excellent choice, particularly if it's where your data resides. It offers a wealth of tools for creating visualizations other than charts and the chart options available are constantly increasing and improving, so the newer versions now include waterfall charts, sunburst diagrams and even map charts. But what sets Excel apart is its flexibility, it gives us total creative control over our designs so if needed we could produce our own animated custom chart to tell the right story for our data. Over five weeks we will explore Excel's rich selection of visualization tools using practical case studies as seen through the eyes of Rohan, an environmental analyst. Rohan is required to produce visualizations that will show trends, forecasts, breakdowns and comparisons for a large variety of environmental data sets. As well as utilising the usual chart types he wants to use conditional formats, sparklines, specialised charts and even create his own animated charts and infographics. In some cases, he will also need to prepare the data using pivot tables to drill down and answer very specific questions. We are going to help him achieve all this and present our finished visualizations in attractive reports and dashboards that use tools like slicers and macros for automation and interactivity.These are the topics we will cover:Week 1: 	Dynamic visualizations with conditional formatting, custom number formatting, sparklines and macrosWeek 2: 	Charting techniques for telling the right storyWeek 3: 	Creating specialised and custom chartsWeek 4: 	Summarising and filtering data with pivot tables and pivot chartsWeek 5: 	Creating interactive dashboards in ExcelThis is the second course in our Specialization on Data Analytics and Visualization. The first course: Excel Fundamentals for Data Analysis, covers data preparation and cleaning but also teaches some of the prerequisites for this course like tables and named ranges as well as text, lookup and logical functions. To get the most out of this course we would recommend you do the first course or have experience with these topics. In this course we focus on Data Visualization in Excel, join us for this exciting journey.", Microsoft Excel          Data Visualization (DataViz)      ,Business,Macquarie University,Enroll for Free,Excel Skills for Data Analytics and Visualization Specialization,"Nicky Bull work for Macquarie University,Dr Prashan S. M. Karunaratne work for Macquarie University",English
Spatial Analysis and Satellite Imagery in a GIS,https://www.coursera.org/learn/spatial-analysis-satellite-imagery-in-a-gis,4.9,"18,321",Don Boyes,14 hours,Beginner,,"In this course, you will learn how to analyze map data using different data types and methods to answer geographic questions. First, you will learn how to filter a data set using different types of queries to find just the data you need to answer a particular question. Then, we will discuss simple yet powerful analysis methods that use vector data to find spatial relationships within and between data sets. In this section, you will also learn about how to use ModelBuilder, a simple but powerful tool for building analysis flowcharts that can then also be run as models. You will then learn how to find, understand, and use remotely sensed data such as satellite imagery, as a rich source of GIS data. You will then learn how to analyze raster data. Finally, you will complete your own project where you get to try out the new skills and tools you have learned about in this course. Note: software is not provided for this course.",Geographic Information System (GIS)          Cartography          Esri          Mapping          Spatial Analysis      ,Physical Science and Engineering,University of Toronto,Enroll for Free,"GIS, Mapping, and Spatial Analysis Specialization",Don Boyes work for University of Toronto,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Python Data Structures,https://www.coursera.org/learn/python-data,4.9,"800,203",Charles Russell Severance,19 hours,,,Explain the principles of data structures &amp; how they are used. Create programs that are able to read and write data from files. Store data as key/value pairs using Python dictionaries. Accomplish multi-step tasks like sorting or looping using tuples,Python Syntax And Semantics          Data Structure          Tuple          Python Programming      ,Computer Science,University of Michigan,Enroll for Free,Python for Everybody Specialization,Charles Russell Severance work for University of Michigan,"Arabic, French, Portuguese (European), Chinese (Simplified), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Neural Networks and Deep Learning,https://www.coursera.org/learn/neural-networks-deep-learning,4.9,"1,013,093","Andrew Ng,Kian Katanforoosh,Younes Bensouda Mourri",27 hours,Intermediate,,"In the first course of the Deep Learning Specialization, you will study the foundational concept of neural networks and deep learning.  By the end, you will be familiar with the significant technological trends driving the rise of deep learning; build, train, and apply fully connected deep neural networks; implement efficient (vectorized) neural networks; identify key parameters in a neural network’s architecture; and apply deep learning to your own applications.The Deep Learning Specialization is our foundational program that will help you understand the capabilities, challenges, and consequences of deep learning and prepare you to participate in the development of leading-edge AI technology. It provides a pathway for you to gain the knowledge and skills to apply machine learning to your work, level up your technical career, and take the definitive step in the world of AI.",Deep Learning          Artificial Neural Network          Backpropagation          Python Programming          Neural Network Architecture      ,Data Science,DeepLearning.AI,Enroll for Free,Deep Learning Specialization,"Andrew Ng work for Stanford University, Coursera, DeepLearning.AI,Kian Katanforoosh work for DeepLearning.AI,Younes Bensouda Mourri work for DeepLearning.AI","Chinese (Traditional), Arabic, French, Portuguese (European), Chinese (Simplified), Italian, Portuguese (Brazilian), Vietnamese, Korean, German, Russian, Turkish, English, Spanish, Japanese"
What is Data Science? ,https://www.coursera.org/learn/what-is-datascience,4.7,"516,658","Rav Ahuja,Alex Aklson",9 hours,Beginner,,Define data science and its importance in today’s data-driven world. Describe the various paths that can lead to a career in data science. Describe the advice given by seasoned data science professionals to data scientists who are just starting out. Explain why data science is considered the sexiest job in the 21st century.,Data Science          Deep Learning          Machine Learning          Big Data          Data Mining      ,Data Science,IBM,Enroll for Free,,"Rav Ahuja work for Coursera, IBM,Alex Aklson work for IBM","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, Turkish, English, Spanish"
Web of Data,https://www.coursera.org/learn/web-data,4.1,"4,104","Catherine Faron Zucker,Fabien Gandon,Olivier Corby",18 hours,Intermediate,,"This MOOC – a joint initiative between EIT Digital, Université de Nice Sophia-Antipolis / Université Côte d'Azur, and INRIA - introduces the Linked Data standards and principles that provide the foundation of the Semantic web. You will learn how to publish, obtain and use structured data directly from the Web. Learning the principles, languages, and standards to exchange data on the Web will enable you to design and produce new applications, products, and services that leverage the volume and variety of data the Web holds. We divided this course into four parts that cover the core technical skills and competencies you need to master to be able to use the Web as a space for giant structure data exchange:•. in the first part, “Principals of a Web of Linked Data”: you will learn and practice the principles to publish and obtain data directly on the Web instead of Web pages; •. in the second part, “The RDF Data Model”: you will learn the standard data model for the Web and its syntaxes to publish and link data on the Web in your applications and services;•. in the third part, “SPARQL Query Language”: you will learn how to directly query and access data sources on the Web and obtain structured data relevant to your activity and domain;•. in the fourth and final part, “Integration of other Data Formats and Sources”: you will learn how the Web standards interact and interoperate with other data formats to allow the integration of a variety of data sources.Each week alternates short videos and quizzes, as well as supplementary resources and forums to gradually progress through the different principles and standards.After following this course successfully, you will have the skills to obtain focused and structured datasets from the Web that you can then use to augment your own datasets, enrich their dimensions, feed your applications, perform data mining, machine learning, and training, data analysis, AI processing and reasoning and other data management.",search for occurrences of a query graph          publish Linked Open Data on the Web          access remotely data sources on the Web          use and mix together existing data to obtain new data      ,Data Science,EIT Digital ,Enroll for Free,,"Catherine Faron Zucker work for EIT Digital ,Fabien Gandon work for EIT Digital ,Olivier Corby work for EIT Digital ",English
Share Data Through the Art of Visualization,https://www.coursera.org/learn/visualize-data,4.5,"68,559",Google Career Certificates,24 hours,Beginner,No prior experience with spreadsheets or data analytics is required. All you need is high-school level math and a curiosity about how things work. ,Describe the use of data visualizations to talk about data and the results of data analysis. Identify Tableau as a data visualization tool and understand its uses. Explain what data driven stories are including reference to their importance and their attributes. Explain principles and practices associated with effective presentations,Data Analysis          Tableau Software          Data Visualization (DataViz)          Presentation      ,Data Science,Google,Enroll for Free,Google Data Analytics Professional Certificate,Google Career Certificates work for Google,English
Visualization for Data Journalism,https://www.coursera.org/learn/visualization-for-data-journalism,4.4,"6,089",Margaret Ng,18 hours,Beginner,,"While telling stories with data has been part of the news practice since its earliest days, it is in the midst of a renaissance. Graphics desks which used to be deemed as “the art department,” a subfield outside the work of newsrooms, are becoming a core part of newsrooms’ operation. Those people (they often have various titles: data journalists, news artists, graphic reporters, developers, etc.) who design news graphics are expected to be full-fledged journalists and work closely with reporters and editors. The purpose of this class is to learn how to think about the visual presentation of data, how and why it works, and how to doit the right way. We will learn how to make graphs like The New York Times, Vox, Pew, and FiveThirtyEight. In the end, you can share–embed your beautiful charts in publications, blog posts, and websites. This course assumes you understand basic coding skills, preferably Python. However, we also provide a brief review on Python in Module 1, in case you want to refresh yourself on the basics and perform simple data analysis.",Python Libraries          Data Analysis          Plotly          Data Reporting          Data Visualization (DataViz)      ,Data Science,University of Illinois at Urbana-Champaign,Enroll for Free,,Margaret Ng work for University of Illinois at Urbana-Champaign,"French, Portuguese (European), Russian, English, Spanish"
Using Data for Geographic Mapping and Forecasting in SAS Visual Analytics,https://www.coursera.org/learn/using-data-geographic-mapping-sas-va,4.8,"7,270",Nicole Ball,5 hours,Intermediate,,"In this course, you learn about the data structure needed for geographic mapping and forecasting, how to use SAS Data Studio to restructure data for analysis, and how to create geo maps and forecasts in SAS Visual Analytics.",,Data Science,SAS,Enroll for Free,SAS Visual Business Analytics Professional Certificate,Nicole Ball work for SAS,Subtitles: English
Understanding and Visualizing Data with Python,https://www.coursera.org/learn/understanding-visualization-data,4.7,"92,827","Brenda Gunderson,Brady T. West,Kerby Shedden",21 hours,Beginner,High school algebra,Properly identify various data types and understand the different uses for each. Create data visualizations and numerical summaries with Python. Communicate statistical ideas clearly and concisely to a broad audience. Identify appropriate analytic techniques for probability and non-probability samples,Statistics          Data Analysis          Python Programming          Data Visualization (DataViz)      ,Data Science,University of Michigan,Enroll for Free,Statistics with Python Specialization,"Brenda Gunderson work for University of Michigan,Brady T. West work for University of Michigan,Kerby Shedden work for University of Michigan","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Tools for Exploratory Data Analysis in Business,https://www.coursera.org/learn/tools-exploratory-data-analysis-business,,"2,271","Jessen Hobson,Ronald Guymon",18 hours,Beginner,Some prior experience using data in a business setting is helpful.,Development of an analytic mindset for approaching business problems. The ability to appraise the value of datasets foraddressing business problems using summary statistics and data visualizations. Competence in operating business analytic software applications for exploratory data analysis.,R and RStudio          Data Cleansing and Exploration          Alteryx          Analytic Mindset          PowerBI      ,Data Science,University of Illinois at Urbana-Champaign,Enroll for Free,Business Analytics Specialization,"Jessen Hobson work for University of Illinois at Urbana-Champaign,Ronald Guymon work for University of Illinois at Urbana-Champaign",English
Importing Data in the Tidyverse,https://www.coursera.org/learn/tidyverse-importing-data,4.6,,"Carrie Wright, PhD,Shannon Ellis, PhD,Stephanie Hicks, PhD,Roger D. Peng, PhD",15 hours,Beginner,F​amiliarity with the R programming language,Describe different data formats. Apply Tidyverse functions to import data into R from external formats. Obtain data from a web API,,Data Science,Johns Hopkins University,Enroll for Free,Tidyverse Skills for Data Science in R Specialization,"Carrie Wright, PhD work for Johns Hopkins University,Shannon Ellis, PhD work for Johns Hopkins University,Stephanie Hicks, PhD work for Johns Hopkins University,Roger D. Peng, PhD work for Johns Hopkins University",Subtitles: English
Visualizing Data in the Tidyverse,https://www.coursera.org/learn/tidyverse-visualize-data,,,"Carrie Wright, PhD,Shannon Ellis, PhD,Stephanie Hicks, PhD,Roger D. Peng, PhD",17 hours,,,Distinguish between various types of plots and their uses. Use the ggplot2 R package to develop data visualizations. Build effective data summary tables. Build data animations for visual storytelling,,Data Science,Johns Hopkins University,Enroll for Free,Tidyverse Skills for Data Science in R Specialization,"Carrie Wright, PhD work for Johns Hopkins University,Shannon Ellis, PhD work for Johns Hopkins University,Stephanie Hicks, PhD work for Johns Hopkins University,Roger D. Peng, PhD work for Johns Hopkins University",Subtitles: English
Wrangling Data in the Tidyverse,https://www.coursera.org/learn/tidyverse-data-wrangling,4.8,,"Carrie Wright, PhD,Shannon Ellis, PhD,Stephanie Hicks, PhD,Roger D. Peng, PhD",14 hours,Manually,,Apply Tidyverse functions to transform non-tidy data to tidy data. Conduct basic exploratory data analysis. Conduct analyses of text data,,Data Science,Johns Hopkins University,Enroll for Free,Tidyverse Skills for Data Science in R Specialization,"Carrie Wright, PhD work for Johns Hopkins University,Shannon Ellis, PhD work for Johns Hopkins University,Stephanie Hicks, PhD work for Johns Hopkins University,Roger D. Peng, PhD work for Johns Hopkins University",Subtitles: English
Modeling Data in the Tidyverse,https://www.coursera.org/learn/tidyverse-modelling-data,,,"Carrie Wright, PhD,Shannon Ellis, PhD,Stephanie Hicks, PhD,Roger D. Peng, PhD",21 hours,,,Describe different types of data analytic questions. Conduct hypothesis tests of your data. Apply linear modeling techniques to answer multivariable questions. Apply machine learning workflows to detect complex patterns in your data,,Data Science,Johns Hopkins University,Enroll for Free,Tidyverse Skills for Data Science in R Specialization,"Carrie Wright, PhD work for Johns Hopkins University,Shannon Ellis, PhD work for Johns Hopkins University,Stephanie Hicks, PhD work for Johns Hopkins University,Roger D. Peng, PhD work for Johns Hopkins University",Subtitles: English
The Data Science of Health Informatics,https://www.coursera.org/learn/the-data-science-of-health-informatics,4.7,"12,002","Hadi H. K. Kharrazi, MD, Ph.D,Sam Meiselman",10 hours,Beginner,"While there are no prerequisites, prior experience with, or knowledge of, health, healthcare, technology, and statistics are helpful.",Articulate different forms of clinical and population level data. Describe the data required to answer a healthcare information problem. Distinguish between data questions and data queries when dealing with a healthcare information problem.,Data Science          Database (DBMS)          Data Analysis          Health Informatics          data querying      ,Health,Johns Hopkins University,Enroll for Free,Health Informatics Specialization,"Hadi H. K. Kharrazi, MD, Ph.D work for Johns Hopkins University,Sam Meiselman work for Johns Hopkins University","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
The Fundamental of Data-Driven Investment,https://www.coursera.org/learn/the-fundamental-of-data-driven-investment,,,Youngju Nielsen,19 hours,Beginner,,Build an investment factor model using regression methodology. Employ optimization algorithm using R standard library. Explain the portfolio performance,Build an investment factor model using regression methodology.          Explain the portfolio performance.          Employ optimization algorithm using R standard library.      ,Data Science,Sungkyunkwan University,Enroll for Free,,Youngju Nielsen work for Sungkyunkwan University,English
"Teaching Impacts of Technology: Data Collection, Use, and Privacy",https://www.coursera.org/learn/teach-impacts-technology-data,4.6,"2,623",Beth Simon,13 hours,Beginner,,"In this course you’ll focus on how constant data collection and big data analysis have impacted us, exploring the interplay between using your data and protecting it, as well as thinking about what it could do for you in the future. This will be done through a series of paired teaching sections, exploring a specific “Impact of Computing” in your typical day and the “Technologies and Computing Concepts” that enable that impact, all at a K12-appropriate level.  This course is part of a larger Specialization through which you’ll learn impacts of computing concepts you need to know, organized into 5 distinct digital “worlds”, as well as learn pedagogical techniques and evaluate lesson plans and resources to utilize in your classroom. By the end, you’ll be prepared to teach pre-college learners to be both savvy and effective participants in their digital world.In this particular digital world (personal data), you’ll explore the following Impacts &amp; Technology pairs --Impacts (Show me what I want to see!): Internet Privacy, Custom Ads, Personalization of web pagesTechnologies and Computing Concepts: Cookies, Web vs Internet, https, Web ServersImpacts (Use my data…. But protect it!): Common Cybersecurity knowledge levels, ISP data collection, Internet design, finding out what is known about you online, software terms and servicesTechnology and Computing Concepts: DNS, Cryptography (ciphers, hashing, encryption, SSL), Deep and Dark WebImpacts (What could my data do for me in the future?): What is Big Data, Machine Learning finds new music, Wearable technologies.Technology and Computing Concepts: AI vs ML, Supervised vs Unsupervised learning, Neural Networks, Recommender systems, Speech recognitionIn the pedagogy section for this course, in which best practices for teaching computing concepts are explored, you’ll learn how to apply Bloom’s taxonomy to create meaningful CS learning objectives, the importance of retrieval-based learning, to build learning activities with online simulators, and how to use “fun” books to teach computing.In terms of CSTA K-12 computer science standards, we’ll primarily cover learning objectives within the “impacts of computing” concept, while also including some within the “networks and the Internet” concepts and the “data and analysis” concept. Practices we cover include “fostering and inclusive computing culture”, “recognizing and defining computational problems”, and “communicating about computing”.",,Social Sciences,University of California San Diego,Enroll for Free,Teaching Impacts of Technology in K-12 Education Specialization,Beth Simon work for University of California San Diego,Subtitles: English
Survey Data Collection and Analytics Project (Capstone),https://www.coursera.org/learn/survey-data-capstone,,,"Frauke Kreuter, Ph.D.,Frederick Conrad, Ph.D.,James M Lepkowski,Richard Valliant, Ph.D.",14 hours,,,"The Capstone Project offers qualified learners to the opportunity to apply their knowledge by analyzing and comparing multiple data sources on the same topic. Students will develop a research question, access and analyze relevant data, and critically examine the quality of each data source. At the completion of this capstone, students will have demonstrated hands-on data analysis capability, evaluated the quality of different data sources using the Total Survey Error approach, involving at least some of the following: comparing weighted non-probability samples to data collected from probability samples, using sampling techniques to correct for coverage errors, and tracking and assess the ease of using an online questionnaire that you implement.",,Health,"University of Michigan,University of Maryland, College Park",Enroll for Free,Survey Data Collection and Analytics  Specialization,"Frauke Kreuter, Ph.D. work for University of Michigan, University of Maryland, College Park,Frederick Conrad, Ph.D. work for University of Michigan,James M Lepkowski work for University of Michigan,Richard Valliant, Ph.D. work for University of Maryland, College Park",Subtitles: English
Statistics for Data Science with Python,https://www.coursera.org/learn/statistics-for-data-science-python,4.6,"9,567","Murtaza Haider,Aije Egwaikhide",13 hours,,,"This Statistics for Data Science course is designed to introduce you to the basic principles of statistical methods and procedures used for data analysis. After completing this course you will have practical knowledge of crucial topics in statistics including. - data gathering, summarizing data using descriptive statistics, displaying and visualizing data, examining relationships between variables, probability distributions, expected values, hypothesis testing, introduction to ANOVA (analysis of variance), regression and correlation analysis. You will take a hands-on approach to statistical analysis using Python and Jupyter Notebooks – the tools of choice for Data Scientists and Data Analysts.  At the end of the course, you will complete a project to apply various concepts in the course to a Data Science problem involving a real-life inspired scenario and demonstrate an understanding of the foundational statistical thinking and reasoning. The focus is on developing a clear understanding of the different approaches for different data types, developing an intuitive understanding, making appropriate assessments of the proposed methods, using Python to analyze our data, and interpreting the output accurately. This course is suitable for a variety of professionals and students intending to start their journey in data and statistics-driven roles such as Data Scientists, Data Analysts, Business Analysts, Statisticians, and Researchers. It does not require any computer science or statistics background. We strongly recommend taking the Python for Data Science course before starting this course to get familiar with the Python programming language,. Jupyter notebooks, and libraries. An optional refresher on Python is also provided.After completing this course, a learner will be able to:✔Calculate and apply measures of central tendency and measures of dispersion to grouped and ungrouped data.✔Summarize, present, and visualize data in a way that is clear, concise, and provides a practical insight for non-statisticians needing the results.✔Identify appropriate hypothesis tests to use for common data sets.✔Conduct hypothesis tests, correlation tests, and regression analysis.✔Demonstrate proficiency in statistical analysis using Python and Jupyter Notebooks.",Probability And Statistics          Regression Analysis          Data Visualization (DataViz)          Statistical Hypothesis Testing          Basic Descriptive Statistics      ,Data Science,IBM,Enroll for Free,Data Science Fundamentals with Python and SQL Specialization,"Murtaza Haider work for IBM,Aije Egwaikhide work for IBM",English
Statistical Inference for Estimation in Data Science,https://www.coursera.org/learn/statistical-inference-for-estimation-in-data-science,,,Jem Corcoran,27 hours,Intermediate,Sequence in calculus up through Calculus II (preferably multivariate calculus) and some programming experience in R.,"Identify characteristics of “good” estimators and be able to compare competing estimators. Construct sound estimators using the techniques of maximum likelihood and method of moments estimation. Construct and interpret confidence intervals for one and two population means, one and two population proportions, and a population variance.",,Data Science,University of Colorado Boulder,Enroll for Free,Data Science Foundations: Statistical Inference Specialization,Jem Corcoran work for University of Colorado Boulder,Subtitles: English
SQL for Data Science with R,https://www.coursera.org/learn/sql-data-science-r,4,"2,470",Rav Ahuja,16 hours,Beginner,,"Create and access a database instance on cloud. Write basic SQL statements: CREATE, DROP, SELECT, INSERT, UPDATE, DELETE. Filter, sort, group results, use built-in functions, compose nested queries, access multiple tables. Access databases from Jupyter using R and SQL to query real-world datasets",Data Science          Select (Sql)          Relational Databases (RDBMS)          R Programming          Tables (Database)      ,Data Science,IBM,Enroll for Free,,"Rav Ahuja work for Coursera, IBM",English
SQL for Data Science,https://www.coursera.org/learn/sql-for-data-science,4.6,"358,409",Sadie St. Lawrence,14 hours,Beginner,,"Identify a subset of data needed from a column or set of columns and write a SQL query to limit to those results. Use SQL commands to filter, sort, and summarize data. Create an analysis table from multiple queries using the UNION operator. Manipulate strings, dates, &amp; numeric data using functions to integrate data from different sources into fields with the correct format for analysis.",Data Science          Data Analysis          Sqlite          SQL      ,Data Science,"University of California, Davis",Enroll for Free,Learn SQL Basics for Data Science Specialization,"Sadie St. Lawrence work for University of California, Davis","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
SQL for Data Science Capstone Project,https://www.coursera.org/learn/sql-data-science-capstone,4.1,"18,019",Don Noxon,35 hours,Intermediate,,Develop a project proposal and select your data. Perform descriptive statistics as part of your exploratory analysis. Develop metrics and perform advanced techniques in SQL. Present your findings and make recommendations,Presentation Skills          Data Analysis          SQL          creating metrics          Exploratory Data Analysis      ,Data Science,"University of California, Davis",Enroll for Free,Learn SQL Basics for Data Science Specialization,"Don Noxon work for University of California, Davis","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Databases and SQL for Data Science with Python,https://www.coursera.org/learn/sql-data-science,4.6,"220,195","Rav Ahuja,Hima Vasudevan",20 hours,Beginner,,"Create and access a database instance on cloud. Write basic SQL statements: CREATE, DROP, SELECT, INSERT, UPDATE, DELETE. Filter, sort, group results, use built-in functions, access multiple tables. Access databases from Jupyter using Python and work with real world datasets",Cloud Databases          Python Programming          Ipython          Relational Database Management System (RDBMS)          SQL      ,Data Science,IBM,Enroll for Free,,"Rav Ahuja work for Coursera, IBM,Hima Vasudevan work for IBM","English, Arabic, Persian"
Spatial Data Science and Applications,https://www.coursera.org/learn/spatial-data-science,4.4,"18,504",Joon Heo,12 hours,Intermediate,,"Spatial (map) is considered as a core infrastructure of modern IT world, which is substantiated by business transactions of major IT companies such as Apple, Google, Microsoft, Amazon, Intel, and Uber, and even motor companies such as Audi, BMW, and Mercedes. Consequently, they are bound to hire more and more spatial data scientists. Based on such business trend, this course is designed to present a firm understanding of spatial data science to the learners, who would have a basic knowledge of data science and data analysis, and eventually to make their expertise differentiated from other nominal data scientists and data analysts. Additionally, this course could make learners realize the value of spatial big data and the power of open source software's to deal with spatial data science problems. This course will start with defining spatial data science and answering why spatial is special from three different perspectives - business, technology, and data in the first week. In the second week, four disciplines related to spatial data science - GIS, DBMS, Data Analytics, and Big Data Systems, and the related open source software's - QGIS, PostgreSQL, PostGIS, R, and Hadoop tools are introduced together. During the third, fourth, and fifth weeks, you will learn the four disciplines one by one from the principle to applications. In the final week, five real world problems and the corresponding solutions are presented with step-by-step procedures in environment of open source software's.",Spatial Analysis          Qgis          Big Data          Geographic Information System (GIS)      ,Data Science,Yonsei University,Enroll for Free,,Joon Heo work for Yonsei University,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Social Media Data Analytics,https://www.coursera.org/learn/social-media-data-analytics,4.1,"35,265",Chirag Shah,13 hours,Intermediate,,"Learner Outcomes: After taking this course, you will be able to:. - Utilize various Application Programming Interface (API) services to collect data from different social media sources such as YouTube, Twitter, and Flickr.- Process the collected data - primarily structured - using methods involving correlation, regression, and classification to derive insights about the sources and people who generated that data.- Analyze unstructured data - primarily textual comments - for sentiments expressed in them.- Use different tools for collecting, analyzing, and exploring social media data for research and development purposes.Sample Learner Story: Data analyst wanting to leverage social media data.Isabella is a Data Analyst working as a consultant for a multinational corporation. She has experience working with Web analysis tools as well as marketing data. She wants to now expand into social media arena, trying to leverage the vast amounts of data available through various social media channels. Specifically, she wants to see how their clients, partners, and competitors view their products/services and talk about them. She hopes to build a new workflow of data analytics that incorporates traditional data processing using Web and marketing tools, as well as newer methods of using social media data.Sample Job Roles requiring these skills: - Social Media Analyst- Web Analyst- Data Analyst- Marketing and Public Relations Final Project Deliverable/ Artifact: The course will have a series of small assignments or mini-projects that involve data collection, analysis, and presentation involving various social media sources using the techniques learned in the class.The course was developed by Dr. Chirag Shah while he was a faculty member at Rutgers University. He is currently a faculty member at University of Washington.",Python Programming          Statistical Analysis          Sentiment Analysis          R Programming      ,Data Science,University of Washington,Enroll for Free,,"Chirag Shah work for University of Washington, Rutgers the State University of New Jersey","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Serverless Data Processing with Dataflow: Foundations,https://www.coursera.org/learn/serverless-data-processing-with-dataflow-foundations,4.1,"2,583",Google Cloud Training,3 hours,Intermediate,,"This course is part 1 of a 3-course series on Serverless Data Processing with Dataflow. In this first course, we start with a refresher of what Apache Beam is and its relationship with Dataflow. Next, we talk about the Apache Beam vision and the benefits of the Beam Portability framework. The Beam Portability framework achieves the vision that a developer can use their favorite programming language with their preferred execution backend. We then show you how Dataflow allows you to separate compute and storage while saving money, and how identity, access, and management tools interact with your Dataflow pipelines. Lastly, we look at how to implement the right security model for your use case on Dataflow.  Prerequisites:The Serverless Data Processing with Dataflow course series builds on the concepts covered in the Data Engineering specialization. We recommend the following prerequisite courses:(i)Building batch data pipelines on Google Cloud : covers core Dataflow principles(ii)Building Resilient Streaming Analytics Systems on Google Cloud : covers streaming basics concepts like windowing, triggers, and watermarks &gt;&gt;&gt; By enrolling in this course you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service &lt;&lt;&lt;",,Data Science,Google Cloud,Enroll for Free,Serverless Data Processing with Dataflow Specialization,Google Cloud Training work for Google Cloud,Subtitles: English
Serverless Data Processing with Dataflow: Operations,https://www.coursera.org/learn/serverless-data-processing-with-dataflow-operations,,,Google Cloud Training,10 hours,Advanced,,"Perform monitoring, troubleshooting, testing and CI/CD on Dataflow pipelines. Deploy Dataflow pipelines with reliability in mind to maximize stability for your data processing platform",,Data Science,Google Cloud,Enroll for Free,Serverless Data Processing with Dataflow Specialization,Google Cloud Training work for Google Cloud,Subtitles: English
Security and Privacy for Big Data - Part 1,https://www.coursera.org/learn/security-privacy-big-data,4.6,"12,139","Enrique Barra,Fabian Garcia Pastor",1 hour,Beginner,,Recognize all security related issues in big data systems and projects. Define cryptographic principles and mechanisms to manage access controls in your Big Data system. Explain security risks and challenges for Big Data system.,,Information Technology,EIT Digital ,Enroll for Free,,"Enrique Barra work for EIT Digital ,Fabian Garcia Pastor work for EIT Digital ","Subtitles: French, Portuguese (European), Russian, English, Spanish"
Security and Privacy for Big Data - Part 2,https://www.coursera.org/learn/security-privacy-big-data-protection,4.7,"6,166","Enrique Barra,Fabian Garcia Pastor",1 hour,Beginner,,"Understand what data protection is and why this is important. Explain what personal data is, and know the essential facts about the GDPR, what the GDPR has changed compared to previous data protection law. Know privacy risks arising from Big Data applications and methods which reduce or prevent privacy risks of data processing activities.  Know concepts like anonymization and pseudonymization, k-anonymity, differential privacy, secure multiparty computation, and homomorphic encryption.",,Information Technology,EIT Digital ,Enroll for Free,,"Enrique Barra work for EIT Digital ,Fabian Garcia Pastor work for EIT Digital ","Subtitles: French, Portuguese (European), Russian, English, Spanish"
Big Data Analysis with Scala and Spark,https://www.coursera.org/learn/scala-spark-big-data,4.7,"90,075",Prof. Heather Miller,28 hours,,,"Manipulating big data distributed over a cluster using functional concepts is rampant in industry, and is arguably one of the first widespread industrial uses of functional ideas. This is evidenced by the popularity of MapReduce and Hadoop, and most recently Apache Spark, a fast, in-memory distributed collections framework written in Scala. In this course, we'll see how the data parallel paradigm can be extended to the distributed case, using Spark throughout. We'll cover Spark's programming model in detail, being careful to understand how and when it differs from familiar programming models, like shared-memory parallel collections or sequential Scala collections. Through hands-on examples in Spark and Scala, we'll learn when important issues related to distribution like latency and network communication should be considered and how they can be addressed effectively for improved performance. Learning Outcomes. By the end of this course you will be able to:- read data from persistent storage and load it into Apache Spark,- manipulate data with Spark and Scala,- express algorithms for data analysis in a functional style, - recognize how to avoid shuffles and recomputation in Spark,Recommended background: You should have at least one year programming experience. Proficiency with Java or C# is ideal, but experience with other languages such as C/C++, Python, Javascript or Ruby is also sufficient. You should have some familiarity using the command line. This course is intended to be taken after Parallel Programming: https://www.coursera.org/learn/parprog1.",Scala Programming          Big Data          Apache Spark          SQL      ,Computer Science,École Polytechnique Fédérale de Lausanne,Enroll for Free,Functional Programming in Scala Specialization,"Prof. Heather Miller work for École Polytechnique Fédérale de Lausanne, CONTEXT University [Testing]","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Population Health: Responsible Data Analysis,https://www.coursera.org/learn/responsible-data-analysis,4.6,"3,351","Mar Rodriguez Girondo,Jelle Goeman,Saskia le Cessie",21 hours,Beginner,,Knows (the value of) all aspects of data management and acknowledge the importance of initial data analysis. Knows the pros and cons of statistical methods and can choose the appropriate data analysis approach in common. health related problems.  Is able to interpret statistical results. and to draw responsible conclusions.,R Programming          Data Analysis          Regression Analysis          Data Reporting          Statistical Data      ,Data Science,Universiteit Leiden,Enroll for Free,,"Mar Rodriguez Girondo work for Universiteit Leiden,Jelle Goeman work for Universiteit Leiden,Saskia le Cessie work for Universiteit Leiden",English
Relational Database Administration (DBA),https://www.coursera.org/learn/relational-database-administration,,,"Ramesh Sannareddy,Rav Ahuja",17 hours,Beginner,Computer and IT literacy. ,Describe common database administration tasks.  Identify server objects.  Configure a database server. Back up and restore databases,Database (DBMS)          Database Servers          Relational Database          Database Security          database administration      ,Information Technology,IBM,Enroll for Free,IBM Data Engineering Professional Certificate,"Ramesh Sannareddy work for IBM,Rav Ahuja work for Coursera, IBM",English
Relational database systems,https://www.coursera.org/learn/relational-database,4.4,"19,169",María del Pilar Ángeles,15 hours,Intermediate,,"Welcome to the specialization course Relational Database Systems. This course will be completed on six weeks, it will be supported with videos and various documents that will allow you to learn in a very simple way how several types of information systems and databases are available to solve different problems and needs of the companies.  Objective:A learner will be able to design, test, and implement analytical, transactional or NoSQL database systems according to business requirements by programming reliable, scalable and maintainable applications and resources using SQL and Hadoop ecosystem.Programming languages:For course 1 you will use the MYSQL language.Software to download:MySQLWorkbench In case you have a Mac / IOS operating system you will need to use a virtual Machine (VirtualBox, Vmware).",Database (DB) Design          Entity          Relational Database          SQL      ,Data Science,Universidad Nacional Autónoma de México,Enroll for Free,Database systems Specialization,María del Pilar Ángeles work for Universidad Nacional Autónoma de México,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Science in Real Life,https://www.coursera.org/learn/real-life-data-science,4.4,"47,030","Brian Caffo, PhD,Jeff Leek, PhD,Roger D. Peng, PhD",7 hours,,,Identify strengths and weaknesses in experimental designs. Learn novel solutions for managing data pulls. Describe common pitfalls in communicating data analyses. Understand a typical day in the life of a data analysis manager,Statistics          Data Science          Data Analysis          Data Management      ,Data Science,Johns Hopkins University,Enroll for Free,Executive Data Science Specialization,"Brian Caffo, PhD work for Johns Hopkins University,Jeff Leek, PhD work for Johns Hopkins University,Roger D. Peng, PhD work for Johns Hopkins University","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Building Data Visualization Tools,https://www.coursera.org/learn/r-data-visualization,3.9,"11,369","Roger D. Peng, PhD,Brooke Anderson",13 hours,Intermediate,,"The data science revolution has produced reams of new data from a wide variety of new sources. These new datasets are being used to answer new questions in way never before conceived. Visualization remains one of the most powerful ways draw conclusions from data, but the influx of new data types requires the development of new visualization techniques and building blocks. This course provides you with the skills for creating those new visualization building blocks. We focus on the ggplot2 framework and describe how to use and extend the system to suit the specific needs of your organization or team. Upon completing this course, learners will be able to build the tools needed to visualize a wide variety of data types and will have the fundamentals needed to address new data types as they come about.",Mapping          Ggplot2          Data Visualization (DataViz)          R Programming      ,Data Science,Johns Hopkins University,Enroll for Free,Mastering Software Development in R Specialization,"Roger D. Peng, PhD work for Johns Hopkins University,Brooke Anderson work for Johns Hopkins University","Arabic, French, Portuguese (European), Chinese (Simplified), Vietnamese, German, Russian, English, Spanish"
Qualitative Data Analysis with MAXQDA Software,https://www.coursera.org/learn/qualitative-data-analysis-with-maxqda-software,4.6,"2,209","Karen Andes, PhD",16 hours,Intermediate,,"This course will introduce you to MAXQDA software for easier data analysis during the qualitative research process. You'll explore how to do memos, variables, segmentation, coding, and data reduction techniques all in this course!",,Health,Emory University,Enroll for Free,Qualitative Research Design and Methods for Public Health Specialization,"Karen Andes, PhD work for Emory University","Subtitles: French, Portuguese (European), Russian, English, Spanish"
Qualitative Data Collection Methods,https://www.coursera.org/learn/qualitative-data-collection-methods,4.9,"2,607","Karen Andes, PhD",14 hours,Beginner,,"This course presents a detailed overview of qualitative methods of data collection, including observation, interviews, and focus group discussions. We will start with an in-depth overview of each method, explore how to plan for data collection, including developing data collection guides, and discuss techniques for managing data collection. For observation, we’ll focus on approaches with low levels of interaction with people and the environment (e.g. non-participant observation). We’ll talk about note-taking strategies, the use of observation guides, and approaches to writing up fieldnotes. For interviews, we’ll discuss development of effective question guides and demonstrate interviewing techniques. For focus group discussions, we’ll highlight moderation strategies and how to integrate activities into question guides to promote interaction in the group setting. Finally, we’ll briefly discuss the transcription process for recorded interviews and focus group discussions. Learners of this course will not only be able to put what they learn into practice, but they'll also develop a portfolio of qualitative research materials for career advancement.",,Health,Emory University,Enroll for Free,Qualitative Research Design and Methods for Public Health Specialization,"Karen Andes, PhD work for Emory University","Subtitles: French, Portuguese (European), Russian, English, Spanish"
"Python Scripting: Files, Inheritance, and Databases",https://www.coursera.org/learn/python-scripting-files-inheritance-databases,,,Aspen Olmsted,13 hours,Beginner,"Learners should have completed the previous course in the specialization: https://coursera.org/learn/python-scripting-dates-classes-collections



",Develop computer programs that utilize classes andobjects to solve business and mathematical problems,inheritance (object-oriented programming)          Python Programming          Numpy          Persist      ,Computer Science,LearnQuest,Enroll for Free,Python Scripting for DevOps Specialization,Aspen Olmsted work for LearnQuest,English
Python Project for Data Engineering,https://www.coursera.org/learn/python-project-for-data-engineering,4.6,"6,453","Ramesh Sannareddy,Joseph Santarcangelo",6 hours,Intermediate,,"Demonstrate your Skills in Python - the language of choice for Data Engineering. Implement Webscraping, and use APIs to extract data in Python. Play the role of a Data Engineer working on a real project to extract, transform and load data using Jupyter notebook and Watson Studio","Extraction, Transformation And Loading (ETL)          Python Programming          Information Engineering          Web Scraping      ",Information Technology,IBM,Enroll for Free,,"Ramesh Sannareddy work for IBM,Joseph Santarcangelo work for Coursera, IBM",English
Python Project for Data Science,https://www.coursera.org/learn/python-project-for-data-science,4.5,"41,061","Azim Hirjani,Joseph Santarcangelo",6 hours,Intermediate,,"Demonstrate your Skills in Python - the language of choice for Data Science and Data Analysis. Apply Python fundamentals, Python data structures, and working with data in Python. Play the role of a Data Scientist / Data Anlayst working on a real project. Build a dashboard using Python and popular Python libraries using Jupyter notebook",Data Science          Python Programming          Ipython          Data Analysis          Pandas      ,Data Science,IBM,Enroll for Free,,"Azim Hirjani work for IBM,Joseph Santarcangelo work for Coursera, IBM",English
Python per la Data Science,https://www.coursera.org/learn/python-per-la-data-science,,,Carlo Sansone,18 hours,Intermediate,Il corso è pensato per quanti abbiano già come prerequisito la conoscenza di Python e aspirano a diventare Data Scientist. ,"Imparare a manipolare e visualizzare i dati python, tramite l'uso di alcune librerie molto diffuse. Imparare a instanziare, addestrare ed utilizzare reti neurali (feedforward e ricorrenti) usando scikit learn. Imparare ad usare i tool Keras e PyTorch per il deep learning. Instanziare e utilizzare una rete encoder/decoder per la segmentazione semantica e come usare reti deep pre-addestrate per la object detection",Acquisire raccogliere organizzare elaborare e modellare i dati          Problem solving proattivo          Scrittura di codici in maniera corretta ed efficace          Analizzare dati strutturati e non strutturati      ,Data Science,Università di Napoli Federico II,Enroll for Free,Data Science con Python e R Specialization,Carlo Sansone work for Università di Napoli Federico II,Italian
Using Python to Access Web Data,https://www.coursera.org/learn/python-network-data,4.8,"529,528",Charles Russell Severance,19 hours,,,Use regular expressions to extract data from strings. Understand the protocols web browsers use to retrieve documents and web apps. Retrieve data from websites and APIs using Python. Work with XML (eXtensible Markup Language) data,Json          Xml          Python Programming          Web Scraping      ,Computer Science,University of Michigan,Enroll for Free,Python for Everybody Specialization,Charles Russell Severance work for University of Michigan,"Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Data Visualization with Python,https://www.coursera.org/learn/python-for-data-visualization,4.5,"137,200",Saishruthi Swaminathan,17 hours,Intermediate,,Describe the importance of data visualization. Relate the history of Matplotlib and its architecture. Apply Matplotlib to create plots using Jupyter notebooks. Discover how to read CSV files into a Pandas DataFrame; process and manipulate the data in the DataFrame; and generate line plots using Matplotlib.,Python Programming          Data Virtualization          Plotly          Matplotlib          Data Visualization (DataViz)      ,Data Science,IBM,Enroll for Free,,Saishruthi Swaminathan work for IBM,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish, Persian"
"Python for Data Science, AI & Development",https://www.coursera.org/learn/python-for-applied-data-science-ai,4.6,"348,943",Joseph Santarcangelo,20 hours,Beginner,,"Build your first program in Python. Learn about Python fundamentals, Python data structures, and working with data in Python. Become familiar with key Python functions, objects, and classes. Gain career skills in one of the world’s most popular programming languages",Data Science          Python Programming          Data Analysis          Pandas          Numpy      ,Data Science,IBM,Enroll for Free,,"Joseph Santarcangelo work for Coursera, IBM","English, Arabic"
Using Databases with Python,https://www.coursera.org/learn/python-databases,4.8,"396,073",Charles Russell Severance,15 hours,,,"Use the Create, Read, Update, and Delete operations to manage databases. Explain the basics of Object Oriented Python. Understand how data is stored across multiple tables in a database. Utilize the Google Maps API to visualize data",Python Programming          Database (DBMS)          Sqlite          SQL      ,Computer Science,University of Michigan,Enroll for Free,Python for Everybody Specialization,Charles Russell Severance work for University of Michigan,"Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Python استخدام قواعد البيانات مع,https://www.coursera.org/learn/python-databases-ar,,,Charles Russell Severance,15 hours,,,استخدم عمليات الإنشاء والقراءة والتحديث والحذف لإدارة قواعد البيانات. اشرح أساسيات Object Oriented Python. تعرف على كيفية تخزين البيانات في جداول متعددة في قاعدة بيانات. استخدم Google Maps API لتصور البيانات,Recursively Enumerable Set          Display Devices          Euler'S Totient Function          Internality      ,Computer Science,University of Michigan,Enroll for Free,,Charles Russell Severance work for University of Michigan,"Arabic, French, Portuguese (Brazilian), Korean, Russian, English, Spanish"
Data Processing Using Python,https://www.coursera.org/learn/python-data-processing,4.1,"51,360",ZHANG Li,29 hours,Beginner,,"This course (The English copy of ""用Python玩转数据"" &lt;https://www.coursera.org/learn/hipython/home/welcome&gt;). is mainly for non-computer majors. It starts with the basic syntax of Python, to how to acquire data in Python locally and from network, to how to present data, then to how to conduct basic and advanced statistic analysis and visualization of data, and finally to how to design a simple GUI to present and process data, advancing level by level.  This course, as a whole, based on Finance data and through the establishment of popular cases one after another, enables learners to more vividly feel the simplicity, elegance, and robustness of Python. Also, it discusses the fast, convenient and efficient data processing capacity of Python in humanities and social sciences fields like literature, sociology and journalism and science and engineering fields like mathematics and biology, in addition to business fields. Similarly, it may also be flexibly applied into other fields.The course has been updated. Updates in the new version are : 1) the whole course has moved from Python 2.x to Python 3.x 2) Added manual webpage fetching and parsing. Web API is also added. 3) Improve the content order and enrich details of some content especially for some practice projects.Note: videos are in Chinese (Simplified) with English subtitles. All other materials are in English.",Python Programming          Numpy          Pandas          Wxpython      ,Computer Science,Nanjing University,Enroll for Free,,ZHANG Li work for Nanjing University,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
"Capstone: Retrieving, Processing, and Visualizing Data with Python",https://www.coursera.org/learn/python-data-visualization,4.7,"210,393",Charles Russell Severance,9 hours,,,Make use of unicode characters and strings. Understand the basics of building a search engine. Select and process the data of your choice. Create email data visualizations,Data Analysis          Python Programming          Database (DBMS)          Data Visualization (DataViz)      ,Data Science,University of Michigan,Enroll for Free,Python for Everybody Specialization,Charles Russell Severance work for University of Michigan,"Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Python Data Structures,https://www.coursera.org/learn/python-data,4.9,"803,936",Charles Russell Severance,19 hours,,,Explain the principles of data structures &amp; how they are used. Create programs that are able to read and write data from files. Store data as key/value pairs using Python dictionaries. Accomplish multi-step tasks like sorting or looping using tuples,Python Syntax And Semantics          Data Structure          Tuple          Python Programming      ,Computer Science,University of Michigan,Enroll for Free,Python for Everybody Specialization,Charles Russell Severance work for University of Michigan,"Arabic, French, Portuguese (European), Chinese (Simplified), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Promote the Ethical Use of Data-Driven Technologies,https://www.coursera.org/learn/promote-ethical-data-driven-technologies,4.6,"5,805","Renée Cummings,Aaron Hui,Megan Smith Branch,Eleanor 'Nell' Watson,Tania De Gasperis",21 hours,Beginner,General business knowledge. ,Distinguish between artificial intelligence and data science concepts. Protect data privacy with ethical and legal standards.  Assess the potential risks of bias. Advocate for the importance of risk evaluation in emerging technologies.,,Data Science,CertNexus,Enroll for Free,CertNexus Certified Ethical Emerging Technologist Professional Certificate,"Renée Cummings work for CertNexus,Aaron Hui work for CertNexus,Megan Smith Branch work for CertNexus,Eleanor 'Nell' Watson work for CertNexus,Tania De Gasperis work for CertNexus","Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Process Data from Dirty to Clean,https://www.coursera.org/learn/process-data,4.8,"95,625",Google Career Certificates,22 hours,Beginner,No prior experience with spreadsheets or data analytics is required. All you need is high-school level math and a curiosity about how things work.,Define data integrity with reference to types of integrity and risk to data integrity. Apply basic SQL functions for use in cleaning string variables in a database. Develop basic SQL queries for use on databases. Describe the process involved in verifying the results of cleaning data,Spreadsheet          Data Cleansing          Sample Size Determination          SQL          Data Integrity      ,Data Science,Google,Enroll for Free,Google Data Analytics Professional Certificate,Google Career Certificates work for Google,English
Probability Theory: Foundation for Data Science,https://www.coursera.org/learn/probability-theory-foundation-for-data-science,4.2,"5,228",Anne Dougherty,48 hours,Intermediate,Sequence in calculus up through Calculus II (preferably multivariate calculus) and some programming experience in R.,Explain why probability is important to statistics and data science. See the relationship between conditional and independent events in a statistical experiment. Calculate the expectation and variance of several random variables and develop some intuition.,Probability          central limit theorem          continuous random variables          Bayes' Theorem          discrete random variables      ,Data Science,University of Colorado Boulder,Enroll for Free,Data Science Foundations: Statistical Inference Specialization,Anne Dougherty work for University of Colorado Boulder,English
Privacy Law and Data Protection,https://www.coursera.org/learn/privacy-law-data-protection,4.8,"13,470",Lauren Steinfeld,12 hours,,,Provide methods for protecting privacy using the Fair Information Principles. Identify the laws and regulations that pertain to data protection. Identify the privacy obligations that can apply to complex organizations. Identify strategies for managing compliance issues related to privacy laws and data protection,Information Privacy          Risk Management          Data Management          Privacy Compliance      ,Business,University of Pennsylvania,Enroll for Free,Regulatory Compliance Specialization,Lauren Steinfeld work for University of Pennsylvania,"French, Portuguese (European), Russian, English, Spanish, Persian"
Preparing for the Google Cloud Professional Data Engineer Exam,https://www.coursera.org/learn/preparing-cloud-professional-data-engineer-exam,4.6,"35,423",Google Cloud Training,9 hours,Advanced,,"Position the Professional Data Engineer Certification. Provide information, tips, and advice on taking the exam. Review each section of the exam covering highest-level concepts to indicate skill gaps/areas of study. Connect candidates to appropriate target learning",,Information Technology,Google Cloud,Enroll for Free,,Google Cloud Training work for Google Cloud,Subtitles: English
Getting Started with SAS Visual Analytics ,https://www.coursera.org/learn/preparing-data-sas-va,4.7,"20,252",Nicole Ball,5 hours,Beginner,,"In this course, you learn more about SAS Visual Analytics and the SAS Viya platform, how to access and investigate data in SAS Visual Analytics, and how to prepare data for analysis using SAS Data Studio.",,Data Science,SAS,Enroll for Free,SAS Visual Business Analytics Professional Certificate,Nicole Ball work for SAS,Subtitles: English
Predictive Analytics and Data Mining,https://www.coursera.org/learn/predictive-analytics-data-mining,4.4,"9,498",Sridhar Seshadri,24 hours,Intermediate,,"This course introduces students to the science of business analytics while casting a keen eye toward the artful use of numbers found in the digital space. The goal is to provide businesses and managers with the foundation needed to apply data analytics to real-world challenges they confront daily in their professional lives. Students will learn to identify the ideal analytic tool for their specific needs; understand valid and reliable ways to collect, analyze, and visualize data; and utilize data in decision making for their agencies, organizations or clients.",Predictive Analytics          Decision-Making Software          Geodemographic Segmentation          Validated Learning      ,Business,University of Illinois at Urbana-Champaign,Enroll for Free,,Sridhar Seshadri work for University of Illinois at Urbana-Champaign,"French, Portuguese (European), Russian, English, Spanish"
Prediction Models with Sports Data,https://www.coursera.org/learn/prediction-models-sports-data,,,"Youngho Park,Stefan Szymanski",33 hours,,,"In this course the learner will be shown how to generate forecasts of game results in professional sports using Python. The main emphasis of the course is on teaching the method of logistic regression as a way of modeling game results, using data on team expenditures. The learner is taken through the process of modeling past results, and then using the model to forecast the outcome games not yet played. The course will show the learner how to evaluate the reliability of a model using data on betting odds. The analysis is applied first to the English Premier League, then the NBA and NHL. The course also provides an overview of the relationship between data analytics and gambling, its history and the social issues that arise in relation to sports betting, including the personal risks.",,Data Science,University of Michigan,Enroll for Free,Sports Performance Analytics Specialization,"Youngho Park work for University of Michigan,Stefan Szymanski work for University of Michigan",Subtitles: English
Tools for Data Science,https://www.coursera.org/learn/open-source-tools-for-data-science,4.5,"241,729","Aije Egwaikhide,Svetlana Levitan,Romeo Kienzler",19 hours,Beginner,,"Describe the languages, tools, and data used by data scientists, including IBM tools focused on data science.  Describe the features of Jupyter Notebook and RStudio IDE that make them popular for data science projects. Create and manage source code for data science in GitHub. Explain how IBM Watson Studio and other IBM data science tools can be used by data scientists.",Data Science          Github          Python Programming          Jupyter notebooks          Rstudio      ,Data Science,IBM,Enroll for Free,,"Aije Egwaikhide work for IBM,Svetlana Levitan work for IBM,Romeo Kienzler work for IBM","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish, Persian"
NoSQL systems,https://www.coursera.org/learn/nosql-databases,4.3,"9,529",María del Pilar Ángeles,9 hours,Intermediate,,"Welcome to the specialization course of NoSQL Systems.  This course will be completed on six weeks, it will be supported with videos and exercises that will allow you to identify the differences between the relational and NoSQL databases. As part of these alternative technologies the student will learn the main characteristics and how to implement the typical NoSQL databases, such as Key-value, columnar, document and graph. Let's start!After completing this course, a learner will be able to●	Identify what type of NoSQL database to implement based on business requirements (key-value, document, full text, graph, etc.)●	Apply NoSQL data modeling from application specific queries●	Use Atomic Aggregates and denormalization as data modelling techniques to optimize query processingSoftware to download:MongoDBNeo4jSAPIQCassandraIn case you have a Mac / IOS operating system you will need to use a virtual Machine (VirtualBox, Vmware).",Document Warehouse          Super Column      ,Data Science,Universidad Nacional Autónoma de México,Enroll for Free,Database systems Specialization,María del Pilar Ángeles work for Universidad Nacional Autónoma de México,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Privacy Fundamentals,https://www.coursera.org/learn/northeastern-data-privacy,4.8,"8,168","Woodrow Hartzog,Todd Relaford",9 hours,Beginner,,Identify foundational understanding of digital age privacy concepts and theories. Identify privacy implications of modern digital technology. Identify the rules and frameworks for data privacy in the age of technology,4th Amendment          information ethics          Biometrics          Information Privacy          Algorithms      ,Information Technology,Northeastern University ,Enroll for Free,,"Woodrow Hartzog work for Northeastern University ,Todd Relaford work for Northeastern University ","French, Portuguese (European), Russian, English, Spanish"
Network Security & Database Vulnerabilities ,https://www.coursera.org/learn/network-security-database-vulnerabilities,4.6,"41,248",IBM Security Learning Services,14 hours,Beginner,,"Understand network basics around the TCP/IP and OSI Models.  Recount DNS, DHCP, Switching and Routing concepts. Understand IP Addressing, Network Address Translation and Packet Sniffing. Describe the structures and vulnerabilities of key databases for cybersecurity including SQL, Couch, Oracle and MongoDB.",database vulnerabilities          Network Security          Sql Injection          Cybersecurity          networking basics      ,Information Technology,IBM,Enroll for Free,,IBM Security Learning Services work for IBM,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Exploring NCAA Data with BigQuery,https://www.coursera.org/learn/ncaa-data-bigquery,,,Google Cloud Training,45 hours,Beginner,,"BigQuery is Google's fully managed, NoOps, low-cost analytics database. With BigQuery you can query terabytes and terabytes of data without managing infrastructure or needing a database administrator. BigQuery uses SQL and takes advantage of the pay-as-you-go model. BigQuery allows you to focus on analyzing data to find meaningful insights. We have a newly available dataset for NCAA Basketball games, teams, and players. The game data covers play-by-play and box scores back to 2009, as well as final scores back to 1996. Additional data about wins and losses goes back to the 1894-5 season in some teams' cases.In this Google Cloud Lab, we will find and query the NCAA dataset using BigQuery.Note: you will have timed access to the online environment. You will need to complete the lab within the allotted time.",Queries          Bigquery          Data Sets          Sports Analysis      ,Data Science,Google Cloud,Enroll,,Google Cloud Training work for Google Cloud,English
Dealing With Missing Data,https://www.coursera.org/learn/missing-data,3.8,"10,056","Richard Valliant, Ph.D.",18 hours,,,"This course will cover the steps used in weighting sample surveys, including methods for adjusting for nonresponse and using data external to the survey for calibration. Among the techniques discussed are adjustments using estimated response propensities, poststratification, raking, and general regression estimation. Alternative techniques for imputing values for missing items will be discussed. For both weighting and imputation, the capabilities of different statistical software packages will be covered, including R®, Stata®, and SAS®.",,Data Science,"University of Maryland, College Park",Enroll for Free,Survey Data Collection and Analytics  Specialization,"Richard Valliant, Ph.D. work for University of Maryland, College Park",Subtitles: English
Foundations of mining non-structured medical data,https://www.coursera.org/learn/mining-medical-data,4,"2,362","Alejandro Rodríguez González,Consuelo Gonzalo-Martín,Ernestina Menasalvas",7 hours,Beginner,,"The goal of this course is to understand the foundations of Big Data and the data that is being generated in the health domain and how the use of technology would help to integrate and exploit all those data to extract meaningful information that can be later used in different sectors of the health domain from physicians to management, from patients to caregivers, etc.  The course offers a high-level perspective of the importance of the medical context within the European context, the types of data that are managed in the health (clinical) context, the challenges to be addressed in the mining of unstructured medical data (text and image) as well as the opportunities from the analytical point of view with an introduction to the basics of data analytics field.",,Data Science,EIT Digital ,Enroll for Free,,"Alejandro Rodríguez González work for EIT Digital ,Consuelo Gonzalo-Martín work for EIT Digital ,Ernestina Menasalvas work for EIT Digital ",Subtitles: English
Measurement – Turning Concepts into Data,https://www.coursera.org/learn/measurement-turning-concepts-data,4.8,,"Jennifer Bachner, PhD",11 hours,Beginner,,"This course provides a framework for how analysts can create and evaluate quantitative measures. Consider the many tricky concepts that are often of interest to analysts, such as health, educational attainment and trust in government. This course will explore various approaches for quantifying these concepts. The course begins with an overview of the different levels of measurement and ways to transform variables. We’ll then discuss how to construct and build a measurement model. We’ll next examine surveys, as they are one of the most frequently used measurement tools. As part of this discussion, we’ll cover survey sampling, design and evaluation. Lastly, we’ll consider different ways to judge the quality of a measure, such as by its level of reliability or validity. By the end of this course, you should be able to develop and critically assess measures for concepts worth study. After all, a good analysis is built on good measures.",Survey Design          Statistical Analysis          Validity          Measurement      ,Data Science,Johns Hopkins University,Enroll for Free,Data Literacy Specialization,"Jennifer Bachner, PhD work for Johns Hopkins University",English
"Managing, Describing, and Analyzing Data",https://www.coursera.org/learn/managing-describing-analyzing-data,4.3,"2,170",Wendy Martin,17 hours,Beginner,,Calculate descriptive statistics and create graphical representations using R software. Solve problems and make decisions using probability distributions. Explore the basics of sampling and sampling distributions with respect to statistical inference. Classify types of data with scales of measurement,analyzing data          describing data          using R          graphing data      ,Data Science,University of Colorado Boulder,Enroll for Free,,Wendy Martin work for University of Colorado Boulder,English
Managing Data Analysis,https://www.coursera.org/learn/managing-data-analysis,4.6,"61,583","Jeff Leek, PhD,Brian Caffo, PhD,Roger D. Peng, PhD",9 hours,,,Differentiate between various types of data pulls. Describe the basic data analysis iteration. Explore datasets to determine if data is appropriate for a project. Use statistical findings to create convincing data analysis presentations,Data Analysis          Communication          Interpretation          Exploratory Data Analysis      ,Business,Johns Hopkins University,Enroll for Free,Executive Data Science Specialization,"Jeff Leek, PhD work for Johns Hopkins University,Brian Caffo, PhD work for Johns Hopkins University,Roger D. Peng, PhD work for Johns Hopkins University","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish, Japanese"
Machine Learning e Data Mining in R,https://www.coursera.org/learn/machine-learning-data-mining-con-r,,,"Antonio Lepore,Biagio Palumbo,Carlo Sansone",31 hours,Intermediate,,"Importare, manipolare e visualizzare dati mediante R e i pacchetti inclusi in tidyverse come dplyr e ggplot2. Riconoscere e risolvere in R, mediante i pacchetti aggiuntivi leaps, glmnet, pls, problemi di apprendimento supervisionato e non supervisionato. Comprendere le differenze tra reti neurali artificiali di tipo shallow e deep",Pacchetti R: dplyr ggplot2 laps glmnet pls          Reti neurali artificiali di tipo shallow e deep          Apprendimento supervisionato e non supervisionato      ,Data Science,Università di Napoli Federico II,Enroll for Free,Data Science con Python e R Specialization,"Antonio Lepore work for Università di Napoli Federico II,Biagio Palumbo work for Università di Napoli Federico II,Carlo Sansone work for Università di Napoli Federico II",Italian
Machine Learning Data Lifecycle in Production ,https://www.coursera.org/learn/machine-learning-data-lifecycle-in-production,4.5,"13,254",Robert Crowe,22 hours,Advanced,• Some knowledge of AI / deep learning,"Identify responsible data collection for building a fair ML production system. Implement feature engineering, transformation, and selection with TensorFlow Extended. Understand the data journey over a production system’s lifecycle and leverage ML metadata and enterprise schemas to address quickly evolving data.",ML Metadata          Convolutional Neural Network          TensorFlow Extended (TFX)          Data Validation          Data transformation      ,Data Science,DeepLearning.AI,Enroll for Free,Machine Learning Engineering for Production (MLOps) Specialization,Robert Crowe work for DeepLearning.AI,English
Scalable Machine Learning on Big Data using Apache Spark,https://www.coursera.org/learn/machine-learning-big-data-apache-spark,3.8,"19,464",Romeo Kienzler,7 hours,Intermediate,,"This course will empower you with the skills to scale data science and machine learning (ML) tasks on Big Data sets using Apache Spark. Most real world machine learning work involves very large data sets that go beyond the CPU, memory and storage limitations of a single computer.  Apache Spark is an open source framework that leverages cluster computing and distributed storage to process extremely large data sets in an efficient and cost effective manner. Therefore an applied knowledge of working with Apache Spark is a great asset and potential differentiator for a Machine Learning engineer.After completing this course, you will be able to:- gain a practical understanding of Apache Spark, and apply it to solve machine learning problems involving both small and big data- understand how parallel code is written, capable of running on thousands of CPUs. - make use of large scale compute clusters to apply machine learning algorithms on Petabytes of data using Apache SparkML Pipelines. - eliminate out-of-memory errors generated by traditional machine learning frameworks when data doesn’t fit in a computer's main memory- test thousands of different ML models in parallel to find the best performing one – a technique used by many successful Kagglers- (Optional) run SQL statements on very large data sets using Apache SparkSQL and the Apache Spark DataFrame API.Enrol now to learn the machine learning techniques for working with Big Data that have been successfully applied by companies like Alibaba, Apple, Amazon, Baidu, eBay, IBM, NASA, Samsung, SAP, TripAdvisor, Yahoo!, Zalando and many others.NOTE: You will practice running machine learning tasks hands-on on an Apache Spark cluster provided by IBM at no charge during the course which you can continue to use afterwards.Prerequisites:- basic python programming- basic machine learning (optional introduction videos are provided in this course as well)- basic SQL skills for optional contentThe following courses are recommended before taking this class (unless you already have the skills)https://www.coursera.org/learn/python-for-applied-data-science or similarhttps://www.coursera.org/learn/machine-learning-with-python or similarhttps://www.coursera.org/learn/sql-data-science for optional lectures",Data Science          Artificial Intelligence (AI)          Machine Learning          Big Data          Spark      ,Data Science,IBM,Enroll for Free,,Romeo Kienzler work for IBM,"French, Portuguese (European), Russian, English, Spanish"
Python and Machine-Learning for Asset Management with Alternative Data Sets,https://www.coursera.org/learn/machine-learning-asset-management-alternative-data,4.4,"10,338","Gideon OZIK,Sean McOwen",20 hours,Intermediate,Python programming (beginners),"Learn what alternative data is and how it is used in financial market applications. . Become immersed in current academic and practitioner state-of-the-art research pertaining to alternative data applications. Perform data analysis of real-world alternative datasets using Python. Gain an understanding and hands-on experience in data analytics, visualization and quantitative modeling applied to alternative data in finance",Advanced vizualisation          Basics of consuption-based alternative data          Text mining methodologies          Web-scritpting tools      ,Business,EDHEC Business School,Enroll for Free,Investment Management with Python and Machine Learning Specialization,"Gideon OZIK work for EDHEC Business School,Sean McOwen work for EDHEC Business School","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Big Data Applications: Machine Learning at Scale,https://www.coursera.org/learn/machine-learning-applications-big-data,3.8,"10,925","Alexey A. Dral,Vladimir Lesnichenko,Evgeny Frolov,Ilya Trofimov,Pavel Mezentsev ,Emeli Dral ",28 hours,Advanced,,"Machine learning is transforming the world around us. To become successful, you’d better know what kinds of problems can be solved with machine learning, and how they can be solved. Don’t know where to start? The answer is one button away. During this course you will:- Identify practical problems which can be solved with machine learning- Build, tune and apply linear models with Spark MLLib- Understand methods of text processing- Fit decision trees and boost them with ensemble learning- Construct your own recommender system. As a practical assignment, you will - build and apply linear models for classification and regression tasks; - learn how to work with texts; - automatically construct decision trees and improve their performance with ensemble learning; - finally, you will build your own recommender system!With these skills, you will be able to tackle many practical machine learning tasks. We provide the tools, you choose the place of application to make this world of machines more intelligent.Special thanks to:- Prof. Mikhail Roytberg, APT dept., MIPT, who was the initial reviewer of the project, the supervisor and mentor of half of the BigData team. He was the one, who helped to get this show on the road.- Oleg Sukhoroslov (PhD, Senior Researcher at IITP RAS), who has been teaching. MapReduce, Hadoop and friends since 2008. Now he is leading the infrastructure team.- Oleg Ivchenko (PhD student APT dept., MIPT), Pavel Akhtyamov (MSc. student at APT dept., MIPT) and Vladimir Kuznetsov (Assistant at P.G. Demidov Yaroslavl State University), superbrains who have developed and now maintain the infrastructure used for practical assignments in this course.- Asya Roitberg, Eugene Baulin, Marina Sudarikova. These people never sleep to babysit this course day and night, to make your learning experience productive, smooth and exciting.",,Data Science,Yandex,Enroll for Free,,"Alexey A. Dral work for Coursera, Moscow Institute of Physics and Technology, Yandex,Vladimir Lesnichenko work for Yandex,Evgeny Frolov work for Yandex,Ilya Trofimov work for Yandex,Pavel Mezentsev  work for Moscow Institute of Physics and Technology, Yandex,Emeli Dral  work for Moscow Institute of Physics and Technology, Yandex, E-Learning Development Fund","Subtitles: French, Portuguese (European), Korean, Russian, English, Spanish"
Getting Started with Data Visualization in R,https://www.coursera.org/learn/jhu-getting-started-data-viz-r,4.8,"6,409",Collin Paschall,12 hours,Beginner,,"Data visualization is a critical skill for anyone that routinely using quantitative data in his or her work - which is to say that data visualization is a tool that almost every worker needs today. One of the critical tools for data visualization today is the R statistical programming language. Especially in conjunction with the tidyverse software packages, R has become an extremely powerful and flexible platform for making figures, tables, and reproducible reports. However, R can be intimidating for first time users, and there are so many resources online that it can be difficult to sort through without guidance. To fill that need, this course is intended for learners who have little or no experience with R but who are looking for an introduction to this tool. By the end of this course, students will be able to import data into R, manipulate that data using tools from the popular tidyverse package, and make simple reports using R Markdown. The course is designed for students with good basic computing skills, but limited if any experience with programming.",,Data Science,Johns Hopkins University,Enroll for Free,Data Visualization & Dashboarding with R Specialization,Collin Paschall work for Johns Hopkins University,Subtitles: English
Data Visualization in R with ggplot2,https://www.coursera.org/learn/jhu-data-visualization-r,4.9,"3,013",Collin Paschall,13 hours,Intermediate,,"Data visualization is a critical skill for anyone that routinely using quantitative data in his or her work - which is to say that data visualization is a tool that almost every worker needs today. One of the critical tools for data visualization today is the R statistical programming language. Especially in conjunction with the tidyverse software packages, R has become an extremely powerful and flexible platform for making figures, tables, and reproducible reports. However, R can be intimidating for first time users, and there are so many resources online that it can be difficult to sort through without guidance. This course is the second in a specialization in Data Visualization offered by Johns Hopkins. It is intended for learners who have either have some experience with R and data wrangling in the tidyverse or have taken the previous course in the specialization. The focus in this course learning to use ggplot2 to make a variety of visualizations and to polish those visualizations using tools within ggplot as well as vector graphics editing software. The course will not go into detail about how the data management works behind the scenes.",,Data Science,Johns Hopkins University,Enroll for Free,Data Visualization & Dashboarding with R Specialization,Collin Paschall work for Johns Hopkins University,Subtitles: English
Advanced Data Visualization with R,https://www.coursera.org/learn/jhu-advanced-data-visualization-r,4.8,"2,070",Collin Paschall,11 hours,,,"Data visualization is a critical skill for anyone that routinely using quantitative data in his or her work - which is to say that data visualization is a tool that almost every worker needs today. One of the critical tools for data visualization today is the R statistical programming language. Especially in conjunction with the tidyverse software packages, R has become an extremely powerful and flexible platform for making figures, tables, and reproducible reports. However, R can be intimidating for first time users, and there are so many resources online that it can be difficult to sort through without guidance. This course is the third in the Specialization ""Data Visualization and Dashboarding in R."". Learners come into this course with a foundation using R to make many basic kinds of visualization, primarily with the ggplot2 package. Accordingly, this course focuses on expanding the learners' inventory of data visualization options. Drawing on additional packages to supplement ggplot2, learners will made more variants of traditional figures, as well as venture into spatial data. The course ends make interactive and animated figures.To fill that need, this course is intended for learners who have little or no experience with R but who are looking for an introduction to this tool. By the end of this course, students will be able to import data into R, manipulate that data using tools from the popular tidyverse package, and make simple reports using R Markdown. The course is designed for students with good basic computing skills, but limited if any experience with programming.",,Data Science,Johns Hopkins University,Enroll for Free,Data Visualization & Dashboarding with R Specialization,Collin Paschall work for Johns Hopkins University,Subtitles: English
Data Manipulation in JavaScript,https://www.coursera.org/learn/javascript-data-manipulation,,,William Mead,19 hours,Beginner,,"This course builds on the skills from the previous course and goes further into managing and manipulating data with JavaScript. You will learn methods for validating and handling data provided by users or coming from an external data source. This course includes a challenge in the form of a seat reservation system, as well as a project that pulls data in from an external data source. The course objectives include validation basics in JavaScript and jQuery; jQuery form validation plugin features; arrow functions; asynchronous functions; and the JavaScript event loop.",,Computer Science,"University of California, Davis",Enroll for Free,JavaScript for Beginners Specialization,"William Mead work for University of California, Davis",Subtitles: English
Inheritance and Data Structures in Java,https://www.coursera.org/learn/java-inheritance-data-structures,4.5,"2,052",Brandon Krakowsky,21 hours,Beginner,High school or college math.,"Examine the concept of inheritance in object-oriented programming and learn how to extend classes and override methods in a subclass. Analyze and fix different parts of a Java program using Eclipse's interactive debugger. Explore different methods for opening, reading, and writing to external files, and deal with errors and exceptions. Examine advanced techniques for storing and manipulating data in collections, and parse text using regular expressions (or regex).",Debugging          Problem Solving          Java Programming          Data Structure          Inheritance      ,Computer Science,University of Pennsylvania,Enroll for Free,Introduction to Programming with Python and Java Specialization,"Brandon Krakowsky work for University of Pennsylvania, Penn Engineering",English
"Java Programming: Arrays, Lists, and Structured Data",https://www.coursera.org/learn/java-programming-arrays-lists-data,4.7,"124,477","Andrew D. Hilton,Robert Duvall,Owen Astrachan,Susan H. Rodger",14 hours,Beginner,,"Build on the software engineering skills you learned in “Java Programming: Solving Problems with Software” by learning new data structures. Use these data structures to build more complex programs that use Java’s object-oriented features. At the end of the course you will write an encryption program and a program to break your encryption algorithm. After completing this course, you will be able to:1. Read and write data from/to files;2. Solve problems involving data files;3. Perform quantitative analyses of data (e.g., finding maximums, minimums, averages); 4. Store and manipulate data in an array or ArrayList;5. Combine multiple classes to solve larger problems;6. Use iterables and collections (including maps) in Java.",Data Structure          Cryptography          Hash Table          Java Programming      ,Computer Science,Duke University,Enroll for Free,,"Andrew D. Hilton work for Duke University,Robert Duvall work for Duke University,Owen Astrachan work for Duke University,Susan H. Rodger work for Duke University","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Introduzione alla Data Visualization con Tableau,https://www.coursera.org/learn/introduzione-data-visualization-tableau,,,Manuel Belgioioso,18 hours,Beginner,Si consiglia di avere una conoscenza base nel lavorare con i dataset.  ,La suite di prodotti Tableau. Connessione alle fonti dati. Semplificazione dei dati. Organizzazione dei dati,Visual Communication          Data Virtualization          Data Visualization (DataViz)          Visual Analytics          Tableau Software      ,Data Science,Università di Napoli Federico II,Enroll for Free,Data Visualization: Analisi dei dati con Tableau Specialization,Manuel Belgioioso work for Università di Napoli Federico II,Italian
Introduction to R Programming for Data Science,https://www.coursera.org/learn/introducton-r-programming-data-science,4.6,"6,265",Yan Luo,11 hours,Beginner,,"Manipulate numeric and textual data types using the R programming language and RStudio or Jupyter Notebooks. Define and manipulate R data structures, including vectors, factors, lists, and data frames. Control program flow, define functions, perform character string and date operations, define regular expressions, and handle errors. Read, write, and save data files and scrape web pages using R.",Data Science          R Programming      ,Data Science,IBM,Enroll for Free,,Yan Luo work for IBM,English
Introduction to NoSQL Databases,https://www.coursera.org/learn/introduction-to-nosql-databases,4.6,"3,975","Rav Ahuja,Ramesh Sannareddy,Steve Ryan",17 hours,Beginner,,"Differentiate between the four main categories of NoSQL repositories and work hands-on with MongoDB, Cassandra, and IBM Cloudant. Apply your knowledge of the characteristics, features, benefits, limitations, and applications of the more popular Big Data processing tools. Describe parallel programming using Resilient Distributed Datasets (RDDs), DataFrames, and SparkSQL.  Acquire real-world data engineering and machine learning skills using Spark Structured Streaming, DataFrames, GraphFrames, Spark ML, and Regression.",Mongodb          NoSQL          Cloud Database          Cloudant          Cassandra      ,Information Technology,IBM,Enroll for Free,,"Rav Ahuja work for Coursera, IBM,Ramesh Sannareddy work for IBM,Steve Ryan work for IBM, SkillUP",English
Introduction to Relational Databases (RDBMS),https://www.coursera.org/learn/introduction-to-relational-databases,4.6,"5,533","Rav Ahuja,Sandip Saha Joy,Lin Joyner,Rose Malcolm",14 hours,Beginner,,"Fundamental Relational Database concepts. Types of RDBMS objects. Popular database systems. Design a relational database and its schema. Create Entity Relationship Diagrams (ERD). Normalize data. Work hands-on with Relational Databases such MySQL, PostgreSQL and Db2 using web tools and command line. Create tables and load data. Export data from one database and import into another RDBMS.","Database (DB) Design          Database Architecture          Postgresql          MySQL          •	Relational Database Management Systems (RDBMS)      ",Information Technology,IBM,Enroll for Free,,"Rav Ahuja work for Coursera, IBM,Sandip Saha Joy work for IBM,Lin Joyner work for IBM,Rose Malcolm work for IBM, SkillUP, TEST public Guided Projects ",English
Introduction to Data Analytics,https://www.coursera.org/learn/introduction-to-data-analytics,4.8,"120,550",Rav Ahuja,11 hours,Beginner,,"Explain what Data Analytics is and the key steps in the Data Analytics process. Differentiate between different data roles such as Data Engineer, Data Analyst, Data Scientist, Business Analyst, and Business Intelligence Analyst. Describe the different types of data structures, file formats, and sources of data. Explain the use for different types of data repositories, the ETL process, and Big Data platforms",Data Science          Spreadsheet          Data Analysis          Microsoft Excel      ,Data Science,IBM,Enroll for Free,,"Rav Ahuja work for Coursera, IBM","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Introduction to Designing Data Lakes on AWS,https://www.coursera.org/learn/introduction-to-designing-data-lakes-in-aws,4.7,"6,360","Rafael Lopes,Morgan Willis",14 hours,Intermediate,,Where to start with a Data Lake?. How to build a secure and scalable Data Lake?. What are the common components of a Data Lake?. Why do you need a Data Lake and what it's value?,Data Science          Analytics          Big Data          Data Lake          Amazon Web Services (Amazon AWS)      ,Data Science,Amazon Web Services,Enroll for Free,,"Rafael Lopes work for Amazon Web Services,Morgan Willis work for Amazon Web Services",English
Introduction to Data Engineering,https://www.coursera.org/learn/introduction-to-data-engineering,4.7,"19,897","Rav Ahuja,Priya Kapoor",11 hours,Beginner,,"Demonstrate the skills required for an entry-level data engineering role.  Implement various concepts in the data engineering lifecycle. Showcase working knowledge with Python, Relational Databases, NoSQL Data Stores, Big Data Engines, Data Warehouses, and Data Pipelines. Describe data security, governance, and compliance.",Data Science          Database (DBMS)          NoSQL          SQL      ,Information Technology,IBM,Enroll for Free,,"Rav Ahuja work for Coursera, IBM,Priya Kapoor work for IBM, O.P. Jindal Global University, SkillUP",English
Introduction to Big Data with Spark and Hadoop,https://www.coursera.org/learn/introduction-to-big-data-with-spark-hadoop,4.1,"3,524","Karthik Muthuraman,Aije Egwaikhide",12 hours,Beginner,,"Deep insight into the impact of Big Data including use cases, tools, and processing methods. Knowledge of the Apache Hadoop architecture, ecosystem, and practices, and the use of applications including HDFS, HBase, Spark, and MapReduce. Know-how to apply Spark programming basics, including parallel programming basics for DataFrames, data sets, and Spark SQL. Proficiency with Spark’s RDDs, data sets, use of Catalyst and Tungsten to optimize SparkSQL, and Spark’s development and runtime environment options.",Apache Hadoop          SparkSQL          SparkML          Big Data          Apache Spark      ,Information Technology,IBM,Enroll for Free,,"Karthik Muthuraman work for IBM,Aije Egwaikhide work for IBM",English
Introduction to Statistics & Data Analysis in Public Health,https://www.coursera.org/learn/introduction-statistics-data-analysis-public-health,4.7,"31,159",Alex Bottle,16 hours,Beginner,You will only need an interest in analysing quantitative data and familiarity with reading standard graphs and tables of data.,"Defend the critical role of statistics in modern public health research and practice.  Describe a data set from scratch, including data item features and data quality issues, using descriptive statistics and graphical methods in R. Select and apply appropriate methods to formulate and examine statistical associations between variables within a data set in R. Interpret the output from your analysis and appraise the role of chance and bias",Run basic analyses in R          R Programming          Understand common data distributions and types of variables          Formulate a scientific hypothesis      ,Health,Imperial College London,Enroll for Free,Statistical Analysis with R for Public Health Specialization,Alex Bottle work for Imperial College London,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Introduction to Clinical Data Science,https://www.coursera.org/learn/introduction-clinical-data-science,4.6,"12,315","Laura K. Wiley, PhD",8 hours,Intermediate,Some programming experience in any language.,"Describe how each type of clinical data are generated, specifically outlining who creates the data, when and why the data are generated. Write SQL code to combine two or more tables using database joins. Write R code to manipulate and tidy data including: selecting columns, filtering rows, and joining data sets.  Write markdown formatted text and combine with R code in RMarkdown documents.",,Data Science,University of Colorado System,Enroll for Free,Clinical Data Science Specialization,"Laura K. Wiley, PhD work for University of Colorado System","Subtitles: French, Portuguese (European), Russian, English, Spanish"
Introduction to Clinical Data,https://www.coursera.org/learn/introduction-clinical-data,4.6,"7,448","Nigam Shah,Steven Bagley,David Magnus",12 hours,Beginner,,How to apply a framework for medical data mining. Ethical use of data in healthcare decisions. How to make use of data that may be inaccurate in systematic ways. What makes a good research question and how to construct a data mining workflow answer it,,Data Science,Stanford University,Enroll for Free,AI in Healthcare Specialization,"Nigam Shah work for Stanford University,Steven Bagley work for Stanford University,David Magnus work for Stanford University","Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
"Intro to Analytic Thinking, Data Science, and Data Mining",https://www.coursera.org/learn/intro-analyticthinking-datascience-datamining,4,"3,112","Dursun Delen,Julie Pai",7 hours,Intermediate,,The knowledge and skills needed to work in the data science profession. How data science is used to solve business problems. The benefits of using the cross-industry standard process for data mining (CRISP-DM),Environmental Data Analysis          Data Documentation          Geophysical Data          Data Mining      ,Data Science,"University of California, Irvine",Enroll for Free,Data Science Fundamentals Specialization,"Dursun Delen work for University of California, Irvine,Julie Pai work for University of California, Irvine","English, Indonesian"
Introduction to Accounting Data Analytics and Visualization,https://www.coursera.org/learn/intro-accounting-data-analytics-visual,4.8,"18,899",Ronald Guymon,19 hours,Beginner,,"Accounting has always been about analytical thinking. From the earliest days of the profession, Luca Pacioli emphasized the importance of math and order for analyzing business transactions. The skillset that accountants have needed to perform math and to keep order has evolved from pencil and paper, to typewriters and calculators, then to spreadsheets and accounting software. A new skillset that is becoming more important for nearly every aspect of business is that of big data analytics: analyzing large amounts of data to find actionable insights. This course is designed to help accounting students develop an analytical mindset and prepare them to use data analytic programming languages like Python and R. We’ve divided the course into three main sections. In the first section, we bridge accountancy to analytics. We identify how tasks in the five major subdomains of accounting (i.e., financial, managerial, audit, tax, and systems) have historically required an analytical mindset, and we then explore how those tasks can be. completed more effectively and efficiently by using big data analytics. We then present a FACT framework for guiding big data analytics: Frame a question, Assemble data, Calculate the data, and Tell others about the results. In the second section of the course, we emphasize the importance of assembling data. Using financial statement data, we explain desirable characteristics of both data and datasets that will lead to effective calculations and visualizations. In the third, and largest section of the course, we demonstrate and explore how Excel and Tableau can be used to analyze big data. We describe visual perception principles and then apply those principles to create effective visualizations. We then examine fundamental data analytic tools, such as regression, linear programming (using Excel Solver), and clustering in the context of point of sale data and loan data. We conclude by demonstrating the power of data analytic programming languages to assemble, visualize, and analyze data. We introduce Visual Basic for Applications. as an example of a programming language, and the Visual Basic Editor as an example of an integrated development environment (IDE).",Data Analysis          Predictive Analytics          Data Visualization (DataViz)          Data Architecture          coding      ,Data Science,University of Illinois at Urbana-Champaign,Enroll for Free,Accounting Data Analytics Specialization,Ronald Guymon work for University of Illinois at Urbana-Champaign,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Innovating with Data and Google Cloud,https://www.coursera.org/learn/innovating-with-data-google-cloud,4.8,"5,245",Google Cloud Training,2 hours,Beginner,,Describe the role of data in digital transformation and the importance of a data-driven culture. Identify common Google Cloud solutions for data management. Identify common Google Cloud solution for smart analytics. Identify Google Cloud’s solutions for Machine Learning and AI,,Information Technology,Google Cloud,Enroll for Free,,Google Cloud Training work for Google Cloud,Subtitles: English
Information Security: Context and Introduction,https://www.coursera.org/learn/information-security-data,4.7,"64,840","Professor Peter Komisarczuk,Professor Keith M. Martin,Dr Jorge Blasco Alis",24 hours,Beginner,,"In this course you will explore information security through some introductory material and gain an appreciation of the scope and context around the subject. This includes a brief introduction to cryptography, security management and network and computer security that allows you to begin the journey into the study of information security and develop your appreciation of some key information security concepts. The course concludes with a discussion around a simple model of the information security industry and explores skills, knowledge and roles so that you can determine and analyse potential career opportunities in this developing profession and consider how you may need to develop personally to attain your career goals. After completing the course you will have gained an awareness of key information security principles regarding information, confidentiality, integrity and availability. You will be able to explain some of the key aspects of information risk and security management, in addition, summarise some of the key aspects in computer and network security, including some appreciation of threats, attacks, exploits and vulnerabilities. You will also gain an awareness of some of the skills, knowledge and roles/careers opportunities within the information security industry.",Cybersecurity          Cryptography          Information Security (INFOSEC)          Security Management      ,Computer Science,"University of London,Royal Holloway, University of London",Enroll for Free,,"Professor Peter Komisarczuk work for University of London,Professor Keith M. Martin work for University of London,Dr Jorge Blasco Alis work for University of London","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
IBM Data Topology,https://www.coursera.org/learn/ibm-data-topology,4.8,,"Mike Hervey,Paul Christensen",6 hours,Intermediate,,"Every business and organization is facing new challenges with their data. Pressures related to regulation and compliance, leveraging AI, spanning multicloud environments, and increasing volumes of inaccessible data are forcing executives and administrators to either modernize their infrastructures or become obsolete. But moving to the latest technology in a monolithic architecture is a tempting solution that can be expensive and cause more problems than it solves. In this course, you learn how to meet the needs of all your data consumers through the construction of a modern logical topology that helps you optimize data flow.",Data Science          Dataflow          Strategic Planning          Artificial Intelligence (AI)          Digital Strategy      ,Information Technology,IBM,Enroll for Free,,"Mike Hervey work for IBM,Paul Christensen work for IBM",English
IBM Data Privacy for Information Architecture,https://www.coursera.org/learn/ibm-data-privacy,4.7,,"Christopher Giardina,Aaron Ritchie",10 hours,,,"Data privacy controls how information is collected, used, shared, and disposed of, in accordance with policies or external laws and regulations. In this course, students will gain an understanding of what data privacy is along with how to identify and understand typical data protection and privatization objectives that an enterprise may have, and how to choose a data protection approach. The student will gain a background in multiple data privacy mechanisms and practices, and learn how to grow their data protection toolkit. The IBM DataFirst method will be the backbone of the discussion.",Information Privacy          IBM datafirst method      ,Information Technology,IBM,Enroll for Free,,"Christopher Giardina work for IBM,Aaron Ritchie work for IBM","English, Arabic"
IBM Data Analyst Capstone Project,https://www.coursera.org/learn/ibm-data-analyst-capstone-project,4.6,"10,946","Ramesh Sannareddy,Rav Ahuja",15 hours,Intermediate,It is highly recommend that you have completed all of the courses in the IBM Data Analyst Professional Certificate prior to starting this course.,"In this course you will apply various Data Analytics skills and techniques that you have learned as part of the previous courses in the IBM Data Analyst Professional Certificate. You will assume the role of an Associate Data Analyst who has recently joined the organization and be presented with a business challenge that requires data analysis to be performed on real-world datasets.  You will undertake the tasks of collecting data from multiple sources, performing exploratory data analysis, data wrangling and preparation, statistical analysis and mining the data, creating charts and plots to visualize data, and building an interactive dashboard. The project will culminate with a presentation of your data analysis report, with an executive summary for the various stakeholders in the organization. You will be assessed on both your work for the various stages in the Data Analysis process, as well as the final deliverable. This project is a great opportunity to showcase your Data Analytics skills, and demonstrate your proficiency to potential employers.",Microsoft Excel          Data Analysis          SQL and RDBMS          Data Visualization (DataViz)          Dashboard      ,Data Science,IBM,Enroll for Free,IBM Data Analyst Professional Certificate,"Ramesh Sannareddy work for IBM,Rav Ahuja work for Coursera, IBM",English
Exploratory Data Analysis for Machine Learning,https://www.coursera.org/learn/ibm-exploratory-data-analysis-for-machine-learning,4.6,"23,135","Mark J Grover,Miguel Maldonado",8 hours,Intermediate,,"This first course in the IBM Machine Learning Professional Certificate introduces you to Machine Learning and the content of the professional certificate. In this course you will realize the importance of good, quality data. You will learn common techniques to retrieve your data, clean it, apply feature engineering, and have it ready for preliminary analysis and hypothesis testing. By the end of this course you should be able to:Retrieve data from multiple data sources: SQL, NoSQL databases, APIs, Cloud Describe and use common feature selection and feature engineering techniquesHandle categorical and ordinal features, as well as missing valuesUse a variety of techniques for detecting and dealing with outliersArticulate why feature scaling is important and use a variety of scaling techniques Who should take this course?This course targets aspiring data scientists interested in acquiring hands-on experience  with Machine Learning and Artificial Intelligence in a business setting. What skills should you have?To make the most out of this course, you should have familiarity with programming on a Python development environment, as well as fundamental understanding of Calculus, Linear Algebra, Probability, and Statistics.",Artificial Intelligence (AI)          Machine Learning          Feature Engineering          Statistical Hypothesis Testing          Exploratory Data Analysis      ,Data Science,IBM,Enroll for Free,,"Mark J Grover work for IBM,Miguel Maldonado work for IBM","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
AI Workflow: Data Analysis and Hypothesis Testing,https://www.coursera.org/learn/ibm-ai-workflow-data-analysis-hypothesis-testing,4.2,"2,800","Mark J Grover,Ray Lopez, Ph.D.",11 hours,Advanced,,"This is the second course in the IBM AI Enterprise Workflow Certification specialization.  You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones.  . In this course you will begin your work for a hypothetical streaming media company by doing exploratory data analysis (EDA).  Best practices for data visualization, handling missing data, and hypothesis testing will be introduced to you as part of your work.  You will learn techniques of estimation with probability distributions and extending these estimates to apply null hypothesis significance tests. You will apply what you learn through two hands on case studies: data visualization and multiple testing using a simple pipeline. By the end of this course you should be able to:1.  List several best practices concerning EDA and data visualization2.  Create a simple dashboard in Watson Studio3.  Describe strategies for dealing with missing data4.  Explain the difference between imputation and multiple imputation5.  Employ common distributions to answer questions about event probabilities6.  Explain the investigative role of hypothesis testing in EDA7.  Apply several methods for dealing with multiple testing Who should take this course?This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses.What skills should you have?It is assumed that you have completed Course 1 of the IBM AI Enterprise Workflow specialization and have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.",Data Science          Information Engineering          Artificial Intelligence (AI)          Machine Learning          Python Programming      ,Data Science,IBM,Enroll for Free,IBM AI Enterprise Workflow Specialization,"Mark J Grover work for IBM,Ray Lopez, Ph.D. work for IBM",English
AI Workflow: Business Priorities and Data Ingestion,https://www.coursera.org/learn/ibm-ai-workflow-business-priorities-data-ingestion,4.3,"4,410","Mark J Grover,Ray Lopez, Ph.D.",8 hours,Intermediate,,"This is the first course of a six part specialization.  You are STRONGLY encouraged to complete these courses in order as they are not individual independent courses, but part of a workflow where each course builds on the previous ones. This first course in the IBM AI Enterprise Workflow Certification specialization introduces you to the scope of the specialization and prerequisites.  Specifically, the courses in this specialization are meant for practicing data scientists who are knowledgeable about probability, statistics, linear algebra, and Python tooling for data science and machine learning.  A hypothetical streaming media company will be introduced as your new client.  You will be introduced to the concept of design thinking, IBMs framework for organizing large enterprise AI projects.  You will also be introduced to the basics of scientific thinking, because the quality that distinguishes a seasoned data scientist from a beginner is creative, scientific thinking.  Finally you will start your work for the hypothetical media company by understanding the data they have, and by building a data ingestion pipeline using Python and Jupyter notebooks. By the end of this course you should be able to:1.  Know the advantages of carrying out data science using a structured process2.  Describe how the stages of design thinking correspond to the AI enterprise workflow3.  Discuss several strategies used to prioritize business opportunities4.  Explain where data science and data engineering have the most overlap in the AI workflow5.  Explain the purpose of testing in data ingestion 6.  Describe the use case for sparse matrices as a target destination for data ingestion 7.  Know the initial steps that can be taken towards automation of data ingestion pipelines Who should take this course?This course targets existing data science practitioners that have expertise building machine learning models, who want to deepen their skills on building and deploying AI in large enterprises. If you are an aspiring Data Scientist, this course is NOT for you as you need real world expertise to benefit from the content of these courses. What skills should you have?It is assumed you have a solid understanding of the following topics prior to starting this course: Fundamental understanding of Linear Algebra; Understand sampling, probability theory, and probability distributions; Knowledge of descriptive and inferential statistical concepts; General understanding of machine learning techniques and best practices; Practiced understanding of Python and the packages commonly used in data science: NumPy, Pandas, matplotlib, scikit-learn; Familiarity with IBM Watson Studio; Familiarity with the design thinking process.",Data Science          Information Engineering          Artificial Intelligence (AI)          Machine Learning          Python Programming      ,Data Science,IBM,Enroll for Free,IBM AI Enterprise Workflow Specialization,"Mark J Grover work for IBM,Ray Lopez, Ph.D. work for IBM",English
Healthcare Data Quality and Governance,https://www.coursera.org/learn/healthcare-data-quality-governance,4.5,"4,824",Doug Berman,12 hours,Intermediate,,"Career prospects are bright for those qualified to work with healthcare data or as Health Information Management (HIM) professionals. Perhaps you work in data analytics but are considering a move into healthcare, or you work in healthcare but are considering a transition into a new role. In either case, Healthcare Data Quality and Governance will provide insight into how valuable data assets are protected to maintain data quality. This serves care providers, patients, doctors, clinicians, and those who carry out the business of improving health outcomes.  ""Big Data"" makes headlines, but that data must be managed to maintain quality. High-quality data is one of the most valuable assets gathered and used by any business. This holds greater significance in healthcare where the maintenance and governance of data quality directly impact people’s lives. This course will explain how data quality is improved and maintained. You’ll learn why data quality matters, then see how healthcare professionals monitor, manage and improve data quality. You’ll see how human and computerized systems interact to sustain data quality through data governance. You’ll discover how to measure data quality with metadata, tracking data provenance, validating and verifying data, along with a communication framework commonly used in healthcare settings. This knowledge matters because high-quality data will be transformed into valuable insights that can save lives, reduce costs, to improve healthcare and make it more accessible and affordable. You will make yourself more of an asset in the healthcare field by what you gain from this course.",,Health,"University of California, Davis",Enroll for Free,Health Information Literacy for Data Analytics Specialization,"Doug Berman work for University of California, Davis","Subtitles: French, Portuguese (European), Russian, English, Spanish"
Healthcare Data Literacy,https://www.coursera.org/learn/healthcare-data-literacy,4.5,"9,950",Brian Paciotti,13 hours,Intermediate,,"This course will help lay the foundation of your healthcare data journey and provide you with knowledge and skills necessary to work in the healthcare industry as a data scientist. Healthcare is unique because it is associated with continually evolving and complex processes associated with health management and medical care. We'll learn about the many facets to consider in healthcare and determine the value and growing need for data analysts in healthcare. We'll learn about the Triple Aim and other data-enabled healthcare drivers. We'll cover different concepts and categories of healthcare data and describe how ontologies and related terms such as taxonomy and terminology organize concepts and facilitate computation. We'll discuss the common clinical representations of data in healthcare systems, including ICD-10, SNOMED, LOINC, drug vocabularies (e.g., RxNorm), and clinical data standards. We’ll discuss the various types of healthcare data and assess the complexity that occurs as you work with pulling in all the different types of data to aid in decisions. We will analyze various types and sources of healthcare data, including clinical, operational claims, and patient generated data as well as differentiate unstructured, semi-structured and structured data within health data contexts. We'll examine the inner workings of data and conceptual harmony. offer some solutions to the data integration problem by defining some important concepts, methods, and applications that are important to this domain.",,Health,"University of California, Davis",Enroll for Free,Health Information Literacy for Data Analytics Specialization,"Brian Paciotti work for University of California, Davis","Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Using clinical health data for better healthcare,https://www.coursera.org/learn/healthcare-data,4.7,"6,107",Tim Shaw,15 hours,Beginner,,"Digital health is rapidly being realised as the future of healthcare. While this is placing emphasis on the input of quality health data in digital records and systems, the delivery of safe and quality healthcare relies not only on the input of data, but also the ability to access and derive meaning from data to generate evidence, inform decision making and drive better health outcomes. This course provides insight into the use of healthcare data, including an overview of best practices and the practical realities of obtaining useful information from digital health systems via the understanding of the fundamental concepts of health data analytics. Learners will understand why data quality is essential in modern healthcare, as they are guided through various stages of the data life cycle, starting with the generation of quality health data, through to discovering patterns and extracting knowledge from health data using common methodologies and tools in the basic analysis, visualisation and communication of health data. In doing so, learners explore current healthcare delivery contexts, and future and emerging digital health data systems and applications that are rapidly becoming tomorrow’s reality.On completion of this course, you will be able to:1.	Identify digital health technologies, health data sources, and the evolving roles of health workforce in digital health environments2.	Understand key health data concepts and terminology, including the significance of data integrity and stakeholder roles in the data life cycle3.	Use health data and basic data analysis to inform and improve decision making and practice.4.	Apply effective methods of communication of health data to facilitate safe and quality care.During this course, you will interact with learning content contributed by:•	Digital Health Cooperative Research Centre•	Australian Digital Health Agency•	eHealth NSW•	Sydney Local Health District•	The NSW Ministry of Health•	Health Education and Training Institute•	Clinical Excellence Commission •	Chris O’Brien Lifehouse•	Monash Partners / Australian Health Research Alliance•	Australian Research Data Commons•	Justice Health &amp; Forensic Mental Health Network•	South Eastern Sydney Local Health District•	Western Sydney Local Health District•	Westmead Breast Cancer Institute•	Agency for Clinical Innovation•	Western NSW Local Health District•	Sydney Children’s Hospital NetworkThis course is a collaborative venture between NSW Health, the University of Sydney and the Digital Health Cooperative Research Centre, including dedicated resources from eHealth NSW, Health Education and Training Institute, and the Research in Implementation Science &amp; eHealth group. While many learning resources and case examples are drawn from the NSW Health service context, this course has relevance for all existing and future health workforce, regardless of role or work context.Note: Materials used are for learning purposes and content may not reflect your organisation’s policies. When working with data, make sure you act within the guidelines and policies of your organisation.",,Health,The University of Sydney,Enroll for Free,,Tim Shaw work for The University of Sydney,"Subtitles: French, Portuguese (European), Russian, English, Spanish"
Healthcare Data Models,https://www.coursera.org/learn/healthcare-data-models,4.5,"4,155",Doug Berman,12 hours,Intermediate,,"Career prospects are bright for those qualified to work in healthcare data analytics. Perhaps you work in data analytics, but are considering a move into healthcare where your work can improve people’s quality of life. If so, this course gives you a glimpse into why this work matters, what you’d be doing in this role, and what takes place on the Path to Value where data is gathered from patients at the point of care, moves into data warehouses to be prepared for analysis, then moves along the data pipeline to be transformed into valuable insights that can save lives, reduce costs, to improve healthcare and make it more accessible and affordable. Perhaps you work in healthcare but are considering a transition into a new role. If so, this course will help you see if this career path is one you want to pursue. You’ll get an overview of common data models and their uses. You’ll learn how various systems integrate data, how to ensure clear communication, measure and improve data quality. Data analytics in healthcare serves doctors, clinicians, patients, care providers, and those who carry out the business of improving health outcomes. This course of study will give you a clear picture of data analysis in today’s fast-changing healthcare field and the opportunities it holds for you.",,Health,"University of California, Davis",Enroll for Free,Health Information Literacy for Data Analytics Specialization,"Doug Berman work for University of California, Davis","Subtitles: French, Portuguese (European), Russian, English, Spanish"
Google Data Analytics Capstone: Complete a Case Study,https://www.coursera.org/learn/google-data-analytics-capstone,4.8,"56,382",Google Career Certificates,8 hours,Beginner,No prior experience with spreadsheets or data analytics is required. All you need is high-school level math and a curiosity about how things work.,"Differentiate between a capstone, case study, and a portfolio. Identify the key features and attributes of a completed case study. Apply the practices and procedures associated with the data analysis process to a given set of data. Discuss the use of case studies/portfolios when communicating with recruiters and potential employers",Job portfolio          Data Cleansing          Data Analysis          Data Visualization (DataViz)          case study      ,Data Science,Google,Enroll for Free,Google Data Analytics Professional Certificate,Google Career Certificates work for Google,English
GIS Data Acquisition and Map Design,https://www.coursera.org/learn/gis-data-acquisition-map-design,4.9,"18,752",Don Boyes,20 hours,Beginner,,"In this course, you will learn how to find GIS data for your own projects, and how to create a well-designed map that effectively communicates your message. The first section focuses on the basic building blocks of GIS data, so that you know what types of GIS files exist, and the implications of choosing one type over another. Next, we'll discuss metadata (which is information about a data set) so you know how to evaluate a data set before you decide to use it, as well as preparing data by merging and clipping files as needed. We'll then talk about how to take non-GIS data, such as a list of addresses, and convert it into ""mappable"" data using geocoding. Finally, you'll learn about how to take data that you have found and design a map using cartographic principles. In the course project, you will find your own data and create your own quantitative map. Note: software is not provided for this course.",Geographic Information System (GIS)          Cartography          Esri          Mapping          Spatial Analysis      ,Physical Science and Engineering,University of Toronto,Enroll for Free,"GIS, Mapping, and Spatial Analysis Specialization",Don Boyes work for University of Toronto,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
"GIS Data Formats, Design and Quality",https://www.coursera.org/learn/gis-data,4.9,"33,082",Nick Santos,28 hours,Intermediate,"At least 2 years experience, comfortable doing data analysis, and fundamental grasp of GIS concepts.",Design data tables and use separating and joining data in a relational database. Write query strings to subset data. Create and work with raster data. Create web maps,Spatial Analysis          Analytics          Workflow          Data Management      ,Physical Science and Engineering,"University of California, Davis",Enroll for Free,Geographic Information Systems  (GIS) Specialization,"Nick Santos work for University of California, Davis","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Getting Started with Data Warehousing and BI Analytics,https://www.coursera.org/learn/getting-started-with-data-warehousing-and-bi-analytics,,,"Ramesh Sannareddy,Rav Ahuja",12 hours,Beginner,,"Explore the architecture, features, and benefits of data warehouses, data marts, and data lakes and identify popular data warehouse system vendors. Design and populate a data warehouse, and model and querydata using CUBE, ROLLUP, and materialized views. . Identify popular data analytics and business intelligence tools and vendors and create data visualizations using IBM Cognos Analytics. . Design and load data into a data warehouse, write aggregation queries, create materialized query tables, and create an analytics dashboard.",Data Warehousing          Cube and Rollup          Business Intelligence (BI)          Star and Snowflake Schema          cognos analytics      ,Information Technology,IBM,Enroll for Free,,"Ramesh Sannareddy work for IBM,Rav Ahuja work for Coursera, IBM",English
Getting Started with Data Analytics on AWS,https://www.coursera.org/learn/getting-started-data-analytics-aws,4.6,"7,276",Rafael Lopes,4 hours,Beginner,,"Explain different types of data analyses – descriptive, diagnostic, predictive, prescriptive. Understand how to perform descriptive data analytics in the cloud with typical data sets. How to build simple visualizations in AWS QuickSight to do descriptive analytics (using S3, Cloudtrail, Athena)",aws          Data Analysis          Cloud      ,Data Science,Amazon Web Services,Enroll for Free,,Rafael Lopes work for Amazon Web Services,English
Genomic Data Science and Clustering (Bioinformatics V),https://www.coursera.org/learn/genomic-data,4.2,"12,919","Pavel  Pevzner,Phillip Compeau",10 hours,Beginner,,"How do we infer which genes orchestrate various processes in the cell?. How did humans migrate out of Africa and spread around the world? In this class, we will see that these two seemingly different questions can be addressed using similar algorithmic and machine learning techniques arising from the general problem of dividing data points into distinct clusters. In the first half of the course, we will introduce algorithms for clustering a group of objects into a collection of clusters based on their similarity, a classic problem in data science, and see how these algorithms can be applied to gene expression data.In the second half of the course, we will introduce another classic tool in data science called principal components analysis that can be used to preprocess multidimensional data before clustering in an effort to greatly reduce the number dimensions without losing much of the ""signal"" in the data.Finally, you will learn how to apply popular bioinformatics software tools to solve a real problem in clustering.",,Health,University of California San Diego,Enroll for Free,Bioinformatics Specialization,"Pavel  Pevzner work for University of California San Diego,Phillip Compeau work for University of California San Diego","Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Exploring ​and ​Preparing ​your ​Data with BigQuery,https://www.coursera.org/learn/gcp-exploring-preparing-data-bigquery,4.7,"52,002",Google Cloud Training,13 hours,Beginner,,"Welcome to the Coursera specialization, From Data to Insights with Google Cloud Platform brought to you by the Google Cloud team. I’m Evan Jones (a data enthusiast) and I’m going to be your guide. This first course in this specialization is Exploring and Preparing your Data with BigQuery. Here we will see what the common challenges faced by data analysts are and how to solve them with the big data tools on Google Cloud Platform. You’ll pick up some SQL along the way and become very familiar with using BigQuery and Cloud Dataprep to analyze and transform your datasets.This course should take about one week to complete, 5-7 total hours of work. By the end of this course, you’ll be able to query and draw insight from millions of records in our BigQuery public datasets. You’ll learn how to assess the quality of your datasets and develop an automated data cleansing pipeline that will output to BigQuery. Lastly, you’ll get to practice writing and troubleshooting SQL on a real Google Analytics e-commerce dataset to drive marketing insights.&gt;&gt;&gt; By enrolling in this specialization you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service &lt;&lt;&lt;",Bigquery          Google Cloud Platform          Cloud Computing          SQL      ,Information Technology,Google Cloud,Enroll for Free,From Data to Insights with Google Cloud Specialization,Google Cloud Training work for Google Cloud,"English, Japanese"
Google Cloud Big Data and Machine Learning Fundamentals,https://www.coursera.org/learn/gcp-big-data-ml-fundamentals,4.7,"228,702",Google Cloud Training,12 hours,Intermediate,,Identify the purpose and value of the key Big Data and Machine Learning products in Google Cloud. Use Cloud SQL and Dataproc to migrate existing MySQL and Hadoop/Pig/Spark/Hive workloads to Google Cloud. Employ BigQuery to carry out interactive data analysis. Choose between different data processing products on Google Cloud.,Tensorflow          Bigquery          Google Cloud Platform          Cloud Computing      ,Data Science,Google Cloud,Enroll for Free,,Google Cloud Training work for Google Cloud,English
Creating New BigQuery Datasets and Visualizing Insights,https://www.coursera.org/learn/gcp-creating-bigquery-datasets-visualizing-insights,4.6,"18,663",Google Cloud Training,11 hours,Beginner,,"This is the second course in the Data to Insights specialization. Here we will cover how to ingest new external datasets into BigQuery and. visualize them with Google Data Studio. We will also cover intermediate SQL concepts like multi-table JOINs and UNIONs which will allow you to analyze data across multiple data sources. Note: Even if you have a background in SQL, there are BigQuery specifics (like handling query cache and table wildcards) that may be new to you.&gt;&gt;&gt; By enrolling in this specialization you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service &lt;&lt;&lt;",,Information Technology,Google Cloud,Enroll,From Data to Insights with Google Cloud Specialization,Google Cloud Training work for Google Cloud,"Subtitles: English, Japanese"
Fundamentals of Data Warehousing,https://www.coursera.org/learn/fundamentals-of-data-warehousing,,,Erik Herman,14 hours,Beginner,,"Welcome to Fundamentals of Data Warehousing, the third course of the Key Technologies of Data Analytics specialization. By enrolling in this course, you are taking the next step in your career in data analytics. This course is the third of a series that aims to prepare you for a role working in data analytics. In this course, you will be introduced to many of the core concepts of data warehousing. You will learn about the primary components of data warehousing. We’ll go through the common data warehousing architectures. The hands-on material offers to add storage to your cloud environment and configure a database. This course covers a wide variety of topics that are critical for understanding data warehousing and are designed to give you an introduction and overview as you begin to build relevant knowledge and skills.",,Business,LearnQuest,Enroll for Free,Key Technologies in Data Analytics Specialization,Erik Herman work for LearnQuest,Subtitles: English
Fundamentals of Data Visualization,https://www.coursera.org/learn/fundamentals-of-data-visualization,,,Danielle Szafir,14 hours,Intermediate,"Python, foundation in Data Science",Develop a toolkit for exploring and communicating complex data using visualization. Produce basic data visualizations using a chosen dataset. Compare methods for visualizing data and understand how these methods may guide users towards different conclusions. Evaluate how effectively a visualization conveys target data,Evaluation Design          Visualizing data with Altair          User-Centered Design (Create basic visualizations that match data and user needs)          Task Analysis (Define elements of a data analysis and/or communication problem)      ,Data Science,University of Colorado Boulder,Enroll for Free,Vital Skills for Data Science Specialization,Danielle Szafir work for University of Colorado Boulder,English
Fundamentals of Data Analysis,https://www.coursera.org/learn/fundamentals-of-data-analysis,,,Erik Herman,18 hours,Beginner,Basic computer knowledge,Explain the primary types of data analysis. Define the phases of the data analysis process. Identify tools and skills required to conduct data analysis,Data visualization Data exploration          Data queries          Data Collection          Data Analysis          Data Visualization (DataViz)      ,Data Science,LearnQuest,Enroll for Free,Key Technologies in Data Analytics Specialization,Erik Herman work for LearnQuest,English
Foundations for Big Data Analysis with SQL,https://www.coursera.org/learn/foundations-big-data-analysis-sql,4.8,"38,812",Glynn Durham,12 hours,Beginner,,"Distinguish operational from analytic databases, and understand how these are applied in big data. Understand how database and table design provides structures for working with data. Appreciate how differences in volume and variety of data affects your choice of an appropriate database system. Recognize the features and benefits of SQL dialects designed to work with big data systems for storage and analysis",Database (DBMS)          Data Warehousing          Data Analysis          Big Data          SQL      ,Data Science,Cloudera,Enroll for Free,Modern Big Data Analysis with SQL Specialization,Glynn Durham work for Cloudera,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
"Foundations: Data, Data, Everywhere",https://www.coursera.org/learn/foundations-data,4.8,"512,051",Google Career Certificates,20 hours,Beginner,No prior experience with spreadsheets or data analytics required. All you need is high school level math and curiosity about how things work. ,"Define and explain key concepts involved in data analytics including data, data analysis, and data ecosystem. Conduct an analytical thinking self assessment giving specific examples of the application of analytical thinking. Discuss the role of spreadsheets, query languages, and data visualization tools in data analytics. Describe the role of a data analyst with specific reference to jobs/positions",Spreadsheet          Data Cleansing          Data Analysis          Data Visualization (DataViz)          SQL      ,Data Science,Google,Enroll for Free,Google Data Analytics Professional Certificate,Google Career Certificates work for Google,English
Fitting Statistical Models to Data with Python,https://www.coursera.org/learn/fitting-statistical-models-data-python,4.4,"24,959","Brenda Gunderson,Brady T. West,Kerby Shedden",16 hours,Intermediate,Completion of the first two courses in this specialization; high school-level algebra,"In this course, we will expand our exploration of statistical inference techniques by focusing on the science and art of fitting statistical models to data. We will build on the concepts presented in the Statistical Inference course (Course 2) to emphasize the importance of connecting research questions to our data analysis methods. We will also focus on various modeling objectives, including making inference about relationships between variables and generating predictions for future observations. This course will introduce and explore various statistical modeling techniques, including linear regression, logistic regression, generalized linear models, hierarchical and mixed effects (or multilevel) models, and Bayesian inference techniques. All techniques will be illustrated using a variety of real data sets, and the course will emphasize different modeling approaches for different types of data sets, depending on the study design underlying the data (referring back to Course 1, Understanding and Visualizing Data with Python).During these lab-based sessions, learners will work through tutorials focusing on specific case studies to help solidify the week’s statistical concepts, which will include further deep dives into Python libraries including Statsmodels, Pandas, and Seaborn. This course utilizes the Jupyter Notebook environment within Coursera.",Bayesian Statistics          Python Programming          Statistical Model          statistical regression      ,Data Science,University of Michigan,Enroll for Free,Statistics with Python Specialization,"Brenda Gunderson work for University of Michigan,Brady T. West work for University of Michigan,Kerby Shedden work for University of Michigan","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Explore Core Data Concepts in Microsoft Azure,https://www.coursera.org/learn/explore-core-data-concepts-microsoft-azure,4.8,"3,373", Microsoft,9 hours,Beginner,"Successful students should start with some basic awareness of computing and Internet concepts, and an interest in extracting insights from data. ","In this course, you will learn the fundamentals of database concepts in a cloud environment, get basic skilling in cloud data services, and build your foundational knowledge of cloud data services within Microsoft Azure. You will identify and describe core data concepts such as relational, non-relational, big data, and analytics, and explore how this technology is implemented with Microsoft Azure. You will explore the roles, tasks, and responsibilities in the world of data. This is the first course in a. program of five courses to help prepare you to take the Exam DP-900: Microsoft Azure Data Fundamentals. so that you can demonstrate that you have a foundational knowledge of the core database concepts in a cloud environment.This course is ideal for IT professionals who want to learn the fundamentals of database concepts in a cloud environment, get basic skilling in cloud data services, and build their foundational knowledge of cloud data services within Microsoft Azure with a view to taking up roles as Data Engineers and Database Administrators. It is also suitable for working database professionals looking for additional skills or credentials to showcase expertise in a cloud environment and IT professionals looking to specialize in the specific area of Azure data.To be successful in this course, you need to have basic computer literacy and proficiency in the English language. Successful Azure Data Fundamentals students start with some basic awareness of computing and Internet concepts, and an interest in extracting insights from data. It is an advantage to have experience using a web browser, familiarity with basic data-related concepts, such as working with tables of data in a spreadsheet, and visualizing data using charts.",Describe core data concept          Identify how data is defined and stored          Describe data job roles          Describe and differentiate batch and streaming data          Identify characteristics of relational and non-relational data      ,Information Technology,Microsoft,Enroll for Free,Microsoft Azure Data Fundamentals DP-900 Exam Prep Specialization, Microsoft work for Microsoft,English
Exploratory Data Analysis with MATLAB,https://www.coursera.org/learn/exploratory-data-analysis-matlab,4.8,"30,459","Erin Byrne,Michael Reardon,Maria Gavilan-Alfonso,Brandon Armstrong,Nikola Trica,Cris LaPierre,Adam Filion,Heather Gorr",19 hours,Beginner,,"In this course, you will learn to think like a data scientist and ask questions of your data. You will use interactive features in MATLAB to extract subsets of data and to compute statistics on groups of related data. You will learn to use. MATLAB to automatically generate code so you can learn syntax as you explore. You will also use interactive documents, called live scripts,. to capture the steps of your analysis, communicate the results, and provide interactive controls allowing others to experiment by selecting groups of data. These skills are valuable for those who have domain knowledge and some exposure to computational tools, but no programming background is required. To be successful in this course, you should have some knowledge of basic statistics (e.g., histograms, averages, standard deviation, curve fitting, interpolation). By the end of this course, you will be able to load data into MATLAB, prepare it for analysis, visualize it, perform basic computations, and communicate your results to others. In your last assignment, you will combine these skills to assess damages following a severe weather event and communicate a polished recommendation based on your analysis of the data. You will be able to visualize the location of these events on a geographic map and create sliding controls allowing you to quickly visualize how a phenomenon changes over time.",Data Analysis          Data Visualization (DataViz)          Matlab      ,Data Science,MathWorks,Enroll for Free,Practical Data Science with MATLAB Specialization,"Erin Byrne work for MathWorks,Michael Reardon work for MathWorks,Maria Gavilan-Alfonso work for MathWorks,Brandon Armstrong work for MathWorks,Nikola Trica work for MathWorks,Cris LaPierre work for MathWorks,Adam Filion work for MathWorks,Heather Gorr work for MathWorks","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Exploratory Data Analysis,https://www.coursera.org/learn/exploratory-data-analysis,4.7,"163,189","Roger D. Peng, PhD,Jeff Leek, PhD,Brian Caffo, PhD",55 hours,,,Understand analytic graphics and the base plotting system in R. Use advanced graphing systems such as the Lattice system. Make graphical displays of very high dimensional data. Apply cluster analysis techniques to locate patterns in data,Cluster Analysis          Ggplot2          R Programming          Exploratory Data Analysis      ,Data Science,Johns Hopkins University,Enroll for Free,,"Roger D. Peng, PhD work for Johns Hopkins University,Jeff Leek, PhD work for Johns Hopkins University,Brian Caffo, PhD work for Johns Hopkins University","Arabic, French, Portuguese (European), Chinese (Simplified), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Executive Data Science Capstone,https://www.coursera.org/learn/executive-data-science-capstone,4.7,"13,477","Jeff Leek, PhD,Brian Caffo, PhD,Roger D. Peng, PhD",2 hours,,,Apply your learning to a real-world scenario. Lead a virtual data science team. Manage a complex analysis project from start to finish. Prepare and submit a final presentation,Data Science          Data Analysis          Management          Data Management      ,Business,Johns Hopkins University,Enroll for Free,Executive Data Science Specialization,"Jeff Leek, PhD work for Johns Hopkins University,Brian Caffo, PhD work for Johns Hopkins University,Roger D. Peng, PhD work for Johns Hopkins University","English, Thai"
Excel Fundamentals for Data Analysis,https://www.coursera.org/learn/excel-data-analysis-fundamentals,4.8,"67,987","Nicky Bull,Dr Prashan S. M. Karunaratne",15 hours,Intermediate,,"Use Excel tools and functions to clean and prepare data for analysis. Use Named Ranges and Tables to automate your analysis. Understand the different types of data in Excel and use appropriate functions to work with them. Use logical and lookup functions to transform, link and categorise data.",Data Analysis          Microsoft Excel          Data Cleansing      ,Business,Macquarie University,Enroll for Free,Excel Skills for Data Analytics and Visualization Specialization,"Nicky Bull work for Macquarie University,Dr Prashan S. M. Karunaratne work for Macquarie University","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Visualization in Excel,https://www.coursera.org/learn/excel-data-visualization,4.9,"13,013","Nicky Bull,Dr Prashan S. M. Karunaratne",18 hours,Intermediate,We expect that you have some background with Excel. You can move around the interface and create basic formulas.,"In an age now driven by ""big data"", we need to cut through the noise and present key information in a way that can be quickly consumed and acted upon making data visualization an increasingly important skill. Visualizations need to not only present data in an easy to understand and attractive way, but they must also provide context for the data, tell a story, achieving that fine balance between form and function. Excel has many rivals in this space, but it is still an excellent choice, particularly if it's where your data resides. It offers a wealth of tools for creating visualizations other than charts and the chart options available are constantly increasing and improving, so the newer versions now include waterfall charts, sunburst diagrams and even map charts. But what sets Excel apart is its flexibility, it gives us total creative control over our designs so if needed we could produce our own animated custom chart to tell the right story for our data. Over five weeks we will explore Excel's rich selection of visualization tools using practical case studies as seen through the eyes of Rohan, an environmental analyst. Rohan is required to produce visualizations that will show trends, forecasts, breakdowns and comparisons for a large variety of environmental data sets. As well as utilising the usual chart types he wants to use conditional formats, sparklines, specialised charts and even create his own animated charts and infographics. In some cases, he will also need to prepare the data using pivot tables to drill down and answer very specific questions. We are going to help him achieve all this and present our finished visualizations in attractive reports and dashboards that use tools like slicers and macros for automation and interactivity.These are the topics we will cover:Week 1: 	Dynamic visualizations with conditional formatting, custom number formatting, sparklines and macrosWeek 2: 	Charting techniques for telling the right storyWeek 3: 	Creating specialised and custom chartsWeek 4: 	Summarising and filtering data with pivot tables and pivot chartsWeek 5: 	Creating interactive dashboards in ExcelThis is the second course in our Specialization on Data Analytics and Visualization. The first course: Excel Fundamentals for Data Analysis, covers data preparation and cleaning but also teaches some of the prerequisites for this course like tables and named ranges as well as text, lookup and logical functions. To get the most out of this course we would recommend you do the first course or have experience with these topics. In this course we focus on Data Visualization in Excel, join us for this exciting journey.",Microsoft Excel          Data Visualization (DataViz)      ,Business,Macquarie University,Enroll for Free,Excel Skills for Data Analytics and Visualization Specialization,"Nicky Bull work for Macquarie University,Dr Prashan S. M. Karunaratne work for Macquarie University",English
Introduction to Data Analysis Using Excel,https://www.coursera.org/learn/excel-data-analysis,4.7,"209,592",Sharad Borle,20 hours,,,"The use of Excel is widespread in the industry. It is a very powerful data analysis tool and almost all big and small businesses use Excel in their day to day functioning. This is an introductory course in the use of Excel and is designed to give you a working knowledge of Excel with the aim of getting to use it for more advance topics in Business Statistics later. The course is designed keeping in mind two kinds of learners -. those who have very little functional knowledge of Excel and those who use Excel regularly but at a peripheral level and wish to enhance their skills. The course takes you from basic operations such as reading data into excel using various data formats, organizing and manipulating data, to some of the more advanced functionality of Excel. All along, Excel functionality is introduced using easy to understand examples which are demonstrated in a way that learners can become comfortable in understanding and applying them. To successfully complete course assignments, students must have access to a Windows version of Microsoft Excel 2010 or later. ________________________________________WEEK 1Module 1: Introduction to SpreadsheetsIn this module, you will be introduced to the use of Excel spreadsheets and various basic data functions of Excel.Topics covered include:•	Reading data into Excel using various formats•	Basic functions in Excel, arithmetic as well as various logical functions•	Formatting rows and columns•	Using formulas in Excel and their copy and paste using absolute and relative referencing________________________________________WEEK 2Module 2: Spreadsheet Functions to Organize DataThis module introduces various Excel functions to organize and query data. Learners are introduced to the IF, nested IF, VLOOKUP and the HLOOKUP functions of Excel. Topics covered include:•	IF and the nested IF functions•	VLOOKUP and HLOOKUP•	The RANDBETWEEN function________________________________________WEEK 3Module 3: Introduction to Filtering, Pivot Tables, and ChartsThis module introduces various data filtering capabilities of Excel. You’ll learn how to set filters in data to selectively access data. A very powerful data summarizing tool, the Pivot Table, is also explained and we begin to introduce the charting feature of Excel.Topics covered include:•	VLOOKUP across worksheets•	Data filtering in Excel•	Use of Pivot tables with categorical as well as numerical data•	Introduction to the charting capability of Excel________________________________________WEEK 4Module 4: Advanced Graphing and ChartingThis module explores various advanced graphing and charting techniques available in Excel. Starting with various line, bar and pie charts we introduce pivot charts, scatter plots and histograms. You will get to understand these various charts and get to build them on your own.Topics covered include•	Line, Bar and Pie charts•	Pivot charts•	Scatter plots•	Histograms",Lookup Table          Data Analysis          Microsoft Excel          Pivot Table      ,Data Science,Rice University,Enroll for Free,Business Statistics and Analysis Specialization,Sharad Borle work for Rice University,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Excel Basics for Data Analysis,https://www.coursera.org/learn/excel-basics-data-analysis-ibm,4.8,"66,437","Sandip Saha Joy,Steve Ryan",12 hours,Beginner,,The fundamentals of spreadsheet applications. How to perform basic spreadsheet tasks. About the importance of data quality. How to import file data into Excel,Data Science          Spreadsheet          Microsoft Excel          Data Analysis          Pivot Table      ,Data Science,IBM,Enroll for Free,,"Sandip Saha Joy work for IBM,Steve Ryan work for IBM, SkillUP","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
"ETL and Data Pipelines with Shell, Airflow and Kafka",https://www.coursera.org/learn/etl-and-data-pipelines-shell-airflow-kafka,4.8,"2,936","Yan Luo,Jeff Grossman,Sabrina Spillner,Ramesh Sannareddy",13 hours,Beginner,,"Describe and contrast Extract, Transform, Load (ETL) processes and Extract, Load, Transform (ELT) processes. Explain batch vs concurrent modes of execution. Describe how shell scripting can be used to implement an ETL pipeline. Describe data pipeline components, processes, tools, and technologies.","Extraction, Transformation And Loading (ETL)          Apache Kafka          Apache Airflow          Data Pipelines      ",Information Technology,IBM,Enroll for Free,,"Yan Luo work for IBM,Jeff Grossman work for IBM,Sabrina Spillner work for IBM,Ramesh Sannareddy work for IBM",English
Ethical Issues in Data Science,https://www.coursera.org/learn/ethical-issues-data-science,4.4,,Bobby Schnabel,23 hours,Beginner,No specific background necessary.,Learners will be able to Identify and manage ethical situations that may arise in their careers. Learnerrs will be able to apply ethical frameworks to help them analyze ethical challenges. Learners will be familiar with key applications of data science that are commonly  linked to ethical issues.,Data Science          Ethics          Algorithms          Privacy          Philosophy      ,Data Science,University of Colorado Boulder,Enroll for Free,Vital Skills for Data Science Specialization,Bobby Schnabel work for University of Colorado Boulder,English
Communicate Effectively about Ethical Challenges in Data-Driven Technologies,https://www.coursera.org/learn/ethical-communication-data-driven-technologies,4.4,"3,008","Renée Cummings,Jennifer Fischer,Megan Smith Branch",14 hours,Beginner,General business knowledge. ,"Develop inclusive strategies to clearly communicate the business impacts of ethical risks to diverse stakeholders. Design communication strategies that are diverse, equitable, and inclusive. Design a crisis communication plan to manage internal and external stakeholders during an ethical controversy.",Marketing          Business Strategy          Leadership And Management          Communication          Crisis Management      ,Data Science,CertNexus,Enroll for Free,CertNexus Certified Ethical Emerging Technologist Professional Certificate,"Renée Cummings work for CertNexus,Jennifer Fischer work for CertNexus,Megan Smith Branch work for CertNexus",English
Create and Lead an Ethical Data-Driven Organization,https://www.coursera.org/learn/ethical-data-driven-technology-leader,4.5,"2,951","Aaron Hui,Abhishek Gupta,Megan Smith Branch",13 hours,Beginner,General business knowledge. ,"Lead an applied ethics initiative, and champion its crucial importance. Promote an ethical organizational culture.  Develop and implement ethical organizational policies and a code of ethics. Evaluate the effectiveness of a code of ethics with internal and external stakeholders.",Code of Ethics          policy          Ethical Leadership          Ethics Of Artificial Intelligence          governance      ,Data Science,CertNexus,Enroll for Free,CertNexus Certified Ethical Emerging Technologist Professional Certificate,"Aaron Hui work for CertNexus,Abhishek Gupta work for CertNexus,Megan Smith Branch work for CertNexus",English
Enterprise Database Migration,https://www.coursera.org/learn/enterprise-database-migration,,"2,078",Google Cloud Training,19 hours,Intermediate,,"Plan, execute, test, and monitor simple and complex enterprise database migrations to Google Cloud.  Choose an appropriate Google Cloud database, migrate SQL Server databases and run Oracle databases on Google Cloud bare metal. Recognize and overcome the challenges of moving data to prevent data loss, preserve data integrity, and minimize downtime. Evaluate on-premises database architectures and plan migrations. Make the business case for moving databases to Google Cloud.",,Information Technology,Google Cloud,Enroll for Free,,Google Cloud Training work for Google Cloud,Subtitles: English
Amazon DynamoDB: Building NoSQL Database-Driven Applications,https://www.coursera.org/learn/dynamodb-nosql-database-driven-apps,4.7,"10,277","Seph Robinson,Morgan Willis",10 hours,Intermediate,,"How NoSQL databases differ from relational databases. How to provision, manage and interact with a DynamoDB table. How to secure a DynamoDB database",NoSQL Database          Cryptography          Workload          security          Recovery      ,Information Technology,Amazon Web Services,Enroll for Free,,"Seph Robinson work for Amazon Web Services,Morgan Willis work for Amazon Web Services","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Web Application Technologies and Django,https://www.coursera.org/learn/django-database-web-apps,4.7,"57,056",Charles Russell Severance,15 hours,Intermediate,,Explain the basics of HTTP and how the request-response cycle works. Install and deploy a simple DJango application. Build simple web pages in HTML and style them using CSS. Explain the basic operations in SQL,Cascading Style Sheets (CCS)          Html          Hypertext Transfer Protocol (HTTP)          SQL          Django (Web Framework)      ,Computer Science,University of Michigan,Enroll for Free,Django for Everybody Specialization,Charles Russell Severance work for University of Michigan,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
"Developing Applications with SQL, Databases, and Django ",https://www.coursera.org/learn/developing-applications-with-sql-databases-and-django,4.5,"4,370","Yan Luo,Rav Ahuja",15 hours,Intermediate,"Knowledge of GitHub, HTML & CSS, Python","Describe a database and how to model data. Compose SQL queries to insert, select, update, and delete data in a database.. Understand Object Relational Model (ORM). Integrate Bootstrap into your Django template and build interactive web pages.",Django (Web Framework)          Database (DBMS)          Cloud Applications          SQL      ,Information Technology,IBM,Enroll for Free,IBM Full Stack Cloud Developer Professional Certificate,"Yan Luo work for IBM,Rav Ahuja work for Coursera, IBM",English
Serverless Data Processing with Dataflow: Develop Pipelines,https://www.coursera.org/learn/developing-pipelines-on-dataflow,4,,Google Cloud Training,19 hours,Advanced,,"In this second installment of the Dataflow course series, we are going to be diving deeper on developing pipelines using the Beam SDK. We start with a review of Apache Beam concepts. Next, we discuss processing streaming data using windows, watermarks and triggers. We then cover options for sources and sinks in your pipelines, schemas to express your structured data, and how to do stateful transformations using State and Timer APIs. We move onto reviewing best practices that help maximize your pipeline performance. Towards the end of the course, we introduce SQL and Dataframes to represent your business logic in Beam and how to iteratively develop pipelines using Beam notebooks.",,Data Science,Google Cloud,Enroll for Free,Serverless Data Processing with Dataflow Specialization,Google Cloud Training work for Google Cloud,Subtitles: English
Design Thinking and Predictive Analytics for Data Products,https://www.coursera.org/learn/design-thinking-predictive-analytics-data-products,4.5,"7,810","Julian McAuley,Ilkay Altintas",8 hours,Intermediate,,"This is the second course in the four-course specialization Python Data Products for Predictive Analytics, building on the data processing covered in Course 1 and introducing the basics of designing predictive models in Python. In this course, you will understand the fundamental concepts of statistical learning and learn various methods of building predictive models. At each step in the specialization, you will gain hands-on experience in data manipulation and building your skills, eventually culminating in a capstone project encompassing all the concepts taught in the specialization.",,Data Science,University of California San Diego,Enroll for Free,Python Data Products for Predictive Analytics Specialization,"Julian McAuley work for University of California San Diego,Ilkay Altintas work for University of California San Diego","Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Visualization,https://www.coursera.org/learn/datavisualization,4.5,"106,764",John C. Hart,15 hours,,,"Learn the general concepts of data mining along with basic methodologies and applications. Then dive into one subfield in data mining: pattern discovery. Learn in-depth concepts, methods, and applications of pattern discovery in data mining. We will also introduce methods for pattern-based classification and some interesting applications of pattern discovery. This course provides you the opportunity to learn skills and content to practice and engage in scalable pattern discovery methods on massive transactional data, discuss pattern evaluation measures, and study methods for mining diverse kinds of patterns, sequential patterns, and sub-graph patterns.",Data Visualization Software          Tableau Software          Data Virtualization          Data Visualization (DataViz)      ,Data Science,University of Illinois at Urbana-Champaign,Enroll for Free,Data Mining  Specialization,John C. Hart work for University of Illinois at Urbana-Champaign,"Arabic, French, Portuguese (European), Chinese (Simplified), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Essential Design Principles for Tableau,https://www.coursera.org/learn/dataviz-design,4.5,"44,724","Govind Acharya,Hunter Whitney",13 hours,Beginner,Comfortable working with data and datasets.,Examine and improve an ineffective visualization.  Examine and improve an ineffective visualization.  Apply visualization best practices.  Create and design visualizations that work best for the target audience,Data Analysis          Tableau Software          Data Virtualization          Data Visualization (DataViz)      ,Data Science,"University of California, Davis",Enroll for Free,Data Visualization with Tableau Specialization,"Govind Acharya work for University of California, Davis,Hunter Whitney work for University of California, Davis","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Visualization with Tableau Project,https://www.coursera.org/learn/dataviz-project,4.6,"21,711","Suk S. Brar, M.B.A.,Hunter Whitney",12 hours,Intermediate, Familiar with Tableau and comfortable working with data and datasets.      ,Develop a project proposal.  Assess the quality of the data and perform exploratory analysis.  Create KPIs and dashboards and assess your analysis.  Create your data story and write a narrative to accompany your visualization,Data Analysis          Interactive Visualization          Tableau Software          Data Visualization (DataViz)      ,Data Science,"University of California, Davis",Enroll for Free,Data Visualization with Tableau Specialization,"Suk S. Brar, M.B.A. work for University of California, Davis,Hunter Whitney work for University of California, Davis","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Visual Analytics with Tableau,https://www.coursera.org/learn/dataviz-visual-analytics,4.6,"40,234","Suk S. Brar, M.B.A.",9 hours,Beginner, Must be comfortable working with data and datasets.  ,Create a chart using Tableau.  Create dates using calculated fields.  Customize table calculations.  Customize and create dual layer maps,Visual Analytics          Map          Tableau Software          Data Visualization (DataViz)      ,Data Science,"University of California, Davis",Enroll for Free,Data Visualization with Tableau Specialization,"Suk S. Brar, M.B.A. work for University of California, Davis","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Creating Dashboards and Storytelling with Tableau,https://www.coursera.org/learn/dataviz-dashboards,4.6,"37,540","Govind Acharya,Hunter Whitney",15 hours,Beginner,Familiar with Tableau and comfortable working with data and datasets.    ,Combine the data and follow the best practices to present your story.  Create calculated fields for KPIs to build a figure that will be used to measure progress in the data. Assemble a dashboard.  Analyze concepts and techniques for compelling storytelling with data,Storyboarding          Tableau Software          Data Virtualization          Data Visualization (DataViz)      ,Data Science,"University of California, Davis",Enroll for Free,Data Visualization with Tableau Specialization,"Govind Acharya work for University of California, Davis,Hunter Whitney work for University of California, Davis","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
"Data Wrangling, Analysis and AB Testing with SQL",https://www.coursera.org/learn/data-wrangling-analysis-abtesting,3.5,"30,012",Katrina Glaeser,16 hours,Intermediate,Some statistics is recommended and at least 2-years business experience.,Validate and clean a dataset. Assess and create datasets to answer your questions. Solve problems using SQL. Build a simple testing framework to touch on AB Testing,A/B Testing          Query String          Data Analysis          Predictive Analytics          SQL      ,Data Science,"University of California, Davis",Enroll for Free,Learn SQL Basics for Data Science Specialization,"Katrina Glaeser work for University of California, Davis","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Science in Stratified Healthcare and Precision Medicine,https://www.coursera.org/learn/datascimed,4.6,"16,288","Dr Areti Manataki,Dr Frances Wong",17 hours,Intermediate,,"An increasing volume of data is becoming available in biomedicine and healthcare, from genomic data, to electronic patient records and data collected by wearable devices. Recent advances in data science are transforming the life sciences, leading to precision medicine and stratified healthcare.  In this course, you will learn about some of the different types of data and computational methods involved in stratified healthcare and precision medicine. You will have a hands-on experience of working with such data. And you will learn from leaders in the field about successful case studies. Topics include: (i) Sequence Processing, (ii) Image Analysis, (iii) Network Modelling, (iv) Probabilistic Modelling, (v) Machine Learning, (vi) Natural Language Processing, (vii) Process Modelling and (viii) Graph Data.Watch the course promo video here: http://edin.ac/2pn350P",Data Science          Python Programming          Machine Learning          Image Analysis      ,Data Science,The University of Edinburgh,Enroll for Free,,"Dr Areti Manataki work for The University of Edinburgh,Dr Frances Wong work for The University of Edinburgh","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Science at Scale - Capstone Project,https://www.coursera.org/learn/datasci-capstone,4.1,"2,239",Bill Howe,6 hours,,,"In the capstone, students will engage on a real world project requiring them to apply skills from the entire data science pipeline: preparing, organizing, and transforming data, constructing a model, and evaluating results. Through a collaboration with Coursolve, each Capstone project is associated with partner stakeholders who have a vested interest in your results and are eager to deploy them in practice. These projects will not be straightforward and the outcome is not prescribed -- you will need to tolerate ambiguity and negative results!. But we believe the experience will be rewarding and will better prepare you for data science projects in practice.",Python Programming          R Programming          Data Analysis          Data Wrangling          Statistics      ,Data Science,University of Washington,Enroll for Free,Data Science at Scale Specialization,Bill Howe work for University of Washington,English
Database Management Essentials,https://www.coursera.org/learn/database-management,4.6,"160,973",Michael Mannino,36 hours,Intermediate,,"Database Management Essentials provides the foundation you need for a career in database development, data warehousing, or business intelligence, as well as for the entire Data Warehousing for Business Intelligence specialization. In this course, you will create relational databases, write SQL statements to extract information to satisfy business reporting requests, create entity relationship diagrams (ERDs) to design databases, and analyze table designs for excessive redundancy. As you develop these skills, you will use either Oracle, MySQL, or PostgreSQL to execute SQL statements and a database diagramming tool such as the ER Assistant or Visual Paradigm to create ERDs. We’ve designed this course to ensure a common foundation for specialization learners. Everyone taking the course can jump right in with writing SQL statements in Oracle, MySQL, or PostgreSQL.",Database (DB) Design          Entity–Relationship (E-R) Model          Database (DBMS)          SQL      ,Computer Science,University of Colorado System,Enroll for Free,Data Warehousing for Business Intelligence Specialization,Michael Mannino work for University of Colorado System,"Arabic, French, Portuguese (European), Chinese (Simplified), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Database Design and Basic SQL in PostgreSQL,https://www.coursera.org/learn/database-design-postgresql,4.8,"10,016",Charles Russell Severance,14 hours,Intermediate,Completion of the first two courses in the Python for Everybody specialization or an equivalent basic understanding of Python,"Utilize psql and SQL commands to implement CRUD (Create, Read, Update, and Delete) operations for tables in a PostgreSQL database. Identify and utilize the functions of primary, logical, and foreign keys within a database.  Build and differentiate between one-to-many and many-to-many relationships within PostgreSQL. Recall key people, organizations, and innovations that were instrumental to building the SQL standard",,Computer Science,University of Michigan,Enroll for Free,PostgreSQL for Everybody Specialization,Charles Russell Severance work for University of Michigan,Subtitles: English
"Database Architecture, Scale, and NoSQL with Elasticsearch",https://www.coursera.org/learn/database-architecture-scale-nosql-elasticsearch-postgresql,4.3,"2,351",Charles Russell Severance,10 hours,Intermediate,Completion of first two courses in the Python for Everybody specialization or an equivalent basic understanding of Python,Understand PostgreSQL architecture; analyze and compare SQL and NoSQL. Compare and contrast ACID and BASE style architectures and databases. Create and utilize an Elasticsearch index in different contexts,,Computer Science,University of Michigan,Enroll for Free,PostgreSQL for Everybody Specialization,Charles Russell Severance work for University of Michigan,Subtitles: English
Data Science Math Skills,https://www.coursera.org/learn/datasciencemathskills,4.5,"289,819","Daniel Egger,Paul Bendich",13 hours,Beginner,,"Data science courses contain math—no avoiding that! This course is designed to teach learners the basic math you will need in order to be successful in almost any data science math course and was created for learners who have basic math skills but may not have taken algebra or pre-calculus. Data Science Math Skills introduces the core math that data science is built upon, with no extra complexity, introducing unfamiliar ideas and math symbols one-at-a-time.  Learners who complete this course will master the vocabulary, notation, concepts, and algebra rules that all data scientists must know before moving on to more advanced material.Topics include:~Set theory, including Venn diagrams~Properties of the real number line~Interval notation and algebra with inequalities~Uses for summation and Sigma notation~Math on the Cartesian (x,y) plane, slope and distance formulas~Graphing and describing functions and their inverses on the x-y plane,~The concept of instantaneous rate of change and tangent lines to a curve~Exponents, logarithms, and the natural log function.~Probability theory, including Bayes’ theorem.While this course is intended as a general introduction to the math skills needed for data science, it can be considered a prerequisite for learners interested in the course, ""Mastering Data Analysis in Excel,"" which is part of the Excel to MySQL Data Science Specialization. Learners who master Data Science Math Skills will be fully prepared for success with the more advanced math concepts introduced in ""Mastering Data Analysis in Excel."" Good luck and we hope you enjoy the course!",Bayes' Theorem          Bayesian Probability          Probability          Probability Theory      ,Math and Logic,Duke University,Enroll for Free,,"Daniel Egger work for Duke University,Paul Bendich work for Duke University","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Building Database Applications in PHP,https://www.coursera.org/learn/database-applications-php,4.9,"39,477",Charles Russell Severance,24 hours,Intermediate,,"In this course, we'll look at the object oriented patterns available in PHP. You'll learn how to connect to a MySQL using the Portable Data Objects (PDO) library and issue SQL commands in the the PHP language. We'll also look at how PHP uses cookies and manages session data. You'll learn how PHP avoids double posting data, how flash messages are implemented, and how to use a session to log in users in web applications. We'll then build the first 'complete' application that has multiple screens to Create, Read, Update and Delete (CRUD) our data. This brings all the previous concepts together and will form the basis for all later web applications. It is assumed that learners have already taken the Building Web Applications course in this specialization.","Hypertext Preprocessor (PHP)          Create, Read, Update And Delete          MySQL      ",Computer Science,University of Michigan,Enroll for Free,Web Applications for Everybody Specialization,Charles Russell Severance work for University of Michigan,"Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Modern Data Warehouse Analytics in Microsoft Azure,https://www.coursera.org/learn/data-warehouse-analytics-microsoft-azure,4.5,, Microsoft,4 hours,Beginner,"Successful students should start with some basic awareness of computing and Internet concepts, and an interest in extracting insights from data. ","Processing options for building data analytics solutions in Azure. You will explore Azure Synapse Analytics, Azure Databricks, and Azure HDInsight.",Describe data ingestion and processing on Azure          Describe the components of a modern data warehouse          Describe data visualization in Microsoft Power BI          Describe analytics workloads      ,Information Technology,Microsoft,Enroll for Free,Microsoft Azure Data Fundamentals DP-900 Exam Prep Specialization, Microsoft work for Microsoft,English
Fundamentals of Visualization with Tableau,https://www.coursera.org/learn/data-visualization-tableau,4.5,"139,052",Desiree' Abbott,11 hours,Beginner,Must be comfortable working with data and datasets.,Install Tableau Public Software and create a visualization.  Examine and navigate the Tableau Public workspace.  Practice and connect to different data sources.  Examine ways to define your project,Tableau Software          Data Virtualization          Data Visualization (DataViz)          Visualization (Computer Graphics)      ,Data Science,"University of California, Davis",Enroll for Free,Data Visualization with Tableau Specialization,"Desiree' Abbott work for University of California, Davis","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Publishing Visualizations in R with Shiny and flexdashboard,https://www.coursera.org/learn/data-viz-shiny-dashboards,4.9,"1,961",Collin Paschall,12 hours,,,"Data visualization is a critical skill for anyone that routinely using quantitative data in his or her work - which is to say that data visualization is a tool that almost every worker needs today. One of the critical tools for data visualization today is the R statistical programming language. Especially in conjunction with the tidyverse software packages, R has become an extremely powerful and flexible platform for making figures, tables, and reproducible reports. However, R can be intimidating for first time users, and there are so many resources online that it can be difficult to sort through without guidance. This course is the fourth in the Specialization ""Data Visualization and Dashboarding in R."" Learners will come to this course with a strong background in making visualization in R using ggplot2. To build on those skills, this course covers creating interactive visualization using Shiny, as well as combining different kinds of figures made in R into interactive dashboards.",,Data Science,Johns Hopkins University,Enroll for Free,Data Visualization & Dashboarding with R Specialization,Collin Paschall work for Johns Hopkins University,Subtitles: English
3D Data Visualization for Science Communication,https://www.coursera.org/learn/data-visualization-science-communication,,"3,010","Kalina Borkiewicz,AJ Christensen",32 hours,Beginner,,"This course is an introduction to 3D scientific data visualization, with an emphasis on science communication and cinematic design for appealing to broad audiences. You will develop visualization literacy, through being able to interpret/analyze (read) visualizations and create (write) your own visualizations. By the end of this course, you will:-Develop visualization literacy.-Learn the practicality of working with spatial data.-Understand what makes a scientific visualization meaningful.-Learn how to create educational visualizations that maintain scientific accuracy.-Understand what makes a scientific visualization cinematic.-Learn how to create visualizations that appeal to broad audiences.-Learn how to work with image-making software. (for those completing the Honors track)",,Data Science,University of Illinois at Urbana-Champaign,Enroll for Free,,"Kalina Borkiewicz work for University of Illinois at Urbana-Champaign,AJ Christensen work for University of Illinois at Urbana-Champaign",Subtitles: English
Design and Build a Data Warehouse for Business Intelligence Implementation,https://www.coursera.org/learn/data-warehouse-bi-building,4.6,"8,335","Michael Mannino,Jahangir Karimi",13 hours,,,"The capstone course, Design and Build a Data Warehouse for Business Intelligence Implementation, features a real-world case study that integrates your learning across all courses in the specialization. In response to business requirements presented in a case study, you’ll design and build a small data warehouse, create data integration workflows to refresh the warehouse, write SQL statements to support analytical and summary query requirements, and use the MicroStrategy business intelligence platform to create dashboards and visualizations. In the first part of the capstone course, you’ll be introduced to a medium-sized firm, learning about their data warehouse and business intelligence requirements and existing data sources. You’ll first architect a warehouse schema and dimensional model for a small data warehouse. You’ll then create data integration workflows using Pentaho Data Integration to refresh your data warehouse. Next, you’ll write SQL statements for analytical query requirements and create materialized views to support summary data management. For data integration workflows and analytical queries, you can use either Oracle or PostgreSQL. Finally, you will use MicroStrategy OLAP capabilities to gain insights into your data warehouse. In the completed project, you’ll have built a small data warehouse containing a schema design, data integration workflows, analytical queries, materialized views, dashboards and visualizations that you’ll be proud to show to your current and prospective employers.",Data Warehousing          Microstrategy          Data Warehouse          SQL      ,Data Science,University of Colorado System,Enroll for Free,Data Warehousing for Business Intelligence Specialization,"Michael Mannino work for University of Colorado System,Jahangir Karimi work for University of Colorado System","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Visualization with R,https://www.coursera.org/learn/data-visualization-r,,"1,852","Yiwen Li,Tiffany Zhu,Saishruthi Swaminathan,Gabriela de Queiroz",10 hours,Beginner,,"Create basic bar charts, histograms, pie charts, scatter plots, line plots, box plots, and maps using Rand related packages. Customize charts and plots using themes and faceting. Create maps using the Leaflet package for R. Create interactive dashboards using the Shiny package for R.",Data Science          Data Analysis          Data Visualization (DataViz)          R Programming      ,Data Science,IBM,Enroll for Free,,"Yiwen Li work for IBM,Tiffany Zhu work for IBM,Saishruthi Swaminathan work for IBM,Gabriela de Queiroz work for IBM",English
Data Visualization and Dashboards with Excel and Cognos,https://www.coursera.org/learn/data-visualization-dashboards-excel-cognos,4.7,"27,985","Sandip Saha Joy,Kevin McFaul,Steve Ryan",9 hours,Beginner,,Basic Excel features to create charts and pivot charts. The important role charts play in telling a data-driven story. About creating advanced charts and visualizations. About the basics of dashboarding,Microsoft Excel          Data Analysis          Data Visualization (DataViz)          IBM Cognos Analytics          Dashboard      ,Data Science,IBM,Enroll for Free,,"Sandip Saha Joy work for IBM,Kevin McFaul work for IBM,Steve Ryan work for IBM, SkillUP","Arabic, French, Portuguese (European), Vietnamese, Russian, English, Spanish"
Data Management and Visualization,https://www.coursera.org/learn/data-visualization,4.4,"75,026",Lisa Dierker,12 hours,,,"Whether being used to customize advertising to millions of website visitors or streamline inventory ordering at a small restaurant, data is becoming more integral to success. Too often, we’re not sure how use data to find answers to the questions that will make us more successful in what we do. In this course, you will discover what data is and think about what questions you have that can be answered by the data – even if you’ve never thought about data before. Based on existing data, you will learn to develop a research question, describe the variables and their relationships, calculate basic statistics, and present your results clearly. By the end of the course, you will be able to use powerful data analysis tools – either SAS or Python – to manage and visualize your data, including how to deal with missing data, variable groups, and graphs. Throughout the course, you will share your progress with others to gain valuable feedback, while also learning how your peers use data to answer their own questions.",SAS Language          Data Analysis          Python Programming          Data Management      ,Data Science,Wesleyan University,Enroll for Free,Data Analysis and Interpretation Specialization,Lisa Dierker work for Wesleyan University,"Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Data Structures and Design Patterns for Game Developers,https://www.coursera.org/learn/data-structures-design-patterns,4.6,"13,249","Dr. Tim ""Dr. T"" Chamillard",22 hours,Intermediate,,"This course is the fourth course in the specialization about learning how to develop video games using the C# programming language and the Unity game engine on Windows or Mac. Why use C# and Unity instead of some other language and game engine? Well, C# is a really good language for learning how to program and then programming professionally. Also, the Unity game engine is very popular with indie game developers; Unity games were downloaded 16,000,000,000 times in 2016! Finally, C# is one of the programming languages you can use in the Unity environment. This course assumes you have the prerequisite knowledge from the previous three courses in the specialization. You should make sure you have that knowledge, either by taking those previous courses or from personal experience, before tackling this course. The required prerequisite knowledge is listed in the ""Who this class is for"" section below. Throughout this course you'll build on your foundational C# and Unity knowledge by developing more robust games with better object-oriented designs using various data structures and design patterns.Data structures and design patterns are both general programming and software architecture topics that span all software, not just games. Although we'll discuss these ideas in the game domain, they also apply if you're writing a web app in ASP.NET, building a tool using WinForms, or any other software you decide to build. Module 1: Explore a Dynamic Array data structure and learn the basics of algorithm analysisModule 2: Learn about and use the common Linked List and Graph data structuresModule 3: Learn about and use several additional data structures: Stacks, Queues, and TreesModule 4: Learn why design patterns are so useful and discover a number of design patterns useful in game developmentModule 5: Complete final peer review“Unity” is a trademark or registered trademark of Unity Technologies or its affiliates in the U.S. and elsewhere.This course is an independent work and is not sponsored by, authorized by, or affiliated with Unity Technologies or its affiliates",,Computer Science,University of Colorado System,Enroll for Free,,"Dr. Tim ""Dr. T"" Chamillard work for Coursera, University of Colorado System","Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Visualization e manipolazione dei dati con Tableau,https://www.coursera.org/learn/data-visualization-manipolazione-tableau,,,Manuel Belgioioso,19 hours,Intermediate,Conoscenza degli strumenti base di Tableau,Combinare le fonti dati. Campi calcolati e parametri. Operazioni al livello della vista. Visualizzazioni geografiche,Visual Communication          Data Virtualization          Data Visualization (DataViz)          Visual Analytics          Tableau Software      ,Data Science,Università di Napoli Federico II,Enroll for Free,Data Visualization: Analisi dei dati con Tableau Specialization,Manuel Belgioioso work for Università di Napoli Federico II,Italian
Data Structures,https://www.coursera.org/learn/data-structures,4.6,"205,479","Alexander S. Kulikov,Michael Levin,Daniel M Kane,Neil Rhodes",25 hours,Intermediate,"Basic knowledge of at least one programming language: C++, Java, Python, C, C#, Javascript, Haskell, Kotlin, Ruby, Rust, Scala. ","A good algorithm usually comes together with a set of good data structures that allow the algorithm to manipulate the data efficiently. In this online course, we consider the common data structures that are used in various computational problems. You will learn how these data structures are implemented in different programming languages and will practice implementing them in our programming assignments. This will help you to understand what is going on inside a particular built-in implementation of a data structure and what to expect from it. You will also learn typical use cases for these data structures. A few examples of questions that we are going to cover in this class are the following:1. What is a good strategy of resizing a dynamic array?2. How priority queues are implemented in C++, Java, and Python?3. How to implement a hash table so that the amortized running time of all operations is O(1) on average?4. What are good strategies to keep a binary tree balanced? You will also learn how services like Dropbox manage to upload some large files instantly and to save a lot of storage space!",Binary Search Tree          Priority Queue          Hash Table          Stack (Abstract Data Type)          List      ,Computer Science,"University of California San Diego,HSE University",Enroll for Free,Data Structures and Algorithms Specialization,"Alexander S. Kulikov work for University of California San Diego, Saint Petersburg State University,Michael Levin work for University of California San Diego, HSE University,Daniel M Kane work for University of California San Diego,Neil Rhodes work for University of California San Diego","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Structures and Performance,https://www.coursera.org/learn/data-structures-optimizing-performance,4.8,"84,794","Christine Alvarado,Mia Minnes,Leo Porter",42 hours,Intermediate,,"How do Java programs deal with vast quantities of data? Many of the data structures and algorithms that work with introductory toy examples break when applications process real, large data sets. Efficiency is critical, but how do we achieve it, and how do we even measure it?. This is an intermediate Java course. We recommend this course to learners who have previous experience in software development or a background in computer science, and in particular, we recommend that you have taken the first course in this specialization (which also requires some previous experience with Java). In this course, you will use and analyze data structures that are used in industry-level applications, such as linked lists, trees, and hashtables. You will explain how these data structures make programs more efficient and flexible. You will apply asymptotic Big-O analysis to describe the performance of algorithms and evaluate which strategy to use for efficient data retrieval, addition of new data, deletion of elements, and/or memory usage.The program you will build throughout this course allows its user to manage, manipulate and reason about large sets of textual data. This is an intermediate Java course, and we will build on your prior knowledge. This course is designed around. the same video series as in our first course in this specialization, including explanations of core content, learner videos, student and engineer testimonials, and support videos -- to better allow you to choose your own path through the course!",Trees (Data Structures)          Data Structure          Linked List          Binary Tree      ,Computer Science,University of California San Diego,Enroll for Free,,"Christine Alvarado work for University of California San Diego,Mia Minnes work for University of California San Diego,Leo Porter work for University of California San Diego","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Data Visualization Capstone,https://www.coursera.org/learn/data-visualization-capstone,4.9,,Collin Paschall,22 hours,,,"Data visualization is a critical skill for anyone that routinely using quantitative data in his or her work - which is to say that data visualization is a tool that almost every worker needs today. One of the critical tools for data visualization today is the R statistical programming language. Especially in conjunction with the tidyverse software packages, R has become an extremely powerful and flexible platform for making figures, tables, and reproducible reports. However, R can be intimidating for first time users, and there are so many resources online that it can be difficult to sort through without guidance. This is the final course in the Specialization ""Data Visualization and Dashboarding in R."" Learners in this course will enter with a well-developed set of skills making a wide variety of visualizations in R. The focus on this course will applying those skills to a unique project, drawing on publicly available data to tell a compelling story using the data visualization toolkit assembled in the previous courses.",,Data Science,Johns Hopkins University,Enroll for Free,Data Visualization & Dashboarding with R Specialization,Collin Paschall work for Johns Hopkins University,Subtitles: English
"Data, Security, and Privacy",https://www.coursera.org/learn/data-security-privacy,,,Tim Carrington,13 hours,Beginner,"Computer Science, Information Technology, Marketing, Business","Students will learn digital literacy, how to use the internet as a productivity tool, and how to manage security threats and protect data.",Protecting Data          digital literacy          Evaluating IT Security Risk          Cyber Security Planning      ,Information Technology,"University of California, Irvine",Enroll for Free,Introduction to Computer Information Systems Specialization,"Tim Carrington work for University of California, Irvine",English
Data Science Methodology,https://www.coursera.org/learn/data-science-methodology,4.6,"164,737","Alex Aklson,Polong Lin",8 hours,Beginner,,"Describe what a methodology is and why data scientists need a methodology.  Describe the six stages in the Cross Industry Process for Data Mining (CRISP-DM) methodology including Business Understanding and Data Understanding. Describe some of the use cases for different analytic models and approaches, such as Predictive, Descriptive, and Classification models.  Explain the importance of identifying the correct sources of data for your data science project.",Data Science          Data Mining          Methodology      ,Data Science,IBM,Enroll for Free,,"Alex Aklson work for IBM,Polong Lin work for IBM","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish, Persian"
Data Science on Google Cloud: Machine Learning,https://www.coursera.org/learn/data-science-machine-learning-google-cloud,,,Google Cloud Training,7 hours,Advanced,,"Activities in these self-paced labs are derived from the exercises from the book Data Science on Google Cloud Platform by Valliappa Lakshmanan, published by O'Reilly Media, Inc. In this Google Cloud Labs Series, covering chapter 9 through the end of the book, you run full-fledged machine learning jobs with state-of-the-art tools and real-world data sets, all using Google Cloud tools and services. Note: you will have timed access to the online environment. You will need to complete the lab within the allotted time.",Tensorflow          Machine Learning          Distributed Machine Learning          Spark      ,Data Science,Google Cloud,Enroll,,Google Cloud Training work for Google Cloud,English
The Data Scientist’s Toolbox,https://www.coursera.org/learn/data-scientists-tools,4.6,"653,843","Jeff Leek, PhD,Roger D. Peng, PhD,Brian Caffo, PhD",18 hours,,,"Set up R, R-Studio, Github and other useful tools. Understand the data, problems, and tools that data analysts use. Explain essential study design concepts. Create a Github repository",Data Science          Github          R Programming          Rstudio      ,Data Science,Johns Hopkins University,Enroll for Free,,"Jeff Leek, PhD work for Johns Hopkins University,Roger D. Peng, PhD work for Johns Hopkins University,Brian Caffo, PhD work for Johns Hopkins University","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Data Science Capstone,https://www.coursera.org/learn/data-science-project,4.5,"33,998","Jeff Leek, PhD,Roger D. Peng, PhD,Brian Caffo, PhD",6 hours,,,Create a useful data product for the public. Apply your exploratory data analysis skills. Build an efficient and accurate prediction model. Produce a presentation deck to showcase your findings,Data Science          Machine Learning          R Programming          Natural Language Processing      ,Data Science,Johns Hopkins University,Enroll for Free,,"Jeff Leek, PhD work for Johns Hopkins University,Roger D. Peng, PhD work for Johns Hopkins University,Brian Caffo, PhD work for Johns Hopkins University","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Data Science with R - Capstone Project,https://www.coursera.org/learn/data-science-with-r-capstone-project,,,"Jeff Grossman,Yan Luo",15 hours,Intermediate,,"Prepare data for modelling by handling missing values, formatting and normalizing data, binning, and turning categorical values into numeric values. Conduct exploratory data analysis using descriptive statistics, data grouping, data analysis and correlation statistics.",Data Science          R Programming          Data Visualization (DataViz)          Linear Regression          Exploratory Data Analysis      ,Data Science,IBM,Enroll for Free,,"Jeff Grossman work for IBM,Yan Luo work for IBM",English
Data Science Ethics,https://www.coursera.org/learn/data-science-ethics,4.8,"23,952",H.V. Jagadish,15 hours,Beginner,,"What are the ethical considerations regarding the privacy and control of consumer information and big data, especially in the aftermath of recent large-scale data breaches?. This course provides a framework to analyze these concerns as you examine the ethical and privacy implications of collecting and managing big data. Explore the broader impact of the data science field on modern society and the principles of fairness, accountability and transparency as you gain a deeper understanding of the importance of a shared set of ethical values. You will examine the need for voluntary disclosure when leveraging metadata to inform basic algorithms and/or complex artificial intelligence systems while also learning best practices for responsible data management, understanding the significance of the Fair Information Practices Principles Act and the laws concerning the ""right to be forgotten.""This course will help you answer questions such as who owns data, how do we value privacy, how to receive informed consent and what it means to be fair.Data scientists and anyone beginning to use or expand their use of data will benefit from this course. No particular previous knowledge needed.",,Data Science,University of Michigan,Enroll for Free,,H.V. Jagadish work for University of Michigan,"Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Introduction to Data Science and scikit-learn in Python,https://www.coursera.org/learn/data-science-and-scikit-learn-in-python,,,"Sabrina Moore,Rajvir Dua,Neelesh Tiruviluamala",14 hours,Beginner,N​one,"Employ artificial intelligence techniques to test hypothesis in Python. Apply a machine learning model combining Numpy, Pandas, and Scikit-Learn",Data Science          Machine Learning          regression          Statistical Hypothesis Testing          medical data      ,Data Science,LearnQuest,Enroll for Free,AI for Scientific Research Specialization,"Sabrina Moore work for LearnQuest,Rajvir Dua work for LearnQuest,Neelesh Tiruviluamala work for LearnQuest",English
Data Science for Business Innovation,https://www.coursera.org/learn/data-science-for-business-innovation,4.3,"7,850","Marco Brambilla,Emanuele Della Valle",7 hours,Beginner,,"What is data science. How data science, machine learning, and data-driven innovation can benefit business outcomes. Foundational concepts and intuitions about machine learning techniques",Data Science          Business Analytics          Decision-Making          Data Analysis          Big Data      ,Data Science,"EIT Digital ,Politecnico di Milano",Enroll for Free,,"Marco Brambilla work for EIT Digital ,Emanuele Della Valle work for EIT Digital ","French, Portuguese (European), Russian, English, Spanish"
Data Science on Google Cloud,https://www.coursera.org/learn/data-science-google-cloud,,,Google Cloud Training,11 hours,Advanced,,"and practice all aspects of ingestion, preparation, processing, querying, exploring and visualizing data sets using Google Cloud tools.",Data ingestion          Bigquery          Data Processing          Data Visualization (DataViz)          SQL      ,Data Science,Google Cloud,Enroll,,Google Cloud Training work for Google Cloud,English
Data Science as a Field,https://www.coursera.org/learn/data-science-as-a-field,,,Jane Wall,10 hours,Intermediate,Knowledge of R required and knowledge of tidyverse is helpful.,"By taking this course, you will be able explain what data science is and identify the key disciplines involved. You will be able to use the steps of the data science process to create a reproducible data analysis and identify personal biases. You will be able to identify interesting data science applications, locate jobs in Data Science, and begin developing a professional network.",Data Science          Applied Mathematics          Information Science          Statistics          Computer Science      ,Data Science,University of Colorado Boulder,Enroll for Free,Vital Skills for Data Science Specialization,Jane Wall work for University of Colorado Boulder,English
A Crash Course in Data Science,https://www.coursera.org/learn/data-science-course,4.5,"179,037","Jeff Leek, PhD,Brian Caffo, PhD,Roger D. Peng, PhD",7 hours,Beginner,,Describe Data Science’s role in various contexts. Understand how Statistics and Machine Learning affect Data Science. Use the key terms used by data scientist. Predict whether a Data Science project will be successful,Data Science          Data Analysis          Machine Learning          Project      ,Data Science,Johns Hopkins University,Enroll for Free,Executive Data Science Specialization,"Jeff Leek, PhD work for Johns Hopkins University,Brian Caffo, PhD work for Johns Hopkins University,Roger D. Peng, PhD work for Johns Hopkins University","Chinese (Traditional), Arabic, French, Portuguese (European), Italian, Vietnamese, German, Urdu, Russian, Turkish, English, Spanish, Hindi"
Data Science Fundamentals for Data Analysts,https://www.coursera.org/learn/data-science-fundamentals-for-data-analysts,3.7,"3,085","Emma Freeman,Mark Roepke",19 hours,Intermediate,Intermediate-level experience with SQL,"Apply foundational data science concepts and techniques to solve these real-world problems.  Design, execute, assess, and communicate the results of your very own data science projects.",Data Science          Data Analysis          Machine Learning      ,Data Science,Databricks,Enroll for Free,Data Science with Databricks for Data Analysts Specialization,"Emma Freeman work for Databricks,Mark Roepke work for Databricks",English
Foundations of Data Science: K-Means Clustering in Python,https://www.coursera.org/learn/data-science-k-means-clustering-python,4.7,"23,163","Dr Matthew Yee-King,Dr Betty Fyn-Sydney,Dr Jamie A Ward,Dr Larisa Soldatova",29 hours,Beginner,,Define and explain the key concepts of data clustering. Demonstrate understanding of the key constructs and features of the Python language. Implement in Python the principle steps of the K-means algorithm. Design and execute a whole data clustering workflow and interpret the outputs.,K-Means Clustering          Machine Learning          Programming in Python      ,Data Science,"University of London,Goldsmiths, University of London",Enroll for Free,,"Dr Matthew Yee-King work for University of London, Coursera, Goldsmiths, University of London,Dr Betty Fyn-Sydney work for University of London, Goldsmiths, University of London,Dr Jamie A Ward work for University of London, Goldsmiths, University of London,Dr Larisa Soldatova work for University of London, Goldsmiths, University of London","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data and Health Indicators in Public Health Practice,https://www.coursera.org/learn/data-public-health,4.7,"26,176","Keri Althoff, PhD, MPH",6 hours,Beginner,,"Epidemiology is often described as the cornerstone science in public health. Epidemiology in public health practice uses study design and analyses to identify causes in an outbreak situation, guides interventions to improve population health, and evaluates programs and policies. In this course, we'll define the role of the professional epidemiologist as it relates to public health services, functions, and competencies. With that foundation in mind, we'll introduce you to the problem solving methodology and demonstrate how it can be used in a wide variety of settings to identify problems, propose solutions, and evaluate interventions. This methodology depends on the use of reliable data, so we'll take a deep dive into the routine and public health data systems that lie at the heart of epidemiology and then conclude with how you can use that data to calculate measures of disease burden in populations.",,Health,Johns Hopkins University,Enroll for Free,Epidemiology in Public Health Practice Specialization,"Keri Althoff, PhD, MPH work for Johns Hopkins University","Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Processing with Azure,https://www.coursera.org/learn/data-processing-with-azure,3.7,"6,391","Samant Bali,Kenny Mobley",13 hours,Intermediate,,Configure batch processing with Databricks and Data Factory on Azure. Use ETL and ELT to load and transform data. Create linked services and identify pipelines for data stored within Data Factory. Explain Data Virtualization in PolyBase,Data Analysis          Microsoft Azure          Big Data          Data Lake          Data Factory      ,Information Technology,LearnQuest,Enroll for Free,,"Samant Bali work for LearnQuest,Kenny Mobley work for LearnQuest","French, Portuguese (European), Russian, English, Spanish"
Communicating Data Science Results,https://www.coursera.org/learn/data-results,3.6,"15,491",Bill Howe,8 hours,,,"Important note: The second assignment in this course covers the topic of Graph Analysis in the Cloud, in which you will use Elastic MapReduce and the Pig language to perform graph analysis over a moderately large dataset, about 600GB. In order to complete this assignment, you will need to make use of Amazon Web Services (AWS). Amazon has generously offered to provide up to $50 in free AWS credit to each learner in this course to allow you to complete the assignment. Further details regarding the process of receiving this credit are available in the welcome message for the course, as well as in the assignment itself. Please note that Amazon, University of Washington, and Coursera cannot reimburse you for any charges if you exhaust your credit. While we believe that this assignment contributes an excellent learning experience in this course, we understand that some learners may be unable or unwilling to use AWS. We are unable to issue Course Certificates for learners who do not complete the assignment that requires use of AWS. As such, you should not pay for a Course Certificate in Communicating Data Results if you are unable or unwilling to use AWS, as you will not be able to successfully complete the course without doing so.Making predictions is not enough!. Effective data scientists know how to explain and interpret their results, and communicate findings accurately to stakeholders to inform business decisions. Visualization is the field of research in computer science that studies effective communication of quantitative results by linking perception, cognition, and algorithms to exploit the enormous bandwidth of the human visual cortex. In this course you will learn to recognize, design, and use effective visualizations.Just because you can make a prediction and convince others to act on it doesn’t mean you should. In this course you will explore the ethical considerations around big data and how these considerations are beginning to influence policy and practice.  You will learn the foundational limitations of using technology to protect privacy and the codes of conduct emerging to guide the behavior of data scientists. You will also learn the importance of reproducibility in data science and how the commercial cloud can help support reproducible research even for experiments involving massive datasets, complex computational infrastructures, or both.Learning Goals: After completing this course, you will be able to:1. Design and critique visualizations2. Explain the state-of-the-art in privacy, ethics, governance around big data and data science3. Use cloud computing to analyze large datasets in a reproducible way.",,Data Science,University of Washington,Enroll for Free,Data Science at Scale Specialization,Bill Howe work for University of Washington,"Subtitles: French, Portuguese (European), Russian, English, Spanish"
Prepare Data for Exploration,https://www.coursera.org/learn/data-preparation,4.8,"119,518",Google Career Certificates,22 hours,Beginner,No  experience with spreadsheets or data analytics is required. All you need is high-school level math skills and a curiosity about how things work.,Explain factors to consider when making decisions about data collection. Discuss the difference between biased and unbiased data. Describe databases with references to their functions and components. Describe best practices for organizing data,Spreadsheet          Metadata          Data Collection          Data Ethics          SQL      ,Data Science,Google,Enroll for Free,Google Data Analytics Professional Certificate,Google Career Certificates work for Google,English
Developing Data Products,https://www.coursera.org/learn/data-products,4.6,"78,785","Brian Caffo, PhD,Jeff Leek, PhD,Roger D. Peng, PhD",10 hours,,,Develop basic applications and interactive graphics using GoogleVis. Use Leaflet to create interactive annotated maps. Build an R Markdown presentation that includes a data visualization. Create a data product that tells a story to a mass audience,Interactivity          Plotly          Web Application          R Programming      ,Data Science,Johns Hopkins University,Enroll for Free,,"Brian Caffo, PhD work for Johns Hopkins University,Jeff Leek, PhD work for Johns Hopkins University,Roger D. Peng, PhD work for Johns Hopkins University","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Data Pipelines with TensorFlow Data Services,https://www.coursera.org/learn/data-pipelines-tensorflow,4.3,"15,282",Laurence Moroney,16 hours,Intermediate,"We recommend taking Course 1 of the TensorFlow in Practice Specialization first, or have a basic familiarity with building models in TensorFlow",Perform efficient ETL tasks using Tensorflow Data Services APIs. Construct train/validation/test splits of any dataset - either custom or present in TensorFlow Hub Dataset library - using Splits API. Use different modules and functions of the TFDS API to prepare your data for training pipelines. Identify bottlenecks in your input pipelines and increase your workflow efficiency by input parallelization,"Artificial Neural Network          Tensorflow          Extraction, Transformation And Loading (ETL)          Data Pipelines          TensorFlow Datasets      ",Computer Science,DeepLearning.AI,Enroll for Free,TensorFlow: Data and Deployment Specialization,Laurence Moroney work for DeepLearning.AI,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Modeling and Regression Analysis in Business,https://www.coursera.org/learn/data-modeling-regression-analysis-business,4.3,"6,636",Sridhar Seshadri,25 hours,Intermediate,,"The course will begin with what is familiar to many business managers and those who have taken the first two courses in this specialization. The first set of tools will explore data description, statistical inference, and regression. We will extend these concepts to other statistical methods used for prediction when the response variable is categorical such as win-don’t win an auction. In the next segment, students will learn about tools used for identifying important features in the dataset that can either reduce the complexity or help identify important features of the data or further help explain behavior.",,Business,University of Illinois at Urbana-Champaign,Enroll for Free,,Sridhar Seshadri work for University of Illinois at Urbana-Champaign,"Subtitles: French, Portuguese (European), Russian, English, Spanish"
Pattern Discovery in Data Mining,https://www.coursera.org/learn/data-patterns,4.3,"36,522",Jiawei Han,17 hours,4.1.,,"Learn the general concepts of data mining along with basic methodologies and applications. Then dive into one subfield in data mining: pattern discovery. Learn in-depth concepts, methods, and applications of pattern discovery in data mining. We will also introduce methods for data-driven phrase mining and some interesting applications of pattern discovery. This course provides you the opportunity to learn skills and content to practice and engage in scalable pattern discovery methods on massive transactional data, discuss pattern evaluation measures, and study methods for mining diverse kinds of patterns, sequential patterns, and sub-graph patterns.",Streams          Sequential Pattern Mining          Data Mining Algorithms          Data Mining      ,Data Science,University of Illinois at Urbana-Champaign,Enroll for Free,Data Mining  Specialization,Jiawei Han work for University of Illinois at Urbana-Champaign,"Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Research Data Management and Sharing,https://www.coursera.org/learn/data-management,4.7,"27,693","Helen Tibbo,Sarah Jones",14 hours,,,"This course will provide learners with an introduction to research data management and sharing. After completing this course, learners will understand the diversity of data and their management needs across the research data lifecycle, be able to identify the components of good data management plans, and be familiar with best practices for working with data including the organization, documentation, and storage and security of data. Learners will also understand the impetus and importance of archiving and sharing data as well as how to assess the trustworthiness of repositories.  Today, an increasing number of funding agencies, journals, and other stakeholders are requiring data producers to share, archive, and plan for the management of their data. In order to respond to these requirements, researchers and information professionals will need the data management and curation knowledge and skills that support the long-term preservation, access, and reuse of data. Effectively managing data can also help optimize research outputs, increase the impact of research, and support open scientific inquiry. After completing this course, learners will be better equipped to manage data throughout the entire research data lifecycle from project planning to the end of the project when data ideally are shared and made available within a trustworthy repository.This course was developed by the Curating Research Assets and Data Using Lifecycle Education (CRADLE) Project in collaboration with EDINA at the University of Edinburgh. This course was made possible in part by the Institute of Museum and Library Services under award #RE-06-13-0052-13. The views, findings, conclusions or recommendations expressed in this Research Data Management and Sharing MOOC do not necessarily represent those of the Institute of Museum and Library Services.Hashtag: #RDMSmooc",Data Management Plan          Research Data Archiving          Metadata          Data Management      ,Data Science,"The University of North Carolina at Chapel Hill,The University of Edinburgh",Enroll for Free,,"Helen Tibbo work for The University of North Carolina at Chapel Hill,Sarah Jones work for The University of Edinburgh","Arabic, French, Portuguese (European), Chinese (Simplified), Italian, Vietnamese, German, Russian, English, Spanish"
Data Mining Project,https://www.coursera.org/learn/data-mining-project,4.6,"6,166","Jiawei Han,ChengXiang Zhai,John C. Hart",11 hours,,,"Note: You should complete all the other courses in this Specialization before beginning this course. This six-week long Project course of the Data Mining Specialization will allow you to apply the learned algorithms and techniques for data mining from the previous courses in the Specialization, including Pattern Discovery, Clustering, Text Retrieval, Text Mining, and Visualization, to solve interesting real-world data mining challenges. Specifically, you will work on a restaurant review data set from Yelp and use all the knowledge and skills you’ve learned from the previous courses to mine this data set to discover interesting and useful knowledge. The design of the Project emphasizes: 1) simulating the workflow of a data miner in a real job setting; 2) integrating different mining techniques covered in multiple individual courses; 3) experimenting with different ways to solve a problem to deepen your understanding of techniques; and 4) allowing you to propose and explore your own ideas creatively. The goal of the Project is to analyze and mine a large Yelp review data set to discover useful knowledge to help people make decisions in dining. The project will include the following outputs: 1. Opinion visualization: explore and visualize the review content to understand what people have said in those reviews.2. Cuisine map construction: mine the data set to understand the landscape of different types of cuisines and their similarities.3. Discovery of popular dishes for a cuisine: mine the data set to discover the common/popular dishes of a particular cuisine.4. Recommendation of restaurants to help people decide where to dine: mine the data set to rank restaurants for a specific dish and predict the hygiene condition of a restaurant.From the perspective of users, a cuisine map can help them understand what cuisines are there and see the big picture of all kinds of cuisines and their relations. Once they decide what cuisine to try, they would be interested in knowing what the popular dishes of that cuisine are and decide what dishes to have. Finally, they will need to choose a restaurant. Thus, recommending restaurants based on a particular dish would be useful. Moreover, predicting the hygiene condition of a restaurant would also be helpful. By working on these tasks, you will gain experience with a typical workflow in data mining that includes data preprocessing, data exploration, data analysis, improvement of analysis methods, and presentation of results. You will have an opportunity to combine multiple algorithms from different courses to complete a relatively complicated mining task and experiment with different ways to solve a problem to understand the best way to solve it. We will suggest specific approaches, but you are highly encouraged to explore your own ideas since open exploration is, by design, a goal of the Project. You are required to submit a brief report for each of the tasks for peer grading. A final consolidated report is also required, which will be peer-graded.",Data Clustering Algorithms          Data Analysis          Natural Language Processing          Data Mining      ,Data Science,University of Illinois at Urbana-Champaign,Enroll for Free,Data Mining  Specialization,"Jiawei Han work for University of Illinois at Urbana-Champaign,ChengXiang Zhai work for University of Illinois at Urbana-Champaign,John C. Hart work for University of Illinois at Urbana-Champaign","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Data Manipulation at Scale: Systems and Algorithms,https://www.coursera.org/learn/data-manipulation,4.3,"57,771",Bill Howe,20 hours,,,"Data analysis has replaced data acquisition as the bottleneck to evidence-based decision making --- we are drowning in it. Extracting knowledge from large, heterogeneous, and noisy datasets requires not only powerful computing resources, but the programming abstractions to use them effectively. The abstractions that emerged in the last decade blend ideas from parallel databases, distributed systems, and programming languages to create a new class of scalable data analytics platforms that form the foundation for data science at realistic scales. In this course, you will learn the landscape of relevant systems, the principles on which they rely, their tradeoffs, and how to evaluate their utility against your requirements. You will learn how practical systems were derived from the frontier of research in computer science and what systems are coming on the horizon.  Cloud computing, SQL and NoSQL databases, MapReduce and the ecosystem it spawned, Spark and its contemporaries, and specialized systems for graphs and arrays will be covered.You will also learn the history and context of data science, the skills, challenges, and methodologies the term implies, and how to structure a data science project. At the end of this course, you will be able to:Learning Goals: 1. Describe common patterns, challenges, and approaches associated with data science projects, and what makes them different from projects in related fields.2. Identify and use the programming models associated with scalable data manipulation, including relational algebra, mapreduce, and other data flow models.3. Use database technology adapted for large-scale analytics, including the concepts driving parallel databases, parallel query processing, and in-database analytics4. Evaluate key-value stores and NoSQL systems, describe their tradeoffs with comparable systems, the details of important examples in the space, and future trends.5. “Think” in MapReduce to effectively write algorithms for systems including Hadoop and Spark. You will understand their limitations, design details, their relationship to databases, and their associated ecosystem of algorithms, extensions, and languages.write programs in Spark6. Describe the landscape of specialized Big Data systems for graphs, arrays, and streams",Relational Algebra          Python Programming          Mapreduce          SQL      ,Data Science,University of Washington,Enroll for Free,Data Science at Scale Specialization,Bill Howe work for University of Washington,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Mining Project,https://www.coursera.org/learn/data-mining-theory-practice-project,,,Qin (Christine) Lv,37 hours,Intermediate,"data science professionals or domain experts, some experience working with data, completion of Data Mining Pipeline and Data Mining Methods",Identify the key components of and propose a real-world data mining project. Design and develop real-world solutions across the full data mining pipeline.  Summarize and present the key findings of the data mining project. Analyze the overall project process and identify possible improvements.,data mining project design and development          data mining project formulation          data mining project summary and presentation          data mining project process analysis and improvement      ,Data Science,University of Colorado Boulder,Enroll for Free,Data Mining Foundations and Practice Specialization,Qin (Christine) Lv work for University of Colorado Boulder,English
Data Mining Methods,https://www.coursera.org/learn/data-mining-methods,,,Qin (Christine) Lv,22 hours,Intermediate,"data science professionals or domain experts, some experience working with data, successful completion of Data Mining Pipeline","Identify the core functionalities of data modeling in the data mining pipeline. Apply techniques that can be used to accomplish the core functionalities of data modeling and explain how they work.  Evaluate data modeling techniques, determine which is most suitable for a particular task, and identify potential improvements.",outlier analysis          clustering          classification          model evaluation          frequent pattern analysis      ,Data Science,University of Colorado Boulder,Enroll for Free,Data Mining Foundations and Practice Specialization,Qin (Christine) Lv work for University of Colorado Boulder,English
Data Mining Pipeline,https://www.coursera.org/learn/data-mining-pipeline,,,Qin (Christine) Lv,21 hours,Intermediate,"data science professionals or domain experts, some experience working with data","By the end of this course, you will be able to identify the key components of the data mining pipeline and describe how they're related. You will be able to identify particular challenges presented by each component of the data mining pipeline. You will be able to apply techniques to address challenges in each component of the data mining pipeline.",Data Pre-Processing          Data Warehousing          data understanding          data mining pipeline      ,Data Science,University of Colorado Boulder,Enroll for Free,Data Mining Foundations and Practice Specialization,Qin (Christine) Lv work for University of Colorado Boulder,English
Designing data-intensive applications,https://www.coursera.org/learn/data-intensive-applications,4.4,"5,990",María del Pilar Ángeles,7 hours,Intermediate,,"Welcome to the specialization course of Designing data-intensive applications.  This course will be completed on four weeks, it will be supported with videos and exercises.By the end of this specialization, learners will be able to propose, design, justify and develop high reliable information systems according to type of data and volume of information, response time, type of processing and queries in order to support scalability, maintainability, security and reliability considering the last information technologies.Software to download:MySQL Workbench RapidminerHadoop framework HortonworksMongoDBIn case you have a Mac / IOS operating system you need to perform an action called VirtualBox.","Atomicity, Consistency, Isolation, Durability (ACID)          Applied Data Mining          Data Mining          Relational Database      ",Data Science,Universidad Nacional Autónoma de México,Enroll for Free,Database systems Specialization,María del Pilar Ángeles work for Universidad Nacional Autónoma de México,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Engineering and Machine Learning using Spark,https://www.coursera.org/learn/data-engineering-and-machine-learning-using-spark,3.7,"1,882","Karthik Muthuraman,Romeo Kienzler",7 hours,Beginner,,"Glean insights into how streaming data and Spark Structured Streaming empower machine learning and AI tasks. Delve into graph theory and Apache Spark GraphFrames, used for motif finding in genetics and biological sciences, and learn to identify data. Discover how ETL processes work with Apache Spark and machine learning and extend that knowledge to Spark MLlib capabilities and related benefits. Explore supervised learning and unsupervised learning, clustering, and learn how to use the k-means clustering algorithm with Spark MLlib.",,Information Technology,IBM,Enroll for Free,,"Karthik Muthuraman work for IBM,Romeo Kienzler work for IBM",Subtitles: English
"Big Data, Genes, and Medicine",https://www.coursera.org/learn/data-genes-medicine,4.3,"27,100",Isabelle Bichindaritz,40 hours,Advanced,,"This course distills for you expert knowledge and skills mastered by professionals in Health Big Data Science and Bioinformatics. You will learn exciting facts about the human body biology and chemistry, genetics, and medicine that will be intertwined with the science of Big Data and skills to harness the avalanche of data openly available at your fingertips and which we are just starting to make sense of. We’ll investigate the different steps required to master Big Data analytics on real datasets, including Next Generation Sequencing data, in a healthcare and biological context, from preparing data for analysis to completing the analysis, interpreting the results, visualizing them, and sharing the results. Needless to say, when you master these high-demand skills, you will be well positioned to apply for or move to positions in biomedical data analytics and bioinformatics. No matter what your skill levels are in biomedical or technical areas, you will gain highly valuable new or sharpened skills that will make you stand-out as a professional and want to dive even deeper in biomedical Big Data. It is my hope that this course will spark your interest in the vast possibilities offered by publicly available Big Data to better understand, prevent, and treat diseases.",Bioinformatics          Data Clustering Algorithms          Big Data          R Programming      ,Health,The State University of New York,Enroll for Free,,Isabelle Bichindaritz work for The State University of New York,"French, Portuguese (European), Russian, English, Spanish"
Modernizing Data Lakes and Data Warehouses with GCP,https://www.coursera.org/learn/data-lakes-data-warehouses-gcp,4.7,"33,872",Google Cloud Training,9 hours,Intermediate,,"The two key components of any data pipeline are data lakes and warehouses. This course highlights use-cases for each type of storage and dives into the available data lake and warehouse solutions on Google Cloud Platform in technical detail. Also, this course describes the role of a data engineer, the benefits of a successful data pipeline to business operations, and examines why data engineering should be done in a cloud environment. Learners will get hands-on experience with data lakes and warehouses on Google Cloud Platform using QwikLabs.",,Information Technology,Google Cloud,Enroll,,Google Cloud Training work for Google Cloud,"Subtitles: English, Spanish"
Applying Machine Learning to your Data with GCP,https://www.coursera.org/learn/data-insights-gcp-apply-ml,4.7,"14,778",Google Cloud Training,10 hours,Intermediate,,"In this module, we define what Machine Learning is and how it can benefit your business. You'll see a few demos of ML in action and learn key ML terms like instances, features, and labels. In the interactive labs, you will practice invoking the pretrained ML APIs available as well as build your own Machine Learning models using just SQL with BigQuery ML. PREREQUISITESTo get the most out of this course, participants must complete the prior courses in this specialization:• Exploring and Preparing your Data• Storing and Visualizing your Data• Architecture and Performance&gt;&gt;&gt; By enrolling in this specialization you agree to the Qwiklabs Terms of Service as set out in the FAQ and located at: https://qwiklabs.com/terms_of_service &lt;&lt;&lt;",Bigquery          Machine Learning          Google Cloud Platform          Cloud Computing      ,Information Technology,Google Cloud,Enroll,From Data to Insights with Google Cloud Specialization,Google Cloud Training work for Google Cloud,"French, Portuguese (European), Russian, English, Spanish, Japanese"
Data Literacy Capstone – Evaluating Research,https://www.coursera.org/learn/data-literacy-capstone-evaluating-research,,,"Jennifer Bachner, PhD",6 hours,Intermediate,Completion of the first four courses in the Data Literacy Specialization,"This is the final course in the Data Literacy Specialization. In this capstone course, you'll apply the skills and knowledge you have acquired in the specialization to the critical evaluation of an original quantitative analysis. The project will first require you to identify and read a piece of high-quality, original, quantitative research on a topic of your choosing. You’ll then interpret and evaluate the findings as well as the methodological approach. As part of the project, you’ll also review other students’ submissions. By the end of the project, you should be empowered to be a critical consumer and user of quantitative research.",Research Methods          research evaluation      ,Social Sciences,Johns Hopkins University,Enroll for Free,Data Literacy Specialization,"Jennifer Bachner, PhD work for Johns Hopkins University",English
Data for Machine Learning,https://www.coursera.org/learn/data-machine-learning,4.4,"6,297",Anna Koop,12 hours,Intermediate,,"This course is all about data and how it is critical to the success of your applied machine learning model. Completing this course will give learners the skills to:. Understand the critical elements of data in the learning, training and operation phasesUnderstand biases and sources of dataImplement techniques to improve the generality of your modelExplain the consequences of overfitting and identify mitigation measuresImplement appropriate test and validation measures.Demonstrate how the accuracy of your model can be improved with thoughtful feature engineering.Explore the impact of the algorithm parameters on model strengthTo be successful in this course, you should have at least beginner-level background in Python programming (e.g., be able to read and code trace existing code, be comfortable with conditionals, loops, variables, lists, dictionaries and arrays). You should have a basic understanding of linear algebra (vector notation) and statistics (probability distributions and mean/median/mode).This is the third course of the Applied Machine Learning Specialization brought to you by Coursera and the Alberta Machine Intelligence Institute.",Statistical Analysis          Machine Learning          Python Programming          Computer Programming          Linear Algebra      ,Data Science,Alberta Machine Intelligence Institute,Enroll for Free,Machine Learning: Algorithms in the Real World Specialization,Anna Koop work for Alberta Machine Intelligence Institute,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
"Data Collection: Online, Telephone and Face-to-face",https://www.coursera.org/learn/data-collection-methods,4.6,"11,262","Frederick Conrad, Ph.D.",21 hours,Beginner,,"This course presents research conducted to increase our understanding of how data collection decisions affect survey errors. This is not a “how–to-do-it” course on data collection, but instead reviews the literature on survey design decisions and data quality in order to sensitize learners to how alternative survey designs might impact the data obtained from those surveys. The course reviews a range of survey data collection methods that are both interview-based (face-to-face and telephone) and self-administered (paper questionnaires that are mailed and those that are implemented online, i.e. as web surveys). Mixed mode designs are also covered as well as several hybrid modes for collecting sensitive information e.g., self-administering the sensitive questions in what is otherwise a face-to-face interview. The course also covers newer methods such as mobile web and SMS (text message) interviews, and examines alternative data sources such as social media. It concentrates on the impact these techniques have on the quality of survey data, including error from measurement, nonresponse, and coverage, and assesses the tradeoffs between these error sources when researchers choose a mode or survey design.",,Health,University of Michigan,Enroll for Free,Survey Data Collection and Analytics  Specialization,"Frederick Conrad, Ph.D. work for University of Michigan","Subtitles: French, Portuguese (European), Russian, English, Spanish"
Data Collection and Processing with Python,https://www.coursera.org/learn/data-collection-processing-python,4.7,"59,044","Paul Resnick,Jaclyn Cohen",16 hours,Intermediate,,"This course teaches you to fetch and process data from services on the Internet. It covers Python list comprehensions and provides opportunities to practice extracting from and processing deeply nested data. You'll also learn how to use the Python requests module to interact with REST APIs and what to look for in documentation of those APIs. For the final project, you will construct a “tag recommender” for the flickr photo sharing site. The course is well-suited for you if you have already taken the ""Python Basics"" and ""Python Functions, Files, and Dictionaries"" courses (courses 1 and 2 of the Python 3 Programming Specialization). If you are already familiar with Python fundamentals but want practice at retrieving and processing complex nested data from Internet services, you can also benefit from this course without taking the previous two.This is the third of five courses in the Python 3 Programming Specialization.",,Computer Science,University of Michigan,Enroll for Free,Python 3 Programming Specialization,"Paul Resnick work for University of Michigan,Jaclyn Cohen work for University of Michigan","Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Data-Driven Process Improvement,https://www.coursera.org/learn/data-driven-process-improvement,4.4,"3,041","Peter Baumgartner,Akshay Sivadas",9 hours,Beginner,"It is helpful if learners have some familiarity with reading reports, gathering and using data, and interpreting visualizations.",Develop a plan to align operational and performance goals. Devise a data collection strategy and validate data integrity. Understand how to create current and future state process maps. Prioritize data gaps for root cause analysis,Gap assessment          Business Process Mapping          KPIs          Data Collection          Data-Driven Decision Making      ,Business,"University at Buffalo,The State University of New York",Enroll for Free,Data-Driven Decision Making (DDDM) Specialization,"Peter Baumgartner work for The State University of New York,Akshay Sivadas work for The State University of New York, University at Buffalo",English
Data-driven Astronomy,https://www.coursera.org/learn/data-driven-astronomy,4.8,"25,151","Tara Murphy,Simon Murphy",24 hours,Intermediate,,"Science is undergoing a data explosion, and astronomy is leading the way. Modern telescopes produce terabytes of data per observation, and the simulations required to model our observable Universe push supercomputers to their limits. To analyse this data scientists need to be able to think computationally to solve problems. In this course you will investigate the challenges of working with large datasets: how to implement algorithms that work; how to use databases to manage your data; and how to learn from your data with machine learning tools. The focus is on practical skills - all the activities will be done in Python 3, a modern programming language used throughout astronomy. Regardless of whether you’re already a scientist, studying to become one, or just interested in how modern astronomy works ‘under the bonnet’, this course will help you explore astronomy: from planets, to pulsars to black holes.Course outline:Week 1: Thinking about data- Principles of computational thinking- Discovering pulsars in radio imagesWeek 2: Big data makes things slow- How to work out the time complexity of algorithms- Exploring the black holes at the centres of massive galaxiesWeek 3: Querying data using SQL- How to use databases to analyse your data- Investigating exoplanets in other solar systemsWeek 4: Managing your data- How to set up databases to manage your data- Exploring the lifecycle of stars in our GalaxyWeek 5: Learning from data: regression- Using machine learning tools to investigate your data- Calculating the redshifts of distant galaxiesWeek 6: Learning from data: classification- Using machine learning tools to classify your data- Investigating different types of galaxiesEach week will also have an interview with a data-driven astronomy expert.Note that some knowledge of Python is assumed, including variables, control structures, data structures, functions, and working with files.",Python Programming          Machine Learning          Applied Machine Learning          SQL      ,Physical Science and Engineering,The University of Sydney,Enroll for Free,,"Tara Murphy work for The University of Sydney,Simon Murphy work for The University of Sydney","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Framework for Data Collection and Analysis,https://www.coursera.org/learn/data-collection-framework,4.2,"23,665","Frauke Kreuter, Ph.D.,Mariel Leonard",10 hours,Intermediate,,"This course will provide you with an overview over existing data products and a good understanding of the data collection landscape. With the help of various examples you will learn how to identify which data sources likely matches your research question, how to turn your research question into measurable pieces, and how to think about an analysis plan. Furthermore this course will provide you with a general framework that allows you to not only understand each step required for a successful data collection and analysis, but also help you to identify errors associated with different data sources. You will learn some metrics to quantify each potential error, and thus you will have tools at hand to describe the quality of a data source. Finally we will introduce different large scale data collection efforts done by private industry and government agencies, and review the learned concepts through these examples. This course is suitable for beginners as well as those that know about one particular data source, but not others, and are looking for a general framework to evaluate data products.",Data Collection          Data Quality          Data Analysis          Data Generating Process      ,Data Science,"University of Maryland, College Park",Enroll for Free,Survey Data Collection and Analytics  Specialization,"Frauke Kreuter, Ph.D. work for University of Michigan, University of Maryland, College Park,Mariel Leonard work for University of Maryland, College Park","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Getting and Cleaning Data,https://www.coursera.org/learn/data-cleaning,4.6,"189,906","Jeff Leek, PhD,Roger D. Peng, PhD,Brian Caffo, PhD",20 hours,,,"Understand common data storage systems. Apply data cleaning basics to make data ""tidy"". Use R for text and date manipulation. Obtain usable data from the web, APIs, and databases",Data Manipulation          Regular Expression (REGEX)          R Programming          Data Cleansing      ,Data Science,Johns Hopkins University,Enroll for Free,,"Jeff Leek, PhD work for Johns Hopkins University,Roger D. Peng, PhD work for Johns Hopkins University,Brian Caffo, PhD work for Johns Hopkins University","Arabic, French, Portuguese (European), Chinese (Simplified), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Combining and Analyzing Complex Data,https://www.coursera.org/learn/data-collection-analytics-project,4.2,"7,132","Richard Valliant, Ph.D.",10 hours,,,"In this course you will learn how to use survey weights to estimate descriptive statistics, like means and totals, and more complicated quantities like model parameters for linear and logistic regressions. Software capabilities will be covered with R® receiving particular emphasis. The course will also cover the basics of record linkage and statistical matching—both of which are becoming more important as ways of combining data from different sources. Combining of datasets raises ethical issues which the course reviews. Informed consent may have to be obtained from persons to allow their data to be linked. You will learn about differences in the legal requirements in different countries.",,Data Science,"University of Maryland, College Park",Enroll for Free,Survey Data Collection and Analytics  Specialization,"Richard Valliant, Ph.D. work for University of Maryland, College Park",Subtitles: English
Data Analytics for Lean Six Sigma,https://www.coursera.org/learn/data-analytics-for-lean-six-sigma,4.8,"47,764",Inez Zwetsloot,11 hours,Beginner,,Welcome to this course on Data Analytics for Lean Six Sigma.  In this course you will learn data analytics techniques that are typically useful within Lean Six Sigma improvement projects. At the end of this course you are able to analyse and interpret data gathered within such a project. You will be able to use Minitab to analyse the data. I will also briefly explain what Lean Six Sigma is.I will emphasize on use of data analytics tools and the interpretation of the outcome. I will use many different examples from actual Lean Six Sigma projects to illustrate all tools. I will not discuss any mathematical background. The setting we chose for our data example is a Lean Six Sigma improvement project. However data analytics tools are very widely applicable. So you will find that you will learn techniques that you can use in a broader setting apart from improvement projects. I hope that you enjoy this course and good luck!Dr. Inez Zwetsloot &amp; the IBIS UvA team,Statistics          Lean Six Sigma          Data Analysis          Minitab      ,Data Science,University of Amsterdam,Enroll for Free,,Inez Zwetsloot work for University of Amsterdam,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish, Romanian"
Data Analysis and Visualization,https://www.coursera.org/learn/data-analyze-visualize,4.4,"3,384","Peter Baumgartner,Brittany O'Dea",11 hours,Beginner,"It is helpful if learners have some familiarity with reading reports, gathering and using data, and interpreting visualizations.","Identify stakeholders and key components imperative to an analytics project plan. Name strengths and weaknesses of different analysis and visualization tools. Visually identify, monitor, and remove process variation. Explain how to create a compelling data story",Data visualization tools          Data storytelling          Data analysis tools          Data-Driven Decision Making          Statistical process control (SPC)      ,Business,"University at Buffalo,The State University of New York",Enroll for Free,Data-Driven Decision Making (DDDM) Specialization,"Peter Baumgartner work for The State University of New York,Brittany O'Dea work for The State University of New York",English
Data Analytics Foundations for Accountancy II,https://www.coursera.org/learn/data-analytics-accountancy-2,,"2,933",Robert Brunner,70 hours,,,"Welcome to Data Analytics Foundations for Accountancy II!. I'm excited to have you in the class and look forward to your contributions to the learning community. To begin, I recommend taking a few minutes to explore the course site. Review the material we’ll cover each week, and preview the assignments you’ll need to complete to pass the course. Click Discussions to see forums where you can discuss the course material with fellow students taking the class.If you have questions about course content, please post them in the forums to get help from others in the course community. For technical problems with the Coursera platform, visit the Learner Help Center.Good luck as you get started, and I hope you enjoy the course!",,Data Science,University of Illinois at Urbana-Champaign,Enroll for Free,,"Robert Brunner work for University of Illinois at Urbana-Champaign, Coursera",Subtitles: English
Advanced Business Analytics Capstone,https://www.coursera.org/learn/data-analytics-business-capstone,4.3,"6,978","Manuel Laguna,Dan Zhang,David Torgerson",19 hours,,,"The analytics process is a collection of interrelated activities that lead to better decisions and to a higher business performance. The capstone of this specialization is designed with the goal of allowing you to experience this process. The capstone project will take you from data to analysis and models, and ultimately to presentation of insights.  In this capstone project, you will analyze the data on financial loans to help with the investment decisions of an investment company. You will go through all typical steps of a data analytics project, including data understanding and cleanup, data analysis, and presentation of analytical results. For the first week, the goal is to understand the data and prepare the data for analysis. As we discussed. in this specialization, data preprocessing and cleanup is often the first step in data analytics projects. Needless to say, this step is crucial for the success of this project. In the second week, you will perform some predictive analytics tasks, including classifying loans and predicting losses from defaulted loans. You will try a variety of tools and techniques. this week, as the predictive accuracy of different tools can vary quite a bit. It is rarely the case that the default model produced by ASP is the best model possible. Therefore, it is important for you to tune the different models in order to improve the performance.Beginning in the third week, we turn our attention to prescriptive analytics, where you will provide some concrete suggestions on how to allocate investment funds using analytics tools, including clustering and simulation based optimization. You will see that allocating funds wisely is crucial for the financial return of the investment portfolio.In the last week, you are expected to present your analytics results to your clients. Since you will obtain many results in your project, it is important for you to judiciously choose what to include in your presentation. You are also expected to follow the principles we covered in the courses in preparing your presentation.",,Data Science,University of Colorado Boulder,Enroll for Free,Advanced Business Analytics Specialization,"Manuel Laguna work for University of Colorado Boulder,Dan Zhang work for University of Colorado Boulder,David Torgerson work for University of Colorado Boulder","Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Data Analytics Foundations for Accountancy I,https://www.coursera.org/learn/data-analytics-accountancy-1,4.1,"7,244",Robert Brunner,67 hours,,,"Welcome to Data Analytics Foundations for Accountancy I! You’re joining thousands of learners currently enrolled in the course. I'm excited to have you in the class and look forward to your contributions to the learning community. To begin, I recommend taking a few minutes to explore the course site. Review the material we’ll cover each week, and preview the assignments you’ll need to complete to pass the course. Click Discussions to see forums where you can discuss the course material with fellow students taking the class.If you have questions about course content, please post them in the forums to get help from others in the course community. For technical problems with the Coursera platform, visit the Learner Help Center.Good luck as you get started, and I hope you enjoy the course!",,Data Science,University of Illinois at Urbana-Champaign,Enroll for Free,,"Robert Brunner work for University of Illinois at Urbana-Champaign, Coursera","Subtitles: French, Portuguese (European), Russian, English, Spanish"
Data Analysis with R,https://www.coursera.org/learn/data-analysis-with-r,4.9,"2,608","Tiffany Zhu,Yiwen Li,Gabriela de Queiroz",14 hours,Intermediate,,"Prepare data for analysis by handling missing values, formatting and normalizing data, binning, and turning categorical values into numeric values. Conduct exploratory data analysis using descriptive statistics, data grouping, analysis of variance (ANOVA), and correlation statistics. Develop a predictive model using various regression methods. Evaluate a model for overfitting and underfitting conditions and tune its performance using regularization and grid search.",Data Science          Statistical Analysis          R Programming          Data Analysis          Data Visualization (DataViz)      ,Data Science,IBM,Enroll for Free,,"Tiffany Zhu work for IBM,Yiwen Li work for IBM,Gabriela de Queiroz work for IBM",English
Data Analysis and Reporting in SAS Visual Analytics,https://www.coursera.org/learn/data-analysis-reporting-sas-va,4.8,"10,784",Nicole Ball,9 hours,Graph-Level,,"In this course, you learn how to use SAS Visual Analytics on SAS Viya to modify data for analysis, perform data discovery and analysis, and create interactive reports.",,Data Science,SAS,Enroll for Free,SAS Visual Business Analytics Professional Certificate,Nicole Ball work for SAS,Subtitles: English
Data Analysis with Python,https://www.coursera.org/learn/data-analysis-with-python,4.7,"213,336",Joseph Santarcangelo,15 hours,Beginner,,Describe Python data acquisition and analysis techniques. Analyze Python data using a dataset. Identify three Python libraries and describe their uses. Read data using Python's Pandas package.,Predictive Modelling          Python Programming          Data Analysis          Data Visualization (DataViz)          Model Selection      ,Data Science,IBM,Enroll for Free,,"Joseph Santarcangelo work for Coursera, IBM","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, Turkish, English, Spanish, Persian"
Data Analysis Using Python,https://www.coursera.org/learn/data-analysis-python,4.6,"5,223",Brandon Krakowsky,17 hours,Beginner,High school or college math.,"Apply basic data science techniques using Python. Understand and apply core concepts like Data Frames and joining data, and use data analysis libraries like pandas, numpy, and matplotlib. Demonstrate how to load, inspect, and query real-world data, and answer basic questions about that data. Analyze data further by applying learned skills in data aggregation and summarization, as well as basic data visualization",Data Science          Python Libraries          Python Programming          Data Analysis          Data Visualization (DataViz)      ,Data Science,University of Pennsylvania,Enroll for Free,Introduction to Programming with Python and Java Specialization,"Brandon Krakowsky work for University of Pennsylvania, Penn Engineering",English
"Data Analysis and Representation, Selection and Iteration",https://www.coursera.org/learn/data-analysis-representation-selection-iteration,4.7,"3,834","Dr. Tim ""Dr. T"" Chamillard",11 hours,Beginner,,"This course is the second course in the specialization exploring both computational thinking and beginning C programming. Rather than trying to define computational thinking, we’ll just say it’s a problem-solving process that includes lots of different components. Most people have a better understanding of what beginning C programming means!. This course assumes you have the prerequisite knowledge from the previous course in the specialization. You should make sure you have that knowledge, either by taking that previous course or from personal experience, before tackling this course. The required prerequisite knowledge is listed below. Prerequisite computational thinking knowledge: Algorithms and procedures, data collectionPrerequisite C knowledge: Data types, variables, constants, and STEM computationsThroughout this course you'll learn about data analysis and data representation, which are computational thinking techniques that help us understand what sets of data have to tell us. For the programming topics, you'll continue building on your C knowledge by implementing selection, which lets us decide which code to execute, and iteration (or looping), which lets us repeat chunks of code multiple times.Module 1: Learn about some common statistics we can calculate as we analyze sets of dataModule 2: Discover how we make decisions in our codeModule 3: Explore the various ways we can represent sets of dataModule 4: Use iteration (looping) to repeat actions in your code",,Computer Science,University of Colorado System,Enroll for Free,Computational Thinking with Beginning C Programming Specialization,"Dr. Tim ""Dr. T"" Chamillard work for Coursera, University of Colorado System","Subtitles: French, Portuguese (European), Russian, English, Spanish"
Data Analysis Tools,https://www.coursera.org/learn/data-analysis-tools,4.5,"42,602","Jen Rose,Lisa Dierker",10 hours,,,"In this course, you will develop and test hypotheses about your data. You will learn a variety of statistical tests, as well as strategies to know how to apply the appropriate one to your specific data and question. Using your choice of two powerful statistical software packages (SAS or Python), you will explore ANOVA, Chi-Square, and Pearson correlation analysis. This course will guide you through basic statistical principles to give you the tools to answer questions you have developed. Throughout the course, you will share your progress with others to gain valuable feedback and provide insight to other learners about their work.",Chi-Squared (Chi-2) Distribution          Data Analysis          Statistical Hypothesis Testing          Analysis Of Variance (ANOVA)      ,Data Science,Wesleyan University,Enroll for Free,Data Analysis and Interpretation Specialization,"Jen Rose work for Wesleyan University,Lisa Dierker work for Wesleyan University",English
Data Analysis with R Programming,https://www.coursera.org/learn/data-analysis-r,4.8,"71,091",Google Career Certificates,37 hours,Beginner,No prior experience with spreadsheets or data analytics is required. All you need is high-school level math and a curiosity about how things work.,"Describe the R programming language and its programming environment. Explain the fundamental concepts associated with programming in R including functions, variables, data types, pipes, and vectors. Describe the options for generating visualizations in R. Demonstrate an understanding of the basic formatting R Markdown to create structure and emphasize content",R Programming          Data Analysis          Data Visualization (DataViz)          R Markdown          Rstudio      ,Data Science,Google,Enroll for Free,Google Data Analytics Professional Certificate,Google Career Certificates work for Google,English
Data Analysis and Presentation Skills: the PwC Approach Final Project,https://www.coursera.org/learn/data-analysis-project-pwc,4.8,"3,551",Alex Mannella,11 hours,Beginner,,"In this Capstone Project, you'll bring together all the new skills and insights you've learned through the four courses. You'll be given a 'mock' client problem and a data set. You'll need to analyze the data to gain business insights, research the client's domain area, and create recommendations. You'll then need to visualize the data in a client-facing presentation. You'll bring it all together in a recorded video presentation. This course was created by PricewaterhouseCoopers LLP with an address at 300 Madison Avenue, New York, New York, 10017.",,Data Science,PwC,Enroll for Free,Data Analysis and Presentation Skills: the PwC Approach Specialization,Alex Mannella work for PwC,Subtitles: English
Data Analysis and Interpretation Capstone,https://www.coursera.org/learn/data-analysis-capstone,4.7,"3,404","Jen Rose,Lisa Dierker",8 hours,,,"The Capstone project will allow you to continue to apply and refine the data analytic techniques learned from the previous courses in the Specialization to address an important issue in society. You will use real world data to complete a project with our industry and academic partners. For example, you can work with our industry partner, DRIVENDATA, to help them solve some of the world's biggest social challenges! DRIVENDATA at www.drivendata.org, is committed to bringing cutting-edge practices in data science and crowdsourcing to some of the world's biggest social challenges and the organizations taking them on.  Or, you can work with our other industry partner, The Connection (www.theconnectioninc.org) to help them better understand recidivism risk for people on parole seeking substance use treatment. For more than 40 years, The Connection has been one of Connecticut’s leading private, nonprofit human service and community development agencies. Each month, thousands of people are assisted by The Connection’s diverse behavioral health, family support and community justice programs. The Connection’s Institute for Innovative Practice was created in 2010 to bridge the gap between researchers and practitioners in the behavioral health and criminal justice fields with the goal of developing maximally effective, evidence-based treatment programs. A major component of the Capstone project is for you to be able to choose the information from your analyses that best conveys results and implications, and to tell a compelling story with this information. By the end of the course, you will have a professional quality report of your findings that can be shown to colleagues and potential employers to demonstrate the skills you learned by completing the Specialization.",,Data Science,Wesleyan University,Enroll for Free,Data Analysis and Interpretation Specialization,"Jen Rose work for Wesleyan University,Lisa Dierker work for Wesleyan University","Subtitles: French, Portuguese (European), German, Russian, English, Spanish"
Cybersecurity for Data Science,https://www.coursera.org/learn/cybersecurity-for-data-science,,,Al Pisano,19 hours,Beginner,Anyone can take this course,Characterize the CIA principles and use them to classify a variety of cyber scenarios. Identify and disseminate vulnerabilities in the data security space- social (human) and technical (digital). Distinguish ethical boundaries of hacking and its applications. Explore professional cybersecurity networks and connect with experts from the field.,Communication          Risk Analysis          Problem Solving      ,Information Technology,University of Colorado Boulder,Enroll for Free,Vital Skills for Data Science Specialization,Al Pisano work for University of Colorado Boulder,English
Contemporary Data Analysis: Survey and Best Practices,https://www.coursera.org/learn/contemporary-data-analysis,,,Valentina Kuskova,16 hours,Beginner,No specific background required,"Despite a large variety of different courses on analytics, the courses that offer a broad overview of the field are rare. From practice of teaching statistics, it became clear that it is difficult for learners to put together a broad field map if they have taken only a few of the different topics on analytical tools. As a result, they do not see the overall picture of everything that the field of data analysis has to offer. This course is designed to fill this gap. It is a survey course on state-of-the-art in interdisciplinary methods of data analysis, applicable to business and academia alike. Unlike other statistical courses, which focus on specific methods, this course will focus on the broader areas within statistics and data analytics. There are five major topics it will cover. It will start with the root of it all - the data – and some of the problems with the data. Then it will move through the contemporary approaches to descriptive, inferential, predictive and prescriptive analytics.Within each broader topic, the course will offer the theoretical foundation behind the methods without focusing too much on the mathematics. It will provide historical references, examples, explanations and case studies to illustrate the main concepts within each broader topic. In doing so, it will introduce the applied, problem-based approach to using specific tools. Then, it will discuss some of the specific of a particular approach. Overall, after taking this course, the students will get a good understanding of the state-of-the-art tools that the field of data analysis currently has to offer.The course consists of two parts. There is a review part with six lectures, providing the description of the major data analysis areas. This 6-lecture course is offered as part of the “Network analytics for business” specialization. For students of the “Master of data and network analytics” program, there are six additional lectures on specific topics. They are designed to illustrate some of the specific state-of-the-art approaches within the broader areas.This Course is part of HSE University Master of Data and Network Analytics degree program. Learn more about admission into the program and how your Coursera work can be leveraged if accepted into the program here https://inlnk.ru/WMKM6.",,Data Science,HSE University,Enroll for Free,Network Analytics for Business Specialization,Valentina Kuskova work for HSE University,Subtitles: English
How to Win a Data Science Competition: Learn from Top Kagglers,https://www.coursera.org/learn/competitive-data-science,4.7,"105,047","Dmitry Ulyanov,Alexander Guschin,Mikhail Trofimov,Dmitry Altukhov,Marios Michailidis",54 hours,Advanced,,"If you want to break into competitive data science, then this course is for you! Participating in predictive modelling competitions can help you gain practical experience, improve and harness your data modelling skills in various domains such as credit, insurance, marketing, natural language processing, sales’ forecasting and computer vision to name a few. At the same time you get to do it in a competitive context against thousands of participants where each one tries to build the most predictive algorithm. Pushing each other to the limit can result in better performance and smaller prediction errors. Being able to achieve high ranks consistently can help you accelerate your career in data science. In this course, you will learn to analyse and solve competitively such predictive modelling tasks. When you finish this class, you will:- Understand how to solve predictive modelling competitions efficiently and learn which of the skills obtained can be applicable to real-world tasks.- Learn how to preprocess the data and generate new features from various sources such as text and images.- Be taught advanced feature engineering techniques like generating mean-encodings, using aggregated statistical measures or finding nearest neighbors as a means to improve your predictions.- Be able to form reliable cross validation methodologies that help you benchmark your solutions and avoid overfitting or underfitting when tested with unobserved (test) data. - Gain experience of analysing and interpreting the data. You will become aware of inconsistencies, high noise levels, errors and other data-related issues such as leakages and you will learn how to overcome them. - Acquire knowledge of different algorithms and learn how to efficiently tune their hyperparameters and achieve top performance. - Master the art of combining different machine learning models and learn how to ensemble. - Get exposed to past (winning) solutions and codes and learn how to read them.Disclaimer : This is not a machine learning online course in the general sense. This course will teach you how to get high-rank solutions against thousands of competitors with focus on practical usage of machine learning methods rather than the theoretical underpinnings behind them.Prerequisites: - Python: work with DataFrames in pandas, plot figures in matplotlib, import and train models from scikit-learn, XGBoost, LightGBM.- Machine Learning: basic understanding of linear models, K-NN, random forest, gradient boosting and neural networks.Do you have technical problems? Write to us: coursera@hse.ru",Data Analysis          Feature Extraction          Feature Engineering          Xgboost      ,Data Science,HSE University,Enroll for Free,Advanced Machine Learning Specialization,"Dmitry Ulyanov work for HSE University,Alexander Guschin work for HSE University,Mikhail Trofimov work for HSE University,Dmitry Altukhov work for HSE University,Marios Michailidis work for HSE University","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Code Free Data Science,https://www.coursera.org/learn/code-free-data-science,4.3,"10,394","Natasha Balac, Ph.D.",14 hours,Beginner,,"How to design Data Science workflows without any programming involved. Essential Data Science skills to design, build, test and evaluate predictive models. Data Manipulation, preparation and cclassification and clustering methods. Ways to apply Data Science algorithms to real data and evaluate and interpret the results",,Data Science,University of California San Diego,Enroll for Free,,"Natasha Balac, Ph.D. work for University of California San Diego","Subtitles: French, Portuguese (European), Russian, English, Spanish"
Analyzing Big Data with SQL,https://www.coursera.org/learn/cloudera-big-data-analysis-sql-queries,4.9,"20,566",Ian Cook,18 hours,Beginner,,Understand the basics of SELECT statements. Understand how and why to filter results. Explore grouping and aggregation to answer analytic questions. Work with sorting and limiting results,Apache Hive          Apache Impala          Data Analysis          Big Data          SQL      ,Data Science,Cloudera,Enroll for Free,Modern Big Data Analysis with SQL Specialization,Ian Cook work for Cloudera,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Managing Big Data in Clusters and Cloud Storage,https://www.coursera.org/learn/cloud-storage-big-data-analysis-sql,4.7,"9,115","Ian Cook,Glynn Durham",21 hours,Beginner,,Use different tools to browse existing databases and tables in big data systems. Use different tools to explore files in distributed big data filesystems and cloud storage. Create and manage big data databases and tables using Apache Hive and Apache Impala. Describe and choose among different data types and file formats for big data systems,Data Management          Distributed File Systems          Cloud Storage          Big Data          SQL      ,Data Science,Cloudera,Enroll for Free,Modern Big Data Analysis with SQL Specialization,"Ian Cook work for Cloudera,Glynn Durham work for Cloudera","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Cloud Data Engineering,https://www.coursera.org/learn/cloud-data-engineering-duke,4.5,"1,587",Noah Gift,17 hours,Intermediate,Beginner level Linux and Python skills,"Welcome to the third course in the Building Cloud Computing Solutions at Scale Specialization! In this course, you will learn how to apply Data Engineering to real-world projects using the Cloud computing concepts introduced in the first two courses of this series. By the end of this course, you will be able to develop Data Engineering applications and use software development best practices to create data engineering applications. These will include continuous deployment, code quality tools, logging, instrumentation and monitoring. Finally, you will use Cloud-native technologies to tackle complex data engineering solutions.  This course is ideal for beginners as well as intermediate students interested in applying Cloud computing to data science, machine learning and data engineering. Students should have beginner level Linux and intermediate level Python skills. For your project in this course, you will build a serverless data engineering pipeline in a Cloud platform: Amazon Web Services (AWS), Azure or Google Cloud Platform (GCP).",,Information Technology,Duke University,Enroll for Free,Building Cloud Computing Solutions at Scale Specialization,Noah Gift work for Duke University,Subtitles: English
Building Advanced Codeless Pipelines on Cloud Data Fusion,https://www.coursera.org/learn/cloud-data-fusion-building-advanced-codeless-pipelines,4.3,,Google Cloud Training,6 hours,Advanced,,"In this Google Cloud Labs Series, learners get hands-on practice on the more advanced data integration features available in Cloud Data Fusion, while sharing best practices to build more robust, reusable, dynamic pipelines. Learners get to try out the data lineage feature as well to derive interesting insights into their data’s history. Note: you will have timed access to the online environment. You will need to complete the lab within the allotted time.",Data Management          Data Pipelines          Cloud Data Fusion      ,Data Science,Google Cloud,Enroll,,Google Cloud Training work for Google Cloud,English
Cloud Data Security,https://www.coursera.org/learn/cloud-data-security,,,Rick Smith,11 hours,Intermediate,Complete ,How to analyze a data breach and trace it back to the vulnerability that made it possible. How data security and privacy requirements arise from legal obligations and industry standards.,HIPAA basics          Compare cloud data services          Analyze a data breach          Database security basics          PCI-DSS basics      ,Information Technology,University of Minnesota,Enroll for Free,Cybersecurity in the Cloud Specialization,Rick Smith work for University of Minnesota,English
Clinical Data Models and Data Quality Assessments,https://www.coursera.org/learn/clinical-data-models-and-data-quality-assessments,4.2,"4,996","Laura K. Wiley, PhD,Michael G. Kahn, MD, PhD",17 hours,Intermediate,,"This course aims to teach the concepts of clinical data models and common data models. Upon completion of this course, learners will be able to interpret and evaluate data model designs using Entity-Relationship Diagrams (ERDs), differentiate between data models and articulate how each are used to support clinical care and data science, and create SQL statements in Google BigQuery to query the MIMIC3 clinical data model and the OMOP common data model.",,Data Science,University of Colorado System,Enroll for Free,Clinical Data Science Specialization,"Laura K. Wiley, PhD work for University of Colorado System,Michael G. Kahn, MD, PhD work for University of Colorado System",Subtitles: English
Data Management for Clinical Research,https://www.coursera.org/learn/clinical-data-management,4.7,"72,267","Stephany Duda, PhD,Paul Harris, PhD",17 hours,Beginner,,"This course presents critical concepts and practical methods to support planning, collection, storage, and dissemination of data in clinical research. Understanding and implementing solid data management principles is critical for any scientific domain. Regardless of your current (or anticipated) role in the research enterprise, a strong working knowledge and skill set in data management principles and practice will increase your productivity and improve your science. Our goal is to use these modules to help you learn and practice this skill set. This course assumes very little current knowledge of technology other than how to operate a web browser. We will focus on practical lessons, short quizzes, and hands-on exercises as we explore together best practices for data management.",Survey Design          Data Collection          Data Management          Clinical Data Management      ,Health,Vanderbilt University,Enroll for Free,,"Stephany Duda, PhD work for Vanderbilt University, Coursera,Paul Harris, PhD work for Vanderbilt University, Coursera","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Calculus through Data & Modelling: Vector Calculus,https://www.coursera.org/learn/calculus-through-data-and-modelling-vector-calculus,4.8,,"Joseph W. Cutrone, PhD",5 hours,Intermediate,Working knowledge of differentiable calculus and some integral calculus of a single variable function. ,"This course continues your study of calculus by focusing on the applications of integration to vector valued functions, or vector fields. These are functions that assign vectors to points in space, allowing us to develop advanced theories to then apply to real-world problems. We define line integrals, which can be used to fund the work done by a vector field. We culminate this course with Green's Theorem, which describes the relationship between certain kinds of line integrals on closed paths and double integrals. In the discrete case, this theorem is called the Shoelace Theorem and allows us to measure the areas of polygons. We use this version of the theorem to develop more tools of data analysis through a peer reviewed project. Upon successful completion of this course, you have all the tools needed to master any advanced mathematics, computer science, or data science that builds off of the foundations of single or multivariable calculus.",,Math and Logic,Johns Hopkins University,Enroll for Free,Integral Calculus through Data and Modeling Specialization,"Joseph W. Cutrone, PhD work for Johns Hopkins University",Subtitles: English
Calculus through Data & Modelling: Techniques of Integration,https://www.coursera.org/learn/calculus-through-data-and-modelling-techniques-of-integration,,,"Joseph W. Cutrone, PhD",5 hours,Intermediate,,"In this course, we build on previously defined notions of the integral of a single-variable function over an interval. Now, we will extend our understanding of integrals to work with functions of more than one variable. First, we will learn how to integrate a real-valued multivariable function over different regions in the plane. Then, we will introduce vector functions, which assigns a point to a vector. This will prepare us for our final course in the specialization on vector calculus. Finally, we will introduce techniques to approximate definite integrals when working with discrete data and through a peer reviewed project on, apply these techniques real world problems.",,Math and Logic,Johns Hopkins University,Enroll for Free,Integral Calculus through Data and Modeling Specialization,"Joseph W. Cutrone, PhD work for Johns Hopkins University",Subtitles: English
Calculus through Data & Modeling: Differentiation Rules,https://www.coursera.org/learn/calculus-through-data-and-modelling-differentiation-rules,4.8,,"Joseph W. Cutrone, PhD",8 hours,Intermediate,,"Calculus through Data &amp; Modeling: Differentiation Rules continues the study of differentiable calculus by developing. new rules for finding derivatives without having to use the limit definition directly. These differentiation rules will enable the calculation of rates of change with relative ease the derivatives of polynomials, rational functions, algebraic functions, exponential and logarithmic functions, and trigonometric and inverse trigonometric functions. Once these rules are developed, they are then applied to solve problems involving rates of change and the approximation of functions.",,Math and Logic,Johns Hopkins University,Enroll for Free,Differential Calculus through Data and Modeling Specialization,"Joseph W. Cutrone, PhD work for Johns Hopkins University",Subtitles: English
Calculus through Data & Modelling: Series and Integration,https://www.coursera.org/learn/calculus-through-data-and-modelling-series-and-integrals,5,,"Joseph W. Cutrone, PhD",9 hours,Intermediate,,"This course continues your study of calculus by introducing the notions of series, sequences, and integration. These foundational tools allow us to develop the theory and applications of the second major tool of calculus: the integral. Rather than measure rates of change, the integral provides a means for measuring the accumulation of a quantity over some interval of input values. This notion of accumulation can be applied to different quantities, including money, populations, weight, area, volume, and air pollutants. The concepts in this course apply to many other disciplines outside of traditional mathematics. Through projects, we will apply the tools of this course to analyze and model real world data, and from that analysis give critiques of policy.  Following the pattern as with derivatives, several important methods for calculating accumulation are developed. Our course begins with the study of the deep and significant result of the Fundamental Theorem of Calculus, which develops the relationship between the operations of differentiation and integration. If you are interested in learning more advanced mathematics, this course is the right course for you.",,Math and Logic,Johns Hopkins University,Enroll for Free,Integral Calculus through Data and Modeling Specialization,"Joseph W. Cutrone, PhD work for Johns Hopkins University",Subtitles: English
Calculus through Data & Modeling: Applying Differentiation,https://www.coursera.org/learn/calculus-through-data-and-modelling-applying-differentiation,4.7,,"Joseph W. Cutrone, PhD",7 hours,Intermediate,,"As rates of change, derivatives give us information about the shape of a graph. In this course, we will apply the derivative to find linear approximations for single-variable and multi-variable functions. This gives us a straightforward way to estimate functions that may be complicated or difficult to evaluate. We will also use the derivative to locate the maximum and minimum values of a function. These optimization techniques are important for all fields, including the natural sciences and data analysis. The topics in this course lend themselves to many real-world applications, such as machine learning, minimizing costs or maximizing profits.",,Math and Logic,Johns Hopkins University,Enroll for Free,Differential Calculus through Data and Modeling Specialization,"Joseph W. Cutrone, PhD work for Johns Hopkins University",Subtitles: English
Calculus through Data & Modeling: Precalculus Review,https://www.coursera.org/learn/calculus-through-data-and-modelling-precalculus-review,4.8,"2,543","Joseph W. Cutrone, PhD",8 hours,Beginner,,"This course is an applications-oriented, investigative approach to the study of the mathematical topics needed for further coursework in single and multivariable calculus. The unifying theme is the study of functions, including polynomial, rational, exponential, logarithmic, and trigonometric functions. An emphasis is placed on using these functions to model and analyze data. Graphing calculators and/or the computer will be used as an integral part of the course.",,Math and Logic,Johns Hopkins University,Enroll for Free,Differential Calculus through Data and Modeling Specialization,"Joseph W. Cutrone, PhD work for Johns Hopkins University",Subtitles: English
Calculus through Data & Modeling: Limits & Derivatives,https://www.coursera.org/learn/calculus-through-data-and-modelling-imits-derivatives,4.8,,"Joseph W. Cutrone, PhD",10 hours,Beginner,,"This first course on concepts of single variable calculus will introduce the notions of limits of a function to define the derivative of a function. In mathematics, the derivative measures the sensitivity to change of the function. For example, the derivative of the position of a moving object with respect to time is the object's velocity: this measures how quickly the position of the object changes when time advances. This fundamental notion will be applied through the modelling and analysis of data.",,Math and Logic,Johns Hopkins University,Enroll for Free,Differential Calculus through Data and Modeling Specialization,"Joseph W. Cutrone, PhD work for Johns Hopkins University",Subtitles: English
Calculus through Data & Modelling: Integration Applications,https://www.coursera.org/learn/calculus-through-data-and-modelling-integration-applications,,,"Joseph W. Cutrone, PhD",6 hours,Intermediate,Some working knowledge of differentiable calculus. ,"This course continues your study of calculus by focusing on the applications of integration. The applications in this section have many common features. First, each is an example of a quantity that is computed by evaluating a definite integral. Second, the formula for that application is derived from Riemann sums. Rather than measure rates of change as we did with differential calculus, the definite integral allows us to measure the accumulation of a quantity over some interval of input values. This notion of accumulation can be applied to different quantities, including money, populations, weight, area, volume, and air pollutants. The concepts in this course apply to many other disciplines outside of traditional mathematics.We will expand the notion of the average value of a data set to allow for infinite values, develop the formula for arclength and curvature, and derive formulas for velocity, acceleration, and areas between curves. Through examples and projects, we will apply the tools of this course to analyze and model real world data.",,Math and Logic,Johns Hopkins University,Enroll for Free,Integral Calculus through Data and Modeling Specialization,"Joseph W. Cutrone, PhD work for Johns Hopkins University",Subtitles: English
Business intelligence and data warehousing,https://www.coursera.org/learn/business-intelligence-data-warehousing,3.9,"10,094",María del Pilar Ángeles,10 hours,Intermediate,,"Welcome to the specialization course Business Intelligence and Data Warehousing. This course will be completed on six weeks, it will be supported with videos and various documents that will allow you to learn in a very simple way how to identify, design and develop analytical information systems, such as Business Intelligence with a descriptive analysis on data warehouses. You will be able to understand the problem of integration and predictive analysis of high volume of unstructured data (big data) with data mining and the Hadoop framework. After completing this course, a learner will be able to●	Create a Star o Snowflake data model Diagram through the Multidimensional Design from analytical business requirements and OLTP system●	Create a physical database system ●	Extract, Transform and load data to a data-warehouse.●	Program analytical queries with SQL using MySQL●	Predictive analysis with RapidMiner●	Load relational or unstructured data to Hortonworks HDFS●	Execute Map-Reduce jobs to query data on HDFS for analytical purposesProgramming languages:For course 2 you will use the MYSQL language.Software to download:RapidminerMYSQLExcelHortonworks Hadoop frameworkIn case you have a Mac / IOS operating system you will need to use a virtual Machine (VirtualBox, Vmware).",Business Intelligence          Data Warehousing          Expected Return          Sap Hana      ,Data Science,Universidad Nacional Autónoma de México,Enroll for Free,Database systems Specialization,María del Pilar Ángeles work for Universidad Nacional Autónoma de México,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Business intelligence and data analytics: Generate insights,https://www.coursera.org/learn/business-intelligence-data-analytics,4.5,"11,685",Connor Stead,13 hours,,,"‘Megatrends’ heavily influence today’s organisations, industries and societies, and your ability to generate insights in this area is crucial to your organisation’s success into the future. This course will introduce you to analytical tools and skills you can use to understand, analyse and evaluate the challenges and opportunities ‘megatrends’ will inevitably bring to your organisation. Via structured learning activities you will explore how these trends can be addressed through sustainability-oriented innovation. You will be introduced to key data analytics concepts such as systems thinking, multi-level perspectives and multidisciplinary methods for envisioning futures, and apply them to specific real-world challenges you and your organisation may face. And there’ll be a focus on future-proofing skills such as teamwork, collaboration with diverse stakeholders and accounting for judgements made within ethical decision-making frameworks.",,Business,Macquarie University,Enroll for Free,Analysing: Numeric and digital literacies Specialization,Connor Stead work for Macquarie University,Subtitles: English
Exploring and Producing Data for Business Decision Making,https://www.coursera.org/learn/business-data,4.8,"33,594","Fataneh Taghaboni-Dutta, Ph.D., PMP",23 hours,Beginner,,"This course provides an analytical framework to help you evaluate key problems in a structured fashion and will equip you with tools to better manage the uncertainties that pervade and complicate business processes. Specifically, you.  will learn how to summarize data and learn concepts of frequency, normal distribution, statistical studies, sampling, and confidence intervals. While you will be introduced to some of the science of what is being taught, the focus will be on applying the methodologies. This will be accomplished through the use of Excel and data sets from different disciplines, allowing you to see the use of statistics in a range of settings. The course will focus not only on explaining these concepts, but also understanding and interpreting the results obtained. You will be able to: • Summarize large data sets in graphical, tabular, and numerical forms• Understand the significance of proper sampling and why one can rely on sample information• Understand why normal distribution can be used in a wide range of settings• Use sample information to make inferences about the population with a certain level of confidence about the accuracy of the estimations• Use Excel for statistical analysisThis course is part of Gies College of Business’ suite of online programs, including the iMBA and iMSM. Learn more about admission into these programs and explore how your Coursera work can be leveraged if accepted into a degree program at https://degrees.giesbusiness.illinois.edu/idegrees/.",Data Analysis          Microsoft Excel          Statistical Analysis          Normal Distribution      ,Business,University of Illinois at Urbana-Champaign,Enroll for Free,Managerial Economics and Business Analysis  Specialization,"Fataneh Taghaboni-Dutta, Ph.D., PMP work for University of Illinois at Urbana-Champaign","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Building a Data Science Team,https://www.coursera.org/learn/build-data-science-team,4.5,"42,405","Jeff Leek, PhD,Brian Caffo, PhD,Roger D. Peng, PhD",6 hours,,,Describe the various roles that make up a Data Science team. Manage a Data Science team onboarding. Know relevant questions for interviewing data scientists. Understand how to encourage and empower Data Science teams,Team Building          Data Science          Management          Team Management      ,Data Science,Johns Hopkins University,Enroll for Free,Executive Data Science Specialization,"Jeff Leek, PhD work for Johns Hopkins University,Brian Caffo, PhD work for Johns Hopkins University,Roger D. Peng, PhD work for Johns Hopkins University","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Big Data Services: Capstone Project,https://www.coursera.org/learn/big-data-services,,"1,792","Alexey A. Dral,Ivan Puzyrevskiy",3 hours,Advanced,,"Are you ready to close the loop on your Big Data skills? Do you want to apply all your knowledge you got from the previous courses in practice? Finally, in the Capstone project, you will integrate all the knowledge acquired earlier to build a real application leveraging the power of Big Data. You will be given a task to combine data from different sources of different types (static distributed dataset, streaming data, SQL or NoSQL storage). Combined, this data will be used to build a predictive model for a financial market (as an example). First, you design a system from scratch and share it with your peers to get valuable feedback. Second, you can make it public, so get ready to receive the feedback from your service users. Real-world experience without any 3G-glasses or mock interviews.",,Data Science,Yandex,Enroll for Free,,"Alexey A. Dral work for Coursera, Moscow Institute of Physics and Technology, Yandex,Ivan Puzyrevskiy work for Yandex",Subtitles: English
BigQuery Basics for Data Analysts,https://www.coursera.org/learn/bigquery-basics-data-analysts,4.7,"3,033",Google Cloud Training,5 hours,Beginner,,"Want to scale your data analysis efforts without managing database hardware? Learn the best practices for querying and getting insights from your data warehouse with this interactive collection of BigQuery Google Cloud Labs Series. BigQuery is Google's fully managed, NoOps, low-cost analytics database. With BigQuery you can query terabytes and terabytes of data without having any infrastructure to manage or needing a database administrator. BigQuery uses SQL and can take advantage of the pay-as-you-go model. BigQuery allows you to focus on analyzing data to find meaningful insights. Note: you will have timed access to the online environment. You will need to complete the lab within the allotted time.",Bigquery          Data Analysis          data          SQL      ,Data Science,Google Cloud,Enroll,,Google Cloud Training work for Google Cloud,English
Big Data Modeling and Management Systems,https://www.coursera.org/learn/big-data-management,4.4,"83,258","Ilkay Altintas,Amarnath Gupta",13 hours,,,"Once you’ve identified a big data issue to analyze, how do you collect, store and organize your data using Big Data solutions?. In this course, you will experience various data genres and management tools appropriate for each. You will be able to describe the reasons behind the evolving plethora of new big data platforms from the perspective of big data management systems and analytical tools. Through guided hands-on tutorials, you will become familiar with techniques using real-time and semi-structured data examples. Systems and tools discussed include: AsterixDB, HP Vertica, Impala, Neo4j, Redis, SparkSQL. This course provides techniques to extract value from existing untapped data sources and discovering new data sources. At the end of this course, you will be able to: * Recognize different data elements in your own work and in everyday life problems * Explain why your team needs to design a Big Data Infrastructure Plan and Information System Design * Identify the frequent data operations required for various types of data * Select a data model to suit the characteristics of your data. * Apply techniques to handle streaming data * Differentiate between a traditional Database Management System and a Big Data Management System * Appreciate why there are so many data management systems * Design a big data information system for an online game companyThis course is for those new to data science. Completion of Intro to Big Data is recommended. No prior programming experience is needed, although the ability to install applications and utilize a virtual machine is necessary to complete the hands-on assignments. Refer to the specialization technical requirements for complete hardware and software specifications.Hardware Requirements: (A) Quad Core Processor (VT-x or AMD-V support recommended), 64-bit; (B) 8 GB RAM; (C) 20 GB disk free. How to find your hardware information: (Windows): Open System by clicking the Start button, right-clicking Computer, and then clicking Properties; (Mac): Open Overview by clicking on the Apple menu and clicking “About This Mac.” Most computers with 8 GB RAM purchased in the last 3 years will meet the minimum requirements.You will need a high speed internet connection because you will be downloading files up to 4 Gb in size. Software Requirements: This course relies on several open-source software tools, including Apache Hadoop. All required software can be downloaded and installed free of charge (except for data charges from your internet provider). Software requirements include: Windows 7+, Mac OS X 10.10+, Ubuntu 14.04+ or CentOS 6+ VirtualBox 5+.",Data Model          Big Data          Data Modeling          Data Management      ,Data Science,University of California San Diego,Enroll for Free,Big Data Specialization,"Ilkay Altintas work for University of California San Diego,Amarnath Gupta work for University of California San Diego","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, Turkish, English, Spanish"
Machine Learning With Big Data,https://www.coursera.org/learn/big-data-machine-learning,4.6,"61,519","Mai Nguyen,Ilkay Altintas",22 hours,,,"Want to make sense of the volumes of data you have collected?. Need to incorporate data-driven decisions into your process?. This course provides an overview of machine learning techniques to explore, analyze, and leverage data. You will be introduced to tools and algorithms you can use to create machine learning models that learn from data, and to scale those models up to big data problems. At the end of the course, you will be able to:•	Design an approach to leverage data using the steps in the machine learning process.•	Apply machine learning techniques to explore and prepare data for modeling.•	Identify the type of machine learning problem in order to apply the appropriate set of techniques.•	Construct models that learn from data using widely available open source tools.•	Analyze big data problems using scalable machine learning algorithms on Spark.Software Requirements: Cloudera VM, KNIME, Spark",Machine Learning Concepts          Knime          Machine Learning          Apache Spark      ,Data Science,University of California San Diego,Enroll for Free,Big Data Specialization,"Mai Nguyen work for University of California San Diego,Ilkay Altintas work for University of California San Diego","Arabic, French, Portuguese (European), Chinese (Simplified), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Big Data - Capstone Project,https://www.coursera.org/learn/big-data-project,4.4,"13,455","Ilkay Altintas,Amarnath Gupta",21 hours,,,"Welcome to the Capstone Project for Big Data! In this culminating project, you will build a big data ecosystem using tools and methods form the earlier courses in this specialization. You will analyze a data set simulating big data generated from a large number of users who are playing our imaginary game ""Catch the Pink Flamingo"". During the five week Capstone Project, you will walk through the typical big data science steps for acquiring, exploring, preparing, analyzing, and reporting. In the first two weeks, we will introduce you to the data set and guide you through some exploratory analysis using tools such as Splunk and Open Office. Then we will move into more challenging big data problems requiring the more advanced tools you have learned including KNIME, Spark's MLLib and Gephi. Finally, during the fifth and final week, we will show you how to bring it all together to create engaging and compelling reports and slide presentations. As a result of our collaboration with Splunk, a software company focus on analyzing machine-generated big data, learners with the top projects will be eligible to present to Splunk and meet Splunk recruiters and engineering leadership.",Big Data          Neo4j          Knime          Splunk      ,Data Science,University of California San Diego,Enroll for Free,Big Data Specialization,"Ilkay Altintas work for University of California San Diego,Amarnath Gupta work for University of California San Diego","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish, Polish"
Big data and Language 2,https://www.coursera.org/learn/big-data-language-2,,"2,254",Seonmin Park,5 hours,Beginner,,"In this course, students will understand characteristics of language through big data. Students will learn how to collect and analyze big data, and find linguistic features from the data. A number of approaches to the linguistic analysis of written and spoken texts will be discussed.",,Language Learning,Korea Advanced Institute of Science and Technology(KAIST),Enroll for Free,,Seonmin Park work for Korea Advanced Institute of Science and Technology(KAIST),"Subtitles: French, Portuguese (European), Russian, English, Spanish"
Graph Analytics for Big Data,https://www.coursera.org/learn/big-data-graph-analytics,4.3,"42,389",Amarnath Gupta,13 hours,,,"Want to understand your data network structure and how it changes under different conditions? Curious to know how to identify closely interacting clusters within a graph? Have you heard of the fast-growing area of graph analytics and want to learn more? This course gives you a broad overview of the field of graph analytics so you can learn new ways to model, store, retrieve and analyze graph-structured data. After completing this course, you will be able to model a problem into a graph database and perform analytical tasks over the graph in a scalable manner. Better yet, you will be able to apply these techniques to understand the significance of your data sets for your own projects.",Graph Theory          Neo4j          Analytics          Graph Database      ,Data Science,University of California San Diego,Enroll for Free,Big Data Specialization,Amarnath Gupta work for University of California San Diego,"Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Introduction to Big Data,https://www.coursera.org/learn/big-data-introduction,4.6,"272,795","Ilkay Altintas,Amarnath Gupta",17 hours,,,"Interested in increasing your knowledge of the Big Data landscape?. This course is for those new to data science and interested in understanding why the Big Data Era has come to be. It is for those who want to become conversant with the terminology and the core concepts behind big data problems, applications, and systems. It is for those who want to start thinking about how Big Data might be useful in their business or career. It provides an introduction to one of the most common frameworks, Hadoop, that has made big data analysis easier and more accessible -- increasing the potential for data to transform our world!. At the end of this course, you will be able to:* Describe the Big Data landscape including examples of real world big data problems including the three key sources of Big Data: people, organizations, and sensors. * Explain the V’s of Big Data (volume, velocity, variety, veracity, valence, and value) and why each impacts data collection, monitoring, storage, analysis and reporting.* Get value out of Big Data by using a 5-step process to structure your analysis. * Identify what are and what are not big data problems and be able to recast big data problems as data science questions.* Provide an explanation of the architectural components and programming models used for scalable big data analysis.* Summarize the features and value of core Hadoop stack components including the YARN resource and job management system, the HDFS file system and the MapReduce programming model.* Install and run a program using Hadoop!This course is for those new to data science. No prior programming experience is needed, although the ability to install applications and utilize a virtual machine is necessary to complete the hands-on assignments. Hardware Requirements:(A) Quad Core Processor (VT-x or AMD-V support recommended), 64-bit; (B) 8 GB RAM; (C) 20 GB disk free. How to find your hardware information: (Windows): Open System by clicking the Start button, right-clicking Computer, and then clicking Properties; (Mac): Open Overview by clicking on the Apple menu and clicking “About This Mac.” Most computers with 8 GB RAM purchased in the last 3 years will meet the minimum requirements.You will need a high speed internet connection because you will be downloading files up to 4 Gb in size. Software Requirements:This course relies on several open-source software tools, including Apache Hadoop. All required software can be downloaded and installed free of charge. Software requirements include: Windows 7+, Mac OS X 10.10+, Ubuntu 14.04+ or CentOS 6+ VirtualBox 5+.",Big Data          Apache Hadoop          Mapreduce          Cloudera      ,Data Science,University of California San Diego,Enroll for Free,Big Data Specialization,"Ilkay Altintas work for University of California San Diego,Amarnath Gupta work for University of California San Diego","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish, Hindi, Persian"
Big Data Emerging Technologies,https://www.coursera.org/learn/big-data-emerging-technologies,4.7,"18,651",Jong-Moon Chung,30 hours,Beginner,,"Every time you use Google to search something, every time you use Facebook, Twitter, Instagram or any other SNS (Social Network Service), and every time you buy from a recommended list of products on Amazon.com you are using a big data system. In addition, big data technology supports your smartphone, smartwatch, Alexa, Siri, and automobile (if it is a newer model) every day. The top companies in the world are currently using big data technology, and every company is in need of advanced big data technology support. Simply put, big data technology is not an option for your company, it is a necessity for survival and growth. So now is the right time to learn what big data is and how to use it in advantage of your company. This 6 module course first focuses on the world’s industry market share rankings of big data hardware, software, and professional services, and then covers the world’s top big data product line and service types of the major big data companies. Then the lectures focused on how big data analysis is possible based on the world’s most popular three big data technologies Hadoop, Spark, and Storm. The last part focuses on providing experience on one of the most famous and widely used big data statistical analysis systems in the world, the IBM SPSS Statistics. This course was designed to prepare you to be more successful in businesses strategic planning in the upcoming big data era. Welcome to the amazing Big Data world!",,Information Technology,Yonsei University,Enroll for Free,Emerging Technologies: From Smartphones to IoT to Big Data Specialization,"Jong-Moon Chung work for Yonsei University, Coursera","Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
"Big Data Essentials: HDFS, MapReduce and Spark RDD",https://www.coursera.org/learn/big-data-essentials,3.9,"51,942","Ivan Puzyrevskiy,Emeli Dral ,Evgeniy Riabenko,Alexey A. Dral,Pavel Mezentsev ",41 hours,Intermediate,,"Have you ever heard about such technologies as HDFS, MapReduce, Spark? Always wanted to learn these new tools but missed concise starting material? Don’t miss this course either!. In this 6-week course you will:- learn some basic technologies of the modern Big Data landscape, namely: HDFS, MapReduce and Spark;- be guided both through systems internals and their applications;- learn about distributed file systems, why they exist and what function they serve;- grasp the MapReduce framework, a workhorse for many modern Big Data applications;- apply the framework to process texts and solve sample business cases;- learn about Spark, the next-generation computational framework;- build a strong understanding of Spark basic concepts;- develop skills to apply these tools to creating solutions in finance, social networks, telecommunications and many other fields.Your learning experience will be as close to real life as possible with the chance to evaluate your practical assignments on a real cluster. No mocking, a friendly considerate atmosphere to make the process of your learning smooth and enjoyable. Get ready to work with real datasets alongside with real masters!Special thanks to:- Prof. Mikhail Roytberg, APT dept., MIPT, who was the initial reviewer of the project, the supervisor and mentor of half of the BigData team. He was the one, who helped to get this show on the road.- Oleg Sukhoroslov (PhD, Senior Researcher at IITP RAS), who has been teaching. MapReduce, Hadoop. and friends since 2008. Now he is leading the infrastructure team.- Oleg Ivchenko (PhD student APT dept., MIPT), Pavel Akhtyamov (MSc. student at APT dept., MIPT) and Vladimir Kuznetsov (Assistant at P.G. Demidov Yaroslavl State University), superbrains who have developed and now maintain the infrastructure used for practical assignments in this course.- Asya Roitberg, Eugene Baulin, Marina Sudarikova. These people never sleep to babysit this course day and night, to make your learning experience productive, smooth and exciting.",Python Programming          Apache Hadoop          Mapreduce          Apache Spark      ,Computer Science,Yandex,Enroll for Free,,"Ivan Puzyrevskiy work for Yandex,Emeli Dral  work for Moscow Institute of Physics and Technology, Yandex, E-Learning Development Fund,Evgeniy Riabenko work for HSE University, Moscow Institute of Physics and Technology, Yandex, E-Learning Development Fund,Alexey A. Dral work for Coursera, Moscow Institute of Physics and Technology, Yandex,Pavel Mezentsev  work for Moscow Institute of Physics and Technology, Yandex","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Big data and Language 1,https://www.coursera.org/learn/big-data-language-1,4.5,"5,125",Seonmin Park,4 hours,Beginner,,"In this course, students will understand characteristics of language through big data. Students will learn how to collect and analyze big data, and find linguistic features from the data. A number of approaches to the linguistic analysis of written and spoken texts will be discussed. The class will consist of lecture videos which are approximately 1 hour and a quiz for each week. There will be a final project which requires students to conduct research on text data and language.",,Language Learning,Korea Advanced Institute of Science and Technology(KAIST),Enroll for Free,,Seonmin Park work for Korea Advanced Institute of Science and Technology(KAIST),"Subtitles: French, Portuguese (European), Russian, English, Spanish"
Big Data Analysis Deep Dive,https://www.coursera.org/learn/big-data-analysis-deep-dive,,,Jeremy Pedersen,14 hours,Intermediate,,"The job market for architects, engineers, and analytics professionals with Big Data expertise continues to increase. The Academy’s Big Data Career path focuses on the fundamental tools and techniques needed to pursue a career in Big Data.  This course includes: data processing with python, writing and reading SQL queries, transmitting data with MaxCompute, analyzing data with Quick BI, using Hive, Hadoop, and spark on E-MapReduce, and how to visualize data with data dashboards. Work through our course material, learn different aspects of the Big Data field, and get certified as a Big Data Professional!",Big Data          Big Data Transmission          Big Data Visualisation      ,Information Technology,Alibaba Cloud Academy,Enroll for Free,,Jeremy Pedersen work for Alibaba Cloud Academy,English
Big Data Integration and Processing,https://www.coursera.org/learn/big-data-integration-processing,4.4,"64,488","Ilkay Altintas,Amarnath Gupta",18 hours,Beginner,,"At the end of the course, you will be able to:. *Retrieve data from example database and big data management systems *Describe the connections between data management operations and the big data processing patterns needed to utilize them in large-scale analytical applications*Identify when a big data problem needs data integration*Execute simple big data integration and processing on Hadoop and Spark platformsThis course is for those new to data science. Completion of Intro to Big Data is recommended. No prior programming experience is needed, although the ability to install applications and utilize a virtual machine is necessary to complete the hands-on assignments. Refer to the specialization technical requirements for complete hardware and software specifications.Hardware Requirements: (A) Quad Core Processor (VT-x or AMD-V support recommended), 64-bit; (B) 8 GB RAM; (C) 20 GB disk free. How to find your hardware information: (Windows): Open System by clicking the Start button, right-clicking Computer, and then clicking Properties; (Mac): Open Overview by clicking on the Apple menu and clicking “About This Mac.” Most computers with 8 GB RAM purchased in the last 3 years will meet the minimum requirements.You will need a high speed internet connection because you will be downloading files up to 4 Gb in size. Software Requirements: This course relies on several open-source software tools, including Apache Hadoop. All required software can be downloaded and installed free of charge (except for data charges from your internet provider). Software requirements include: Windows 7+, Mac OS X 10.10+, Ubuntu 14.04+ or CentOS 6+ VirtualBox 5+.",Big Data          Mongodb          Splunk          Apache Spark      ,Data Science,University of California San Diego,Enroll for Free,Big Data Specialization,"Ilkay Altintas work for University of California San Diego,Amarnath Gupta work for University of California San Diego","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Building Batch Data Pipelines on GCP,https://www.coursera.org/learn/batch-data-pipelines-gcp,4.5,"30,298",Google Cloud Training,13 hours,Intermediate,,"Data pipelines typically fall under one of the Extra-Load, Extract-Load-Transform or Extract-Transform-Load paradigms. This course describes which paradigm should be used and when for batch data. Furthermore, this course covers several technologies on Google Cloud Platform for data transformation including BigQuery, executing Spark on Cloud Dataproc, pipeline graphs in Cloud Data Fusion and serverless data processing with Cloud Dataflow. Learners will get hands-on experience building data pipeline components on Google Cloud Platform using Qwiklabs.",,Information Technology,Google Cloud,Enroll,,Google Cloud Training work for Google Cloud,"Subtitles: French, Portuguese (European), Russian, English, Spanish"
"Big Data, Artificial Intelligence, and Ethics",https://www.coursera.org/learn/big-data-ai-ethics,4.6,"18,760",Martin Hilbert,12 hours,Beginner,,Define and discuss big data opportunities and limitations. Work with IBM Watson and analyze a personality through Natural Language Programming (NLP). Examine how AI is used through case studies. Examine and discuss the roles ethics play in AI and big data.,,Data Science,"University of California, Davis",Enroll for Free,Computational Social Science Specialization,"Martin Hilbert work for University of California, Davis","Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Basic Data Processing and Visualization,https://www.coursera.org/learn/basic-data-processing-visualization-python,4.3,"17,086","Julian McAuley,Ilkay Altintas",11 hours,Intermediate,B​asic knowledge of programming (any language),"Develop data strategy and process for how data will be generated, collected, and consumed. Load and process formatted datasets such as CSV and JSON. Deal with data in various formats (e.g. timestamps, strings) and filter and “clean” datasets by removing outliers etc. Basic experience with data processing libraries such as numpy and data ingestion with urllib, requests",Python Libraries          Data Pre-Processing          Data Visualization (DataViz)          Web Scraping      ,Data Science,University of California San Diego,Enroll for Free,Python Data Products for Predictive Analytics Specialization,"Julian McAuley work for University of California San Diego,Ilkay Altintas work for University of California San Diego","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Analyze Datasets and Train ML Models using AutoML,https://www.coursera.org/learn/automl-datasets-ml-models,4.5,"11,284","Antje Barth,Shelbee Eigenbrode,Sireesha Muppala,Chris Fregly",19 hours,Advanced,"Working knowledge of ML & Python, familiarity with Jupyter notebook & stat, completion of the Deep Learning & AWS Cloud Technical Essentials courses","Prepare data, detect statistical data biases, and perform feature engineering at scale to train models with pre-built algorithms.",Statistical Data Bias Detection          Multi-class Classification with FastText and BlazingText          Data ingestion          Exploratory Data Analysis          Automated Machine Learning (AutoML)      ,Data Science,"DeepLearning.AI,Amazon Web Services",Enroll for Free,Practical Data Science Specialization,"Antje Barth work for DeepLearning.AI,Shelbee Eigenbrode work for Amazon Web Services, DeepLearning.AI,Sireesha Muppala work for DeepLearning.AI,Chris Fregly work for Amazon Web Services, DeepLearning.AI",English
Using Asylo to Protect Secret Data from an Attacker with Root Privileges,https://www.coursera.org/learn/asylo-protect-secret-data,,,Google Cloud Training,1 hour,Intermediate,,"In this Google Cloud Lab, you build a simple example enclave. The example demonstrates initializing an enclave, passing arguments to code running inside the enclave, encrypting those arguments inside the enclave, and returning the processed results. Even though this is a very simple example, it demonstrates the basic functionality provided by Asylo and the steps required to utilize that functionality. What is Asylo?Asylo is an open-source framework for developing enclave applications. It defines an abstract enclave model that can be mapped transparently onto a variety of enclave technologies (a.k.a., enclave backends). Asylo provides a software-development platform that supports a growing range of use cases. In a sense, the enclave backend can be viewed as a special-purpose embedded computer running inside a conventional machine, with Asylo providing the necessary runtime for that embedded computer.What is an enclave?On traditional systems, the Operating System (OS) kernel has unrestricted access to a machine's hardware resources. The kernel typically exposes most of its access permissions to a root user without any restrictions. Additionally, a root user can extend or modify the kernel on a running system. As a result, if an attacker can execute code with root privileges, they can compromise every secret and bypass every security policy on the machine. For instance, if an attacker obtains root access on a machine that manages TLS keys, those keys may be compromised.Enclaves are an emerging technology paradigm that changes this equation. An enclave is a special execution context where code can run protected from even the OS kernel, with the guarantee that even a user running with root privileges cannot extract the enclave's secrets or compromise its integrity. Such protections are enabled through hardware isolation technologies such as Intel SGX or ARM TrustZone, or even through additional software layers such as a hypervisor. These technologies enable new forms of isolation beyond the usual kernel/user-space separation.New security features are exciting for developers building secure applications, but in practice there is a big gap between having a raw capability and developing applications that leverage that capability. Building useful enclave applications requires tools to construct, load, and operate enclaves. Doing useful work in an enclave requires programming-language support and access to core platform libraries.Note: you will have timed access to the online environment. You will need to complete the lab within the allotted time.",enclave applications          Enclave          security          Asylo      ,Information Technology,Google Cloud,Enroll,,Google Cloud Training work for Google Cloud,English
Applying Data Analytics in Marketing,https://www.coursera.org/learn/applying-data-analytics-business-in-marketing,4.5,"15,065",Joseph T. Yun,12 hours,Intermediate,A basic familiarity with R is recommended.,"This course introduces students to customer satisfaction measurement through a wide range of analytical approaches. We will discuss the components of customer satisfaction, major issues in measuring customer satisfaction, statistical methods in analyzing customer satisfaction influence, sentiment analysis with social media data, influence analysis with social media data, and text summarization with social media data. This course aims to provide the foundation required to make better marketing decisions by analyzing multiple types of data related to customer satisfaction.",Data Analysis          Analytics          Marketing          Marketing Analytics      ,Business,University of Illinois at Urbana-Champaign,Enroll for Free,Business Analytics Specialization,Joseph T. Yun work for University of Illinois at Urbana-Champaign,English
Applying Data Analytics in Finance,https://www.coursera.org/learn/applying-data-analytics-business-in-finance,4.5,"15,054","Sung Won Kim,Jose Luis Rodriguez",23 hours,Intermediate,,Understand the forecasting process. Describe time series data. Develop an ARIMA Model. Understand a basic trading algorithm,,Business,University of Illinois at Urbana-Champaign,Enroll for Free,,"Sung Won Kim work for University of Illinois at Urbana-Champaign,Jose Luis Rodriguez work for University of Illinois at Urbana-Champaign, Coursera Project Network","Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Applied Data Science for Data Analysts,https://www.coursera.org/learn/applied-data-science-for-data-analysts,4.2,"1,910","Kevin Coyle,Mark Roepke,Emma Freeman",16 hours,Intermediate,Completion of the first two courses in the Data Science with Databricks for Data Analysts Coursera specialization. This course is the final course.,Explore data using unsupervised machine learning.  Solve complex supervised learning problems using tree-based models. Apply hyperparameter tuning and cross-validation strategies to improve model performance.,Data Science          Machine Learning          Databricks      ,Data Science,Databricks,Enroll for Free,Data Science with Databricks for Data Analysts Specialization,"Kevin Coyle work for Databricks,Mark Roepke work for Databricks,Emma Freeman work for Databricks",English
Applied Data Science Capstone,https://www.coursera.org/learn/applied-data-science-capstone,4.7,"87,418","Yan Luo,Joseph Santarcangelo",11 hours,Intermediate,,"Explain the capstone project scenario and a problem that you will solve with location data.  Select a location data provider based on its features.  Demonstrate proficiency by creating a Jupyter Notebook for the capstone project and sharing it for peer review.  Describe the types of location data available in the Foursquare dataset.",Data Science          Methodology          Github          Jupyter Notebook          K-Means Clustering      ,Data Science,IBM,Enroll for Free,,"Yan Luo work for IBM,Joseph Santarcangelo work for Coursera, IBM",English
Apache Spark (TM) SQL for Data Analysts,https://www.coursera.org/learn/apache-spark-sql-for-data-analysts,4.6,"9,642",Kate Sullivan,14 hours,Intermediate,Familiarity with SQL ,"Ingest, transform, and query data to extract valuable insights. Leverage existing SQL skills to start working with Apache Spark.",Data Analysis          Spark SQL          SQL      ,Data Science,Databricks,Enroll for Free,Data Science with Databricks for Data Analysts Specialization,Kate Sullivan work for Databricks,English
Applied Analytics and Data for Decision Making,https://www.coursera.org/learn/analytics-data-decisions,4.5,,"Akshay Sivadas,Brittany O'Dea",11 hours,Beginner,"It is helpful if learners have some familiarity with reading reports, gathering and using data, and interpreting visualizations.","Describe techniques to Identify root causes of variation and tools for evaluating potential solutions. Apply the Design of Experiments (DOE) technique to test improvement options. Evaluate, for a specific organization, which operational excellence methodology provides the maximum value. Explain how to foster a culture of data literacy",ISO 9001: 2015          Lean          Design of Experiments (DOE)          Data-Driven Decision Making          Six Sigma      ,Business,"University at Buffalo,The State University of New York",Enroll for Free,Data-Driven Decision Making (DDDM) Specialization,"Akshay Sivadas work for The State University of New York, University at Buffalo,Brittany O'Dea work for The State University of New York",English
Analyze Data to Answer Questions,https://www.coursera.org/learn/analyze-data,4.6,"78,275",Google Career Certificates,26 hours,Beginner,No prior experience with spreadsheets or data analytics is required. All you need is high-school level math and a curiosity about how things work. ,Discuss the importance of organizing your data before analysis with references to sorts and filters. Demonstrate an understanding of what is involved in the conversion and formatting of data. Apply the use of functions and syntax to create SQL queries for combining data from multiple database tables. Describe the use of functions to conduct basic calculations on data in spreadsheets,Spreadsheet          Data Analysis          SQL          Data Calculations          Data Aggregation      ,Data Science,Google,Enroll for Free,Google Data Analytics Professional Certificate,Google Career Certificates work for Google,English
Big Data Analytical Platform on Alibaba Cloud ,https://www.coursera.org/learn/alibabacloudbigdata,4.4,,Derek Meng,8 hours,Intermediate,"Cloud Computing Fundamental Knowledge, Background in Statistical Theory ",Learn the Big Data Theory. Take data in different formats to Put in Alibaba Cloud Big Data Products. Analyze Sets of Data to produce meaningful conclusions. Draw Graphs and Tables to demonstrate the analysis of Big Data Results,,Information Technology,Alibaba Cloud Academy,Enroll for Free,Alibaba Cloud Computing Specialization,Derek Meng work for Alibaba Cloud Academy,Subtitles: English
"Graph Search, Shortest Paths, and Data Structures",https://www.coursera.org/learn/algorithms-graphs-data-structures,4.8,"66,570",Tim Roughgarden,15 hours,Intermediate,,"The primary topics in this part of the specialization are: data structures (heaps, balanced search trees, hash tables, bloom filters), graph primitives (applications of breadth-first and depth-first search, connectivity, shortest paths), and their applications (ranging from deduplication to social network analysis).",Graphs          Data Structure          Algorithms          Hash Table      ,Computer Science,Stanford University,Enroll for Free,Algorithms Specialization,Tim Roughgarden work for Stanford University,"Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
"Algorithms, Data Collection, and Starting to Code",https://www.coursera.org/learn/algorithms-data-collection-code,4.6,"16,586","Dr. Tim ""Dr. T"" Chamillard",15 hours,Beginner,,"This course starts you on your journey learning about computational thinking and beginning C programming. If you’d like to explore how we can interact with the world in a rigorous, computational way, and would also like to start learning to program, this is the course for you!. You may have heard lots of talk about computational thinking recently, but if you ask 10 different people what it is you’ll probably get 10 different answers. Rather than trying to define computational thinking, we’ll just say it’s a problem-solving process that includes lots of different components. In this course, we’ll explore algorithms and data collection.Most people have a better understanding of what beginning C programming means! You’ll start learning how to develop C programs in this course by writing your first C program; learning about data types, variables, and constants; and honing your C programming skills by implementing a variety of STEM computations. This course doesn't assume you have any previous programming experience, so don't worry if you've never written code before.If that all sounds interesting to you, go ahead and jump into the course!Caution: Beginning (assuming no prior programming knowledge) is not the same as easy (not hard to do). Learning to program IS hard to do, especially since the courses in this specialization are built from a freshman-level college course. Meeting the course challenges while you master the material will be rewarding to you, but doing that will require hard work and maybe even a few expletives along the way.Module 1: Learn about algorithms and write your first C programModule 2: Discover how we store data in our programsModule 3: Explore how we use data collection to solve problems and answer questionsModule 4: Practice writing C programs to implement STEM computations",,Computer Science,University of Colorado System,Enroll for Free,Computational Thinking with Beginning C Programming Specialization,"Dr. Tim ""Dr. T"" Chamillard work for Coursera, University of Colorado System","Subtitles: Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
"Artificial Intelligence Data Fairness and Bias						",https://www.coursera.org/learn/ai-data-bias,4.8,"3,247",Brent Summers,6 hours,Beginner,,"In this course, we will explore fundamental issues of fairness and bias in machine learning. As predictive models begin making important decisions, from college admission to loan decisions, it becomes paramount to keep models from making unfair predictions. From human bias to dataset awareness, we will explore many aspects of building more ethical models.",machine learning fairness          Ethics          data bias      ,Computer Science,LearnQuest,Enroll for Free,Ethics in the Age of AI Specialization,Brent Summers work for LearnQuest,"French, Portuguese (European), Russian, English, Spanish"
Advanced Clinical Data Science,https://www.coursera.org/learn/advanced-clinical-data-science,,,"Michael G. Kahn, MD, PhD,Laura K. Wiley, PhD",4 hours,Intermediate,,This course prepares you to deal with advanced clinical data science topics and techniques including temporal and research quality analysis.,,Data Science,University of Colorado System,Enroll for Free,Clinical Data Science Specialization,"Michael G. Kahn, MD, PhD work for University of Colorado System,Laura K. Wiley, PhD work for University of Colorado System",Subtitles: English
Advanced Data Science Capstone,https://www.coursera.org/learn/advanced-data-science-capstone,4.6,"13,148",Romeo Kienzler,9 hours,Advanced,,"This project completer has proven a deep understanding on massive parallel data processing, data exploration and visualization, advanced machine learning and deep learning and how to apply his knowledge in a real-world practical use case where he justifies architectural decisions, proves understanding the characteristics of different algorithms, frameworks and technologies and how they impact model performance and scalability. . Please note: You are requested to create a short video presentation at the end of the course. This is mandatory to pass. You don't need to share the video in public.",,Data Science,IBM,Enroll for Free,Advanced Data Science with IBM Specialization,Romeo Kienzler work for IBM,"Subtitles: Arabic, French, Portuguese (European), Chinese (Simplified), Russian, English, Spanish"
Advanced Data Structures in Java,https://www.coursera.org/learn/advanced-data-structures,4.8,"73,266","Leo Porter,Mia Minnes,Christine Alvarado",29 hours,Intermediate,,"How does Google Maps plan the best route for getting around town given current traffic conditions?. How does an internet router forward packets of network traffic to minimize delay?. How does an aid group allocate resources to its affiliated local partners?. To solve such problems, we first represent the key pieces of data in a complex data structure. In this course, you’ll learn about data structures, like graphs, that are fundamental for working with structured real world data. You will develop, implement, and analyze algorithms for working with this data to solve real world problems.  In addition, as the programs you develop in this course become more complex, we’ll examine what makes for good code and class hierarchy design so that you can not only write correct code, but also share it with other people and maintain it in the future.The backbone project in this course will be a route planning application. You will apply the concepts from each Module directly to building an application that allows an autonomous agent (or a human driver!) to navigate its environment. And as usual we have our different video series to help tie the content back to its importance in the real world and to provide tiered levels of support to meet your personal needs.",Graphs          Search Algorithm          Graph Algorithms          Graph Data Structures      ,Computer Science,University of California San Diego,Enroll for Free,Object Oriented Java Programming: Data Structures and Beyond Specialization,"Leo Porter work for University of California San Diego,Mia Minnes work for University of California San Diego,Christine Alvarado work for University of California San Diego","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Accounting Data Analytics with Python,https://www.coursera.org/learn/accounting-data-analytics-python,4.1,"8,065","Ronald Guymon,Linden Lu",32 hours,Intermediate,,"Know how to operate software that will help you create and run Python code. Execute Python code for wrangling data from different structures into a Pandas dataframe structure. Run and interpret fundamental data analytic tasks in Python including descriptive statistics, data visualizations, and regression. Use relational databases and know how to manipulate such databases directly through the command line, and indirectly through a Python script.",Python Programming          Data Visualization (DataViz)          Linear Regression          SQL          Data Preparation      ,Data Science,University of Illinois at Urbana-Champaign,Enroll for Free,Accounting Data Analytics Specialization,"Ronald Guymon work for University of Illinois at Urbana-Champaign,Linden Lu work for University of Illinois at Urbana-Champaign","Arabic, French, Portuguese (European), Italian, Vietnamese, German, Russian, English, Spanish"
Data Analytics in Accounting Capstone,https://www.coursera.org/learn/accounting-data-analytics-capstone,,"1,781",Linden Lu,19 hours,Intermediate,,"This capstone is the last course in the Data Analytics in Accountancy Specialization. In this capstone course, you are going to take the knowledge and skills you have acquired from the previous courses and apply them to a real-world problem. You will be provided with a loan dataset from Lending Club which is the largest peer-to-peer lending platform. You will explore the characteristics of the features in the dataset through statistical analysis, exploratory data analysis and visualization. You will also create a machine learning model to predict whether a loan will be fully paid or not. Finally, you will construct a portfolio with the help of your analysis. The goal is to create a portfolio that achieves better return than the overall return of all loans on the Lending Club platform.",Data Analysis          Python Programming          Machine Learning          Data Visualization (DataViz)      ,Data Science,University of Illinois at Urbana-Champaign,Enroll for Free,Accounting Data Analytics Specialization,Linden Lu work for University of Illinois at Urbana-Champaign,"French, Portuguese (European), Javanese, Russian, English, Spanish"
"Big Data Analysis: Hive, Spark SQL, DataFrames and GraphFrames",https://www.coursera.org/learn/big-data-analysis,4,"29,461","Alexey A. Dral,Pavel Klemenkov,Natalia Pritykovskaya,Pavel Mezentsev ",37 hours,Advanced,,"No doubt working with huge data volumes is hard, but to move a mountain, you have to deal with a lot of small stones. But why strain yourself? Using. Mapreduce and Spark you tackle the issue partially, thus leaving some space for high-level tools. Stop. struggling to make your big data workflow productive and efficient,. make use of the tools we are offering you. This course will teach you how to:- Warehouse your data efficiently using Hive, Spark SQL and Spark DataFframes. - Work with large graphs, such as social graphs or networks. - Optimize your Spark applications for maximum performance.Precisely, you will master your knowledge in:- Writing and executing Hive &amp; Spark SQL queries;- Reasoning how the queries are translated into actual execution primitives (be it MapReduce jobs or Spark transformations);- Organizing your data in Hive to optimize disk space usage and execution times;- Constructing Spark DataFrames and using them to write ad-hoc analytical jobs easily;- Processing large graphs with Spark GraphFrames;- Debugging, profiling and optimizing Spark application performance. Still in doubt? Check this out. Become a data ninja by taking this course!Special thanks to:- Prof. Mikhail Roytberg, APT dept., MIPT, who was the initial reviewer of the project, the supervisor and mentor of half of the BigData team. He was the one, who helped to get this show on the road.- Oleg Sukhoroslov (PhD, Senior Researcher at IITP RAS), who has been teaching. MapReduce, Hadoop and friends since 2008. Now he is leading the infrastructure team.- Oleg Ivchenko (PhD student APT dept., MIPT), Pavel Akhtyamov (MSc. student at APT dept., MIPT) and Vladimir Kuznetsov (Assistant at P.G. Demidov Yaroslavl State University), superbrains who have developed and now maintain the infrastructure used for practical assignments in this course.- Asya Roitberg, Eugene Baulin, Marina Sudarikova. These people never sleep to babysit this course day and night, to make your learning experience productive, smooth and exciting.",Graphs          Hive          Apache Hive          Apache Spark      ,Data Science,Yandex,Enroll for Free,,"Alexey A. Dral work for Coursera, Moscow Institute of Physics and Technology, Yandex,Pavel Klemenkov work for Yandex,Natalia Pritykovskaya work for Yandex,Pavel Mezentsev  work for Moscow Institute of Physics and Technology, Yandex","Arabic, French, Portuguese (European), Italian, Vietnamese, Korean, German, Russian, English, Spanish"
Fundamentals of Big Data,https://www.coursera.org/learn/fundamentals-of-big-data,,,Erik Herman,12 hours,,,"Welcome to Fundamentals of Big Data, the fourth course of the Key Technologies of Data Analytics specialization. By enrolling in this course, you are taking the next step in your career in data analytics. This course is the fourth of a series that aims to prepare you for a role working in data analytics. In this course, you will be introduced to many of the core concepts of big data. You will learn about the primary systems used in big data. We’ll go through phases of a common big data life cycle. This course covers a wide variety of topics that are critical for understanding big data and are designed to give you an introduction and overview as you begin to build relevant knowledge and skills.",,Information Technology,LearnQuest,Enroll for Free,Key Technologies in Data Analytics Specialization,Erik Herman work for LearnQuest,Subtitles: English
"Healthcare Data Security, Privacy, and Compliance",https://www.coursera.org/learn/healthcare-data-security,4.7,"2,473","Paul Nagy, PhD, FSIIM",6 hours,Beginner,,"In the final course of the Healthcare IT Support program, we will focus on the types of healthcare data that you need to be aware, complexities of security and privacy within healthcare, and issues related to compliance and reporting. As a health IT support specialist, you’ll be exposed to different types of data sources and data elements that are utilized in healthcare. It’s important for you to understand the basic language of healthcare data and for you to recognize the sensitive nature of protected health information (PHI). Maintaining data privacy and security is everyone’s responsibility, including IT support staff! We’ll go into detail about HIPAA and the risks associated with security breaches, ransomware and phishing. We’ll go into detail about some of the key laws and regulations specific to healthcare and the importance of compliance with them.  You'll leave this course well versed on the Stark Law, the Joint Commission and the purpose of quality measures. We wrap up the Healthcare IT Support certificate with tips on job interviews, skills that can make you standout, and words of advice on the endless possibilities in this dynamic and growing field. Make sure you talk to others who’ve been there before about the process of being hired at a large health system. Be rest assured that you’ll receive training when you start a new role, and you might even be partnered with someone else for the first few weeks as you get onboarded. Remember, this is not the end--rather, it’s just the beginning of the next step in your journey!",,Health,Johns Hopkins University,Enroll for Free,Healthcare IT Support Specialization,"Paul Nagy, PhD, FSIIM work for Johns Hopkins University",Subtitles: English
Introduction to Data Science in Python,https://www.coursera.org/learn/python-data-analysis,4.5,"634,691",Christopher Brooks,31 hours,Intermediate,,"Understand techniques such as lambdas and manipulating csv files. Describe common Python functionality and features used for data science. Query DataFrame structures for cleaning and processing. Explain distributions, sampling, and t-tests",Python Programming          Numpy          Pandas          Data Cleansing      ,Data Science,University of Michigan,Enroll for Free,Applied Data Science with Python Specialization,Christopher Brooks work for University of Michigan,"Arabic, French, Portuguese (European), Italian, Portuguese (Brazilian), Vietnamese, German, Russian, English, Spanish"
